{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"8g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "table_name = 'user_kposminin.urls_w_levels1'\n",
    "query2 = '''\n",
    "select * from {0}\n",
    "where hash(cookie) % 64 = 0\n",
    "'''.format(table_name)\n",
    "\n",
    "#hc.sql(query2[0])\n",
    "#hc.sql(query2[1])\n",
    "\n",
    "rdd = hc.sql(query2).rdd #Посмотреть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Group by cookie and form url list the cookie visited\n",
    "rdd2 = rdd.map(lambda row: (row['cookie'] , row['domain'])).reduceByKey(lambda a,b: a + ';;' + b)\n",
    "\n",
    "# Label target cookies (=cookies visited target url) and exclude some urls\n",
    "import re\n",
    "#target_urls =['mkb.ru/facility/private_person/cards/credit_card','mkb.ru']\n",
    "target_urls =['avito.ru']\n",
    "exclude_urls = target_urls + []\n",
    "\n",
    "def handle_row(row,targ_urls, exclud_urls):\n",
    "    proc_urls = row[1]\n",
    "    for u in exclud_urls:\n",
    "        proc_urls = re.sub('[^;;]*'+ u +'[^;;]*','',proc_urls)\n",
    "    return (\n",
    "        any(tu in row[1] for tu in targ_urls), \n",
    "        re.sub('[;]{3,}',';;',proc_urls)\n",
    "    )\n",
    "\n",
    "rdd3 = rdd2.map(lambda row: handle_row(row,target_urls, exclude_urls))\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "\n",
    "tf = HashingTF(numFeatures = 10 ** 6)\n",
    "\n",
    "#transform urls (as Bag of Words) into features and form features with labels\n",
    "all_data = rdd3.map(lambda row: LabeledPoint(row[0], tf.transform(row[1].split(';;'))))\n",
    "# TODO count visits or not\n",
    "# split into train and test samples\n",
    "train_data, test_data = all_data.randomSplit([6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'D94A28A5676A86514BB2', u'm.ok.ru;;m.ok.ru;;m.ok.ru;;m.ok.ru')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "train_data.cache()\n",
    "\n",
    "model = LogisticRegressionWithSGD.train(train_data)\n",
    "model.clearThreshold()\n",
    "#Testing result\n",
    "test_res = test_data.map(lambda lp: (model.predict(lp.features),lp.label)) #.sortByKey(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52756335488805073"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "test_res_list = test_res.collect()\n",
    "aucroc = sklearn.metrics.roc_auc_score(\n",
    "        [e[1] for e in test_res_list],\n",
    "        [e[0] for e in test_res_list]\n",
    ")\n",
    "aucroc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_ROC(arr):\n",
    "    ''''Calculates ROC curve from arr input with two columns: \n",
    "        first is classifier score and second is label (0 or 1). arr is sorted by score.\n",
    "        Output is tuple with AUC ROC as first element and ROC array with two \n",
    "        columns FPR and TPR as second element.\n",
    "    '''\n",
    "    #cumulative positive, negative, true positive rate, false positive rate,\n",
    "    # area under ROC curve\n",
    "    TPR,FPR, AUC = 0., 0., 0.\n",
    "    one_to_P = 1. / sum([e[1] for e in arr])\n",
    "    one_to_N =  one_to_P / (len(arr) *  one_to_P - 1)\n",
    "    ROC = []\n",
    "    for e in arr:\n",
    "        if e[1] == 0 :            \n",
    "            FPR+= one_to_N\n",
    "            AUC += TPR * one_to_N\n",
    "        else:            \n",
    "            TPR+= one_to_P\n",
    "        ROC.append([FPR,TPR])\n",
    "    return (AUC, ROC)\n",
    "    \n",
    "#test_res_list = sorted(test_res_list, key = lambda e: -e[0])\n",
    "#res = calc_ROC(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.scatter([e[0] for e in res[1]],[e[0] for e in res[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(20, {1: 1.0, 14: 1.0, 18: 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = HashingTF(numFeatures = 20 ) \n",
    "tf1.transform(['fF','EFE','AS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52756335488805073"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'set_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-06f21e7c00f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'af'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2148\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 2150\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'set_columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([range(10),range(10)]).set_columns(['af','fg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
