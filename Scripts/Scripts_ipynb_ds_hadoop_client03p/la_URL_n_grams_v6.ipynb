{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Текстовый анализ URL в задаче lookalike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "\n",
    "sc.stop()\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 64)\n",
    "        .set(\"spark.driver.maxResultSize\", \"64g\")\n",
    "        .set('spark.driver.memory','32g')\n",
    "        .set(\"spark.executor.memory\", '16g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 6048)        \n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "n = 2\n",
    "tf_size = 2 ** 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I used alias to avoid confusion with the mllib library\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.ml.feature import HashingTF as MLHashingTF\n",
    "from pyspark.ml.feature import IDF as MLIDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate ru to eng, Transform text to n_gram list, Get n_gram index\n",
    "\n",
    "#abc = list(set(''.join([e[0] for e in hc.sql('select url from prod_raw_liveinternet.access_log v where ymd = \"2017-01-10\" limit 100000').collect()])))\n",
    "\n",
    "def n_gram(s, n):\n",
    "    '''Returns n-gram list from string s.'''\n",
    "    return [s[i:i+n] for i in range(len(s) - n + 1)]\n",
    "\n",
    "def n_gram_index(ngr,abc):\n",
    "    '''Returns index of n-gram ngr. ngr chars must be from abc list'''\n",
    "    N = tr_abc_len\n",
    "    ind = 0\n",
    "    \n",
    "    for i in range(len(ngr)):\n",
    "        try:\n",
    "            j = abc.index(ngr[i].lower())\n",
    "            if j > N:\n",
    "                j = abc.index(ngr[i].lower().translate(transl))\n",
    "            ind += (N ** i) * j\n",
    "        except ValueError:\n",
    "            ind += (N ** i) * (N - 1)\n",
    "    return ind\n",
    "\n",
    "#abc = list(u'abcdefghijklmnopqrstuvwxyz0123456789 _абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "#tr_abc_len = abc.index(u'а') - 1\n",
    "\n",
    "symbols = (u\"абвгдеёжзийклмнопрстуфхцчшщъыьэюя&-?%#!/\\=_.-~$\",\n",
    "           u\"abvgdeejzijklmnoprstufhzcss_y_eua           \")\n",
    "transl = {ord(a):ord(b) for a, b in zip(*symbols)}\n",
    "\n",
    "def handle_str(s,transl):\n",
    "    '''Translate ru-> eng by letter and lower string'''\n",
    "    return re.sub('[ ]+',' '*(n-1),re.sub('''[$#=\\[\\]_~+!&()*\\./:;\\?|'\"%-\\[\\],]''',' ',urllib.unquote(s.encode('UTF-8','ignore')).decode('UTF-8','ignore').lower().translate(transl)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = train_sample.collect()\n",
    "#for i in range(len(a)):\n",
    "#    print i\n",
    "#    b = handle_str(a[i].up,transl)\n",
    "s= u'''ok.ru/feed glistof.net/board/statusy_pro_ulybku/32 ok.ru/dk?st.cmd=anonymMain mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki\n",
    "mail.ru/?from=odnoklassniki ok.ru/ mail.ru/?from=odnoklassniki ok.ru/game/candyvalley2 ok.ru/dk?st.cmd=anonymMain\n",
    "ok.ru/game/candyvalley2 ok.ru/gifts ok.ru/feed ok.ru/ ok.ru/feed ok.ru/game/candyvalley2 ok.ru/game/candyvalley\n",
    "ok.ru/dk?st.cmd=anonymMain ok.ru/ my-hit.org/film/19945/ news.mail.ru/politics/27714036/?frommail=1 my-hit.org/film/19945/ news.mail.ru/politics/27714036/?frommail=1 filmogo.co/5902-odnazhdy-v-odesse-2-sezon-vse-seriyiiiiji.html \n",
    "ok.ru/game/candyvalley allserials.net/serial-3560-zapovednik-straha-1-sezon.html fast-torrent.ru/film/mezhdu-zhiznyu-i-smertyu.html ok.ru/feed bigcinema.to/series/severnyy-veter-serial.html\n",
    "go.mail.ru/search?rf=1011&fm=1&q=%D1%87%D1%82%D0%BE%20%D1%82%D0%B0%D0%BA%D0%BE%D0%B5%D0%B1%D1%80%D1%8E%D0%BA%D0%B8%20%D0%BA%D1%8E%D0%BB%D0%BE%D1%82%D1%8B&sbmt=1478611919453 bigcinema.to/series/severnyy-veter-serial.html \n",
    "bolshoyvopros.ru/questions/1828070-chto-takoe-brjuki-kjuloty-kak-oni-vygljadjat-kto-ih-avtor.html go.mail.ru/search?fm=1&rf=1011&q=ex.ua ok.ru/?_erv=vaywlyirbwpynedplup ok.ru/game/vegamix ok.ru/game/piratetreasures mail.ru/?from=odnoklassniki\n",
    "ok.ru/?_erv=vaywlyirbwpynedplup mail.ru/?from=odnoklassniki filmogo.co/5902-odnazhdy-v-odesse-2-sezon-vse-seriyiiiiji.html mail.ru/?from=odnoklassniki allserials.net/serial-3560-zapovednik-straha-1-sezon.html \n",
    "mail.ru/?from=odnoklassniki news.mail.ru/politics/27714037/?frommail=1 ok.ru/dk?st.cmd=anonymMain news.mail.ru/politics/27714037/?frommail=1 mail.ru/?from=odnoklassniki go.mail.ru/search?fm=1&rf=1011&q=cnfnecs ghj ek%2Cre \n",
    "mail.ru/?from=odnoklassniki statusas.ru/ulibka/33-ulibka.html mail.ru/?from=odnoklassniki go.mail.ru/search?fm=1&rf=1011&q=%D0%B1%D1%80%D1%8E%D0%BA%D0%B8 %D0%BA%D1%8E%D0%BB%D0%BE%D1%82%D1%8B mail.ru/?from=odnoklassniki\n",
    "mail.ru/?from=odnoklassniki ok.ru/feed mail.ru/?from=odnoklassniki ok.ru/profile/330316254834 mail.ru/?from=odnoklassniki pogoda.mail.ru/prognoz/kiev/ mail.ru/?from=odnoklassniki pogoda.mail.ru/prognoz/kiev/\n",
    "news.mail.ru/politics/27714036/?frommail=1 mail.ru/?from=odnoklassniki news.mail.ru/politics/27714036/?frommail=1 mail.ru/?from=odnoklassniki glistof.net/board/statusy_pro_ulybku/32 ok.ru/?_erv=viewlyirbwpynedra\n",
    "mail.ru/?from=odnoklassniki ok.ru/ mail.ru/?from=odnoklassniki ok.ru/ bigcinema.to/series/podzemnyy-perehod-serial.html bigcinema.to/series/podzemnyy-perehod-serial.html fast-torrent.ru/film/mezhdu-zhiznyu-i-smertyu.html \n",
    "bigcinema.to/series/severnyy-veter-serial.html bigcinema.to/series/severnyy-veter-serial.html mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki pogoda.mail.ru/prognoz/kiev/\n",
    "pogoda.mail.ru/prognoz/kiev/ mail.ru/?from=odnoklassniki mail.ru/?from=odnoklassniki news.mail.ru/incident/27707964/?frommail=1 news.mail.ru/incident/27707964/?frommail=1'''\n",
    "\n",
    "#print(handle_str(s,transl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_ngram_stat(sdf,n,tf_size,idf_method = None, minDocFreq = 1):\n",
    "    '''\n",
    "    Generates n-gram statistics of sdf.\n",
    "    \n",
    "    Input:\n",
    "      sdf -PySpark DataFrame.sdf last column contains text data to analyse (type string)\n",
    "      n - size of n-grams\n",
    "      tf_size -  dimension of a  space ngram projected to;\n",
    "      \n",
    "    Returns DataFrame with all sdf columns except last + columns:\n",
    "        tf_size - dimension of a  space ngram projected to;\n",
    "        tf_index - list of  indexes of n-gram found in sdf text columns;\n",
    "        tf_values - list of corresponding TF values (n-gram counts);\n",
    "        idf_values - list of corresponding TFIDF values.\n",
    "    '''\n",
    "    cols = sdf.columns\n",
    "    df_ngrams = (sdf\n",
    "               .rdd\n",
    "               .map(lambda r: list(r[:-1]) + [n_gram(handle_str(r[-1],transl),n)])\n",
    "               .toDF()\n",
    "               .withColumnRenamed(\"_{}\".format(len(cols)),\"ngram_list\"))    \n",
    "    htf_method = MLHashingTF(numFeatures = tf_size, inputCol=\"ngram_list\", outputCol=\"tf\")\n",
    "    df_tf = htf_method.transform(df_ngrams)    \n",
    "    if not idf_method:\n",
    "        print('Fitting idf_method')\n",
    "        idf_method = MLIDF(inputCol=\"tf\", outputCol=\"idf\", minDocFreq = minDocFreq).fit(df_tf)        \n",
    "    df_tfidf = idf_method.transform(df_tf)\n",
    "    df_data = (df_tfidf\n",
    "             .rdd\n",
    "             .map(lambda r:\n",
    "                  list(r[:-3]) + \n",
    "                  [r.tf.indices.tolist(),\n",
    "                  r.tf.values.tolist(),\n",
    "                  r.idf.values.tolist()]\n",
    "                 )\n",
    "             .toDF()\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)),\"tf_index\")\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)+1),\"tf_values\")\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)+2),\"idf_values\")\n",
    "             )\n",
    "    for i in range(len(cols)):\n",
    "        df_data = df_data.withColumnRenamed(\"_{}\".format(i+1),cols[i])\n",
    "    return df_data, idf_method\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sample = hc.sql('select phone_num,label,first_day,up from user_kposminin.url_text_20161108_2')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data,idf_method = generate_ngram_stat(train_sample, n = n, tf_size = tf_size)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data.write.saveAsTable(\"user_kposminin.url_text_feat_20161108_7\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-19 16:07:26.249256\n"
     ]
    }
   ],
   "source": [
    "test_sample = hc.sql('select phone_num,label,first_day,up from user_kposminin.url_text_20161115 where (substr(md5(phone_num),1,1) in (\"0\",\"1\") or label = 1)')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-19 16:38:30.312345\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IDFModel\n",
    "idfm = MLIDF._new_java_obj(\"org.apache.spark.ml.feature.IDFModel.load\", \"idf_model\")\n",
    "idf_method = IDFModel(idfm)\n",
    "\n",
    "test_data, _ = generate_ngram_stat(test_sample, n = n, tf_size = tf_size, idf_method = idf_method)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.write.saveAsTable(\"user_kposminin.url_text_feat_20161115_12\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#idf_method.save('idf_model.m')\n",
    "sc.parallelize(Seq(idf_method), 1).saveAsObjectFile(\"idf_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save IDF model\n",
    "writer = idf_method._call_java(\"write\")\n",
    "writer.save(\"idf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-19 17:28:50.775353\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-19 18:06:28.583026\n"
     ]
    }
   ],
   "source": [
    "tst = hc.sql('select phone_num,label,first_day,concat(substr(up,1,20),\"kkkkkk\") as up from user_kposminin.url_text_20161108_2  limit 5')\n",
    "df_tst = tst.toPandas()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting idf_method\n"
     ]
    }
   ],
   "source": [
    "tst_data,idf_method2 = generate_ngram_stat(tst, n = n, tf_size = tf_size)\n",
    "df_tst_data = tst_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_num</th>\n",
       "      <th>label</th>\n",
       "      <th>first_day</th>\n",
       "      <th>tf_index</th>\n",
       "      <th>tf_values</th>\n",
       "      <th>idf_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+70195908524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1097, 1102, 3139, 3143, 3240, 3241, 3245, 324...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 0.69314718056, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+70292460512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1091, 1094, 1110, 3180, 3241, 3276, 3349, 335...</td>\n",
       "      <td>[2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, ...</td>\n",
       "      <td>[1.38629436112, 0.69314718056, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+70292959915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1097, 1101, 1106, 3110, 3112, 3163, 3246, 329...</td>\n",
       "      <td>[1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 2.19722457734, 0.69314718056, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+70638960894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1091, 1096, 3114, 3180, 3238, 3335, 3380, 341...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, ...</td>\n",
       "      <td>[0.69314718056, 1.09861228867, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+70639551572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1094, 1095, 1102, 1106, 3132, 3194, 3231, 323...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 1.09861228867, 0.69314718056, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phone_num  label  first_day  \\\n",
       "0  +70195908524      0          0   \n",
       "1  +70292460512      0          0   \n",
       "2  +70292959915      0          0   \n",
       "3  +70638960894      0          0   \n",
       "4  +70639551572      0          0   \n",
       "\n",
       "                                            tf_index  \\\n",
       "0  [1097, 1102, 3139, 3143, 3240, 3241, 3245, 324...   \n",
       "1  [1091, 1094, 1110, 3180, 3241, 3276, 3349, 335...   \n",
       "2  [1097, 1101, 1106, 3110, 3112, 3163, 3246, 329...   \n",
       "3  [1091, 1096, 3114, 3180, 3238, 3335, 3380, 341...   \n",
       "4  [1094, 1095, 1102, 1106, 3132, 3194, 3231, 323...   \n",
       "\n",
       "                                           tf_values  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, ...   \n",
       "2  [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          idf_values  \n",
       "0  [0.69314718056, 0.69314718056, 1.09861228867, ...  \n",
       "1  [1.38629436112, 0.69314718056, 1.09861228867, ...  \n",
       "2  [0.69314718056, 2.19722457734, 0.69314718056, ...  \n",
       "3  [0.69314718056, 1.09861228867, 1.09861228867, ...  \n",
       "4  [0.69314718056, 1.09861228867, 0.69314718056, ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting idf_method\n"
     ]
    }
   ],
   "source": [
    "sdf = tst\n",
    "idf_method = None\n",
    "if True:\n",
    "    cols = sdf.columns\n",
    "    df_ngrams = (sdf\n",
    "               .rdd\n",
    "               .map(lambda r: list(r[:-1]) + [n_gram(handle_str(r[-1],transl),n)])\n",
    "               .toDF()\n",
    "               .withColumnRenamed(\"_{}\".format(len(cols)),\"ngram_list\"))    \n",
    "    htf_method = MLHashingTF(numFeatures = tf_size, inputCol=\"ngram_list\", outputCol=\"tf\")\n",
    "    df_tf = htf_method.transform(df_ngrams)    \n",
    "    if not idf_method:\n",
    "        print('Fitting idf_method')\n",
    "        idf_method = MLIDF(inputCol=\"tf\", outputCol=\"idf\", minDocFreq = 1).fit(df_tf)        \n",
    "    df_tfidf = idf_method.transform(df_tf)\n",
    "    df_data = (df_tfidf\n",
    "             .rdd\n",
    "             .map(lambda r:\n",
    "                  list(r[:-3]) + \n",
    "                  [r.tf.indices.tolist(),\n",
    "                  r.tf.values.tolist(),\n",
    "                  r.idf.values.tolist()]\n",
    "                 )\n",
    "             .toDF()\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)),\"tf_index\")\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)+1),\"tf_values\")\n",
    "             .withColumnRenamed(\"_{}\".format(len(cols)+2),\"idf_values\")\n",
    "             )\n",
    "    for i in range(len(cols)):\n",
    "        df_data = df_data.withColumnRenamed(\"_{}\".format(i+1),cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len([e for e in df.iloc[:,3] if 'k ' in e])\n",
    "len([e for e in df.iloc[1:,3] if 'k ' in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_tfidf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1048576, {1097: 1.0, 1102: 1.0, 3139: 1.0, 3143: 1.0, 3240: 1.0, 3241: 1.0, 3245: 1.0, 3247: 1.0, 3362: 1.0, 3364: 1.0, 3424: 5.0, 3477: 1.0, 3480: 1.0, 3511: 1.0, 3520: 1.0, 3521: 1.0, 3556: 1.0, 3628: 2.0, 3635: 1.0, 3681: 1.0})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'vk',\n",
       "  u'k ',\n",
       "  u' c',\n",
       "  u'co',\n",
       "  u'om',\n",
       "  u'm ',\n",
       "  u' v',\n",
       "  u'vk',\n",
       "  u'k ',\n",
       "  u' c',\n",
       "  u'co',\n",
       "  u'om',\n",
       "  u'm ',\n",
       "  u' f',\n",
       "  u'fr',\n",
       "  u'ri',\n",
       "  u'ie',\n",
       "  u'en'],\n",
       " 12,\n",
       " 18)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,3],len(set(df.iloc[1,3])),len(df.iloc[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SparseVector(1048576, {1091: 2.0, 1094: 1.0, 1110: 1.0, 3180: 2.0, 3241: 1.0, 3276: 1.0, 3349: 2.0, 3356: 1.0, 3411: 2.0, 3424: 5.0, 3517: 1.0, 3550: 2.0, 3639: 1.0, 3765: 2.0}),\n",
       " SparseVector(1048576, {1091: 1.3863, 1094: 0.6931, 1110: 1.0986, 3180: 1.3863, 3241: 0.6931, 3276: 1.0986, 3349: 1.3863, 3356: 1.0986, 3411: 1.3863, 3424: 0.0, 3517: 0.6931, 3550: 1.3863, 3639: 1.0986, 3765: 2.1972}))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tf[1],df.idf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"vk\": tf 0.166667. idf 2.251292.  tfidf 0.375215\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tf = 2./12\n",
    "\n",
    "idf = np.log((18.+1)/(1.+1))\n",
    "print('\"vk\": tf {:3f}. idf {:3f}.  tfidf {:3f}'.format(tf,idf,tf*idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"k \": tf 1.000000. idf 1.845827.  tfidf 1.845827\n"
     ]
    }
   ],
   "source": [
    "tf = 1.\n",
    "\n",
    "idf = np.log((18.+1)/(2.+1))\n",
    "print('\"k \": tf {:3f}. idf {:3f}.  tfidf {:3f}'.format(tf,idf,tf*idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_num</th>\n",
       "      <th>label</th>\n",
       "      <th>first_day</th>\n",
       "      <th>tf_index</th>\n",
       "      <th>tf_values</th>\n",
       "      <th>idf_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+70195908524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1097, 1102, 3139, 3143, 3240, 3241, 3245, 324...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 0.69314718056, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+70292460512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1091, 1094, 1110, 3180, 3241, 3276, 3349, 335...</td>\n",
       "      <td>[2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, ...</td>\n",
       "      <td>[1.38629436112, 0.69314718056, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+70292959915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1097, 1101, 1106, 3110, 3112, 3163, 3246, 329...</td>\n",
       "      <td>[1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 2.19722457734, 0.69314718056, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+70638960894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1091, 1096, 3114, 3180, 3238, 3335, 3380, 341...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, ...</td>\n",
       "      <td>[0.69314718056, 1.09861228867, 1.09861228867, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+70639551572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1094, 1095, 1102, 1106, 3132, 3194, 3231, 323...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.69314718056, 1.09861228867, 0.69314718056, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phone_num  label  first_day  \\\n",
       "0  +70195908524      0          0   \n",
       "1  +70292460512      0          0   \n",
       "2  +70292959915      0          0   \n",
       "3  +70638960894      0          0   \n",
       "4  +70639551572      0          0   \n",
       "\n",
       "                                            tf_index  \\\n",
       "0  [1097, 1102, 3139, 3143, 3240, 3241, 3245, 324...   \n",
       "1  [1091, 1094, 1110, 3180, 3241, 3276, 3349, 335...   \n",
       "2  [1097, 1101, 1106, 3110, 3112, 3163, 3246, 329...   \n",
       "3  [1091, 1096, 3114, 3180, 3238, 3335, 3380, 341...   \n",
       "4  [1094, 1095, 1102, 1106, 3132, 3194, 3231, 323...   \n",
       "\n",
       "                                           tf_values  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, ...   \n",
       "2  [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                          idf_values  \n",
       "0  [0.69314718056, 0.69314718056, 1.09861228867, ...  \n",
       "1  [1.38629436112, 0.69314718056, 1.09861228867, ...  \n",
       "2  [0.69314718056, 2.19722457734, 0.69314718056, ...  \n",
       "3  [0.69314718056, 1.09861228867, 1.09861228867, ...  \n",
       "4  [0.69314718056, 1.09861228867, 0.69314718056, ...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
