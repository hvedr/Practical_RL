{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "#import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import datetime\n",
    "#from pyspark.mllib.regression import LabeledPoint\n",
    "#from pyspark.mllib.feature import HashingTF\n",
    "#from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "#import scipy.sparse as sps\n",
    "#from pyspark.mllib.linalg import Vectors\n",
    "#import sklearn\n",
    "import itertools\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "#from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "sc = SparkContext()\n",
    "hc = HiveContext(sc)\n",
    "sc.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD модель интернет-логов. Выделение тем. ##\n",
    "Есть таблица интернет-логов  $m_{ij}$, каждая строка отвечает одному интернет-пользователю, каждый столбец - фрагменту урла. $m_{ij}=1$, если посетитель $i$ посетил фрагмент урла $j$ в рамках рассматриваемой сессии, иначе $m_{ij}=0$.\n",
    "\n",
    "Выделим темы - группировки урлов и пользователей. Для этого воспользуемся модификацией SVD разложения. \n",
    "\n",
    "Зафиксируем количество тем $K$. Для каждого пользователя сформируем вектор длины $K$, отражающий степень близости темы к пользователю. Получаем матрицу $X_{ik}$. Индекс $i$ отвечает пользователю, $k$ отвечает теме. \n",
    "\n",
    "Аналогично сформируем вектор  длины $K$ для каждого фрагмента урла. Получаем матрицу $Y_{kj}$. $k$ отвечает теме, $j$ отвечает фрагменту урла.\n",
    "\n",
    "Далее для каждого пользователя $i$ введем число $a_i$, которое в целом характеризует его интернет-активность.\n",
    "\n",
    "Аналогично, элементы вектора $b_j$ отражают популярность урла $j$.\n",
    "\n",
    "Параметр $\\mu$ есть усредняющий скаляр по всей выборке.\n",
    "\n",
    "Далее интерес пользователя  $i$ к фрагменту урла $j$ будем моделировать величиной $s_{ij} = \\mu + a_i + b_j + \\sum_k X_{ik} \\cdot Y_{kj}$.\n",
    "\n",
    "Для перевода этой величины в вероятность, воспользуемся логистической функцией: \n",
    "$\\hat{m}_{ij} = 1/(1+e^{-s_{ij}})$. \n",
    "\n",
    "Таким образом, построенная величина $\\hat{m}_{ij}$ есть  модельная оценка вероятности посещения пользователем $i$ фрагмента урла $j$.\n",
    "\n",
    "Введем функцию ошибки $L = \\sum_{ij} L_{ij} $,\n",
    "$$L_{ij} = -m_{ij} \\cdot \\ln(\\hat{m}_{ij}) - (1 - m_{ij}) \\cdot \\ln(1 - \\hat{m}_{ij}) + \\lambda_{0} \\cdot \\mu + \\lambda_{1}\\cdot (a_i^2 + b_j^2) + \\lambda_{2} \\cdot \\sum_k(X_{ik}^2 + Y_{kj}^2)$$.\n",
    "\n",
    "Для обучения будем использовать стохастический градиентный спуск (его модификацию Adadelta http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#AdaDelta_8211_implementation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 0 0.809257903106 2.09594658865 0.165913560335 0.855935721474 2.13917406658 0.214316548923 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 1 0.788582837572 2.17859933153 0.0935745905955 0.839298914975 2.23017948441 0.143858630258 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 2 0.803490759358 2.27255746797 0.0689574050549 0.860066898123 2.33192521053 0.124137741918 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 3 0.821735427527 2.34781430068 0.0586959909485 0.882792995481 2.41246765699 0.117955664727 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 4 0.83228223851 2.38041119311 0.0582177612093 0.896357199357 2.44858208016 0.120244758959 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 5 0.860782205622 2.47431898286 0.0540138170042 0.926557901789 2.54423676933 0.11771846802 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 6 0.854591438852 2.46078771085 0.0514933028514 0.921777362337 2.53230250667 0.116514790171 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 7 0.868387273247 2.5176026912 0.0437795642711 0.935966739729 2.58965427025 0.10912297447 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 8 0.868216419477 2.50943827101 0.0476054937103 0.937026737063 2.58234660364 0.114366803774 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 9 0.877130661724 2.52810596469 0.0516430102414 0.946707355267 2.6014615336 0.1193302661 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 10 0.864560561916 2.49315593461 0.0502628755661 0.934694906444 2.5669843538 0.118550182764 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 11 0.885488437494 2.5650913731 0.0456869696902 0.956120168695 2.63903352008 0.114663493002 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 12 0.885431067959 2.5783413265 0.0389759386893 0.956255318502 2.65252082344 0.108122566033 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 13 0.883135233575 2.56147171816 0.0439669912839 0.954295774403 2.63568706783 0.113600127691 \n",
      "[1, 1, 1] [0.000248, 0.000248, 0.00248] 14 0.886114006605 2.56441050987 0.0469657549745 0.957210091 2.63880601592 0.116412128538 \n",
      "Finish. Work time 0:12:10.328531.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = datetime.datetime.now()\n",
    "# Param selection\n",
    "query = '''\n",
    "select id_num,urlfr_num from \n",
    "(select id_num,urlfr_num,count(*) over (partition by id_num) as uf_cnt,count(*) over (partition by urlfr_num) as id_cnt from user_kposminin.visits_enum_20160412 \n",
    "where id_num < 10000) a\n",
    "where id_cnt > 10 and uf_cnt > 9\n",
    "'''\n",
    "# where uf_cnt > 9 and id_cnt > 500\n",
    "\n",
    "\n",
    "K = 50\n",
    "id_cnt = 10000\n",
    "urlfr_cnt = 3000000\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "#lmbd = np.array([0.01, 0.01, 0.01])\n",
    "\n",
    "#step = np.array([0.001, 0.005, 0.01])\n",
    "\n",
    "param_grid = []\n",
    "\n",
    " #   [[0.00001, 0.0001, 0.0001],[0.01, 0.05, 0.01]],\n",
    "for base_step in np.exp(np.arange(-4,0,2)):\n",
    "    for base_lmbd in np.exp(np.arange(-14,-8,2)):\n",
    "        for var_step in np.array([[0.1,1,0.1],[0.01,1,10]]):\n",
    "            for var_lmbd in np.array([[0.01,0.1,1],[1,0.1,0.01]]):\n",
    "                param_grid.append([var_step * base_step,var_lmbd * base_lmbd])\n",
    "\n",
    "'''\n",
    "# Load and parse the data\n",
    "sampled_data = hc.sql(query) \\\n",
    "            .collect()\n",
    "print('Sampled data consists of {} rows, {} id and {} uf.'.format(len(sampled_data),len(set([e[0] for e in sampled_data])),len(set([e[1] for e in sampled_data]))))\n",
    "\n",
    "train,test = [], []\n",
    "for r in sampled_data:\n",
    "    if(np.random.rand() < 0.1):\n",
    "        test.append(r)\n",
    "    else:\n",
    "        train.append(r)\n",
    "'''\n",
    "#  \n",
    "# prediction is m^hat_{ij} = 1/(1+exp(-s_{ij})) where s_{ij} = mu + a[i] + b[j] + sum_k (X[i,k] * Y[k,j])\n",
    "# error function is L_{ij} = -m_{ij}*ln(m^hat_{ij}) - (1 - m_{ij})*ln(1 - m^hat_{ij}) + \n",
    "#                            lmbd[0] * mu + lmbd[1]*(a_i^2 + b_j^2) + lmbd[2]*sum_k(X_{ik}^2 + Y_{kj}^2)\n",
    "f = open('data/collab_filter_SGD_param_tuning.csv','a+')\n",
    "f.write('\\n\\n New calc at {}'.format(datetime.datetime.now()))\n",
    "stat = []\n",
    "prev_id = -1\n",
    "uf_visited= []\n",
    "neg_sig_share = 2\n",
    "rho = 0.9\n",
    "eps = 1e-6\n",
    "\n",
    "for step,lmbd in [[[1,1,1],[2.48e-04,2.48e-04,2.48E-03]]]:    \n",
    "    #Init matrices\n",
    "    mu, mu_gr_sq, mu_d_sq = np.random.rand(1) - 0.5 - 2, np.zeros(1), np.zeros(1) # One-element array to be able to update inside a procedure\n",
    "    a, a_gr_sq,   a_d_sq = np.random.rand(id_cnt) - 0.5, np.zeros(id_cnt), np.zeros(id_cnt)\n",
    "    b, b_gr_sq,   b_d_sq = np.random.rand(urlfr_cnt) - 0.5, np.zeros(urlfr_cnt), np.zeros(urlfr_cnt)\n",
    "    X, X_gr_sq,   X_d_sq = np.random.rand(id_cnt, K) - 0.5, np.zeros([id_cnt, K]), np.zeros([id_cnt, K])\n",
    "    Y, Y_gr_sq,   Y_d_sq = np.random.rand(K,urlfr_cnt) - 0.5, np.zeros([K,urlfr_cnt]), np.zeros([K,urlfr_cnt])\n",
    "\n",
    "    def make_step(i, j, v):\n",
    "        s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "        pred = 1./(1+np.exp(-s))\n",
    "        err = v - pred # r[2] - pred\n",
    "        grad_mu = -err + lmbd[0] * mu\n",
    "        grad_ai = -err + lmbd[1] * a[i]\n",
    "        grad_bj = -err + lmbd[1] * b[j]\n",
    "        grad_xi = -err * Y[:,j] + lmbd[2] * X[i,:]\n",
    "        grad_yj = -err * X[i,:] + lmbd[2] * Y[:,j]\n",
    "        \n",
    "        # TODO Implement Adadelta SGD version. \n",
    "        #http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#AdaDelta_8211_implementation\n",
    "        # \n",
    "        mu_gr_sq[0] = rho * mu_gr_sq[0] + (1-rho) * (grad_mu[0] ** 2)\n",
    "        a_gr_sq[i]  = rho * a_gr_sq[i] + (1-rho) * (grad_ai ** 2)\n",
    "        b_gr_sq[j]  = rho * b_gr_sq[j] + (1-rho) * (grad_bj ** 2)\n",
    "        X_gr_sq[i,:]  = rho * X_gr_sq[i,:] + (1-rho) * (grad_xi ** 2)\n",
    "        Y_gr_sq[:,j]  = rho * Y_gr_sq[:,j] + (1-rho) * (grad_yj ** 2)\n",
    "        \n",
    "        dmu = -(mu_d_sq + eps) ** 0.5 / (mu_gr_sq + eps) ** 0.5 * grad_mu\n",
    "        dai = -(a_d_sq[i] + eps) ** 0.5 / (a_gr_sq[i] + eps) ** 0.5 * grad_ai\n",
    "        dbj = -(b_d_sq[j] + eps) ** 0.5 / (b_gr_sq[j] + eps) ** 0.5 * grad_bj\n",
    "        dXi = -(X_d_sq[i,:]  + eps) ** 0.5 / (X_gr_sq[i,:]  + eps) ** 0.5 * grad_xi\n",
    "        dYj = -(Y_d_sq[:,j]  + eps) ** 0.5 / (Y_gr_sq[:,j]  + eps) ** 0.5 * grad_yj\n",
    "        \n",
    "        mu_d_sq[0] = rho * mu_d_sq[0] + (1-rho) * (dmu[0] ** 2)\n",
    "        a_d_sq[i]  = rho * a_d_sq[i] + (1-rho) * (dai ** 2)\n",
    "        b_d_sq[j]  = rho * b_d_sq[j] + (1-rho) * (dbj ** 2)\n",
    "        X_d_sq[i,:]  = rho * X_d_sq[i,:] + (1-rho) * (grad_xi ** 2)\n",
    "        Y_d_sq[:,j]  = rho * Y_d_sq[:,j] + (1-rho) * (grad_yj ** 2)\n",
    "        \n",
    "        mu[0]+= dmu[0] /5\n",
    "        a[i] += dai /5\n",
    "        b[j] += dbj / 5\n",
    "        X[i,:] = X[i,:] + dXi /5\n",
    "        Y[:,j] = Y[:,j] + dYj / 5\n",
    "        \n",
    "        #mu[0]   += - grad_mu * step[0]\n",
    "        #a[i] += - grad_ai * step[1]\n",
    "        #b[j] += - grad_bj * step[1]\n",
    "        #X[i,:] = X[i,:] - grad_xi * step[2]\n",
    "        #Y[:,j] = Y[:,j] - grad_yj * step[2]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for r in train:\n",
    "            i,j = r[:2]\n",
    "            make_step(i, j, 1)\n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(train) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not train[(ni + k) % len(train)][1] in uf_visited):                        \n",
    "                        make_step(prev_id, train[(ni + k) % len(train)][1],0)\n",
    "                        neg += 1\n",
    "                    k +=1 \n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        \n",
    "        #calc err\n",
    "        err1_p ,err2_p, err1_n, err2_n = 0, 0, 0, 0\n",
    "        for r in test:\n",
    "            i,j = r[:2]\n",
    "            s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "            pred = 1/(1+np.exp(-s))\n",
    "            err1_p += - 1 * np.log(pred) # r[2] - pred\n",
    "            err2_p += - 1 * np.log(pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i] ** 2 + b[j] ** 2) + lmbd[2] * (X[i,:].dot(X[i,:]) + Y[:,j].dot(Y[:,j]))\n",
    "            \n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(test) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not test[(ni + k) % len(test)][1] in uf_visited): \n",
    "                        i1, j1 = prev_id, train[(ni + k) % len(train)][1]\n",
    "                        s = mu[0] + a[i1] + b[j1] + X[i1,:].dot(Y[:,j1])\n",
    "                        pred = 1/(1+np.exp(-s))\n",
    "                        err1_n += - 1 * np.log(1 - pred) # r[2] - pred\n",
    "                        err2_n += - 1 * np.log(1 - pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i1] ** 2 + b[j1] ** 2) + lmbd[2] * (X[i1,:].dot(X[i1,:]) + Y[:,j1].dot(Y[:,j1]))                        \n",
    "                        neg += 1\n",
    "                    k +=1 \n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        err1_t = (err1_p + err1_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err2_t = (err2_p + err2_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err1_p /= float(len(test))\n",
    "        err2_p /= float(len(test))\n",
    "        err1_n /= len(test) * neg_sig_share\n",
    "        err2_n /= len(test) * neg_sig_share        \n",
    "        \n",
    "        stat=('{} ' * 9).format(step,lmbd,epoch,err1_t, err1_p,err1_n,err2_t, err2_p,err2_n)\n",
    "        f.write(stat + '\\n')\n",
    "        print(stat)\n",
    "        \n",
    "print('Finish. Work time {}.'.format(datetime.datetime.now()- start_time))\n",
    "f.write('\\nFinish at {}. Work time {}.\\n\\n\\n'.format(datetime.datetime.now(),datetime.datetime.now() - start_time))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mu' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9cb4eb1a6a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outside '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-9cb4eb1a6a6c>\u001b[0m in \u001b[0;36msd\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'mu' referenced before assignment"
     ]
    }
   ],
   "source": [
    "mu = np.random.rand(1) - 0.5 - 6\n",
    "def sd(a):\n",
    "    print(mu[0])\n",
    "    mu = mu + 3\n",
    "    print(mu[0])\n",
    "\n",
    "sd(2)\n",
    "print('outside '+ str(mu[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i= 1\n",
    "j = 1\n",
    "v = 1\n",
    "if True:\n",
    "    mu, mu_gr_sq, mu_d_sq = np.random.rand(1) - 0.5 -6, np.zeros(1), np.zeros(1) # One-element array to be able to update inside a procedure\n",
    "    a, a_gr_sq,   a_d_sq = np.random.rand(id_cnt) - 0.5, np.zeros(id_cnt), np.zeros(id_cnt)\n",
    "    b, b_gr_sq,   b_d_sq = np.random.rand(urlfr_cnt) - 0.5, np.zeros(urlfr_cnt), np.zeros(urlfr_cnt)\n",
    "    X, X_gr_sq,   X_d_sq = np.random.rand(id_cnt, K) - 0.5, np.zeros([id_cnt, K]), np.zeros([id_cnt, K])\n",
    "    Y, Y_gr_sq,   Y_d_sq = np.random.rand(K,urlfr_cnt) - 0.5, np.zeros([K,urlfr_cnt]), np.zeros([K,urlfr_cnt])\n",
    "    if True:\n",
    "        s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "        pred = 1./(1+np.exp(-s))\n",
    "        err = v - pred # r[2] - pred\n",
    "        grad_mu = -err + lmbd[0] * mu\n",
    "        grad_ai = -err + lmbd[1] * a[i]\n",
    "        grad_bj = -err + lmbd[1] * b[j]\n",
    "        grad_xi = -err * Y[:,j] + lmbd[2] * X[i,:]\n",
    "        grad_yj = -err * X[i,:] + lmbd[2] * Y[:,j]\n",
    "        \n",
    "        # TODO Implement Adadelta SGD version. \n",
    "        #http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#AdaDelta_8211_implementation\n",
    "        # \n",
    "        mu_gr_sq[0] = rho * mu_gr_sq[0] + (1-rho) * (grad_mu[0] ** 2)\n",
    "        a_gr_sq[i]  = rho * a_gr_sq[i] + (1-rho) * (grad_ai ** 2)\n",
    "        b_gr_sq[j]  = rho * b_gr_sq[j] + (1-rho) * (grad_bj ** 2)\n",
    "        X_gr_sq[i,:]  = rho * X_gr_sq[i,:] + (1-rho) * (grad_xi ** 2)\n",
    "        Y_gr_sq[:,j]  = rho * Y_gr_sq[:,j] + (1-rho) * (grad_yj ** 2)\n",
    "        \n",
    "        dmu = -(mu_d_sq + eps) ** 0.5 / (mu_gr_sq + eps) ** 0.5 * grad_mu\n",
    "        dai = -(a_d_sq[i] + eps) ** 0.5 / (a_gr_sq[i] + eps) ** 0.5 * grad_ai\n",
    "        dbj = -(b_d_sq[j] + eps) ** 0.5 / (b_gr_sq[j] + eps) ** 0.5 * grad_bj\n",
    "        dXi = -(X_d_sq[i,:]  + eps) ** 0.5 / (X_gr_sq[i,:]  + eps) ** 0.5 * grad_xi\n",
    "        dYj = -(Y_d_sq[:,j]  + eps) ** 0.5 / (Y_gr_sq[:,j]  + eps) ** 0.5 * grad_yj\n",
    "        \n",
    "        mu_d_sq[0] = rho * mu_d_sq[0] + (1-rho) * (dmu[0] ** 2)\n",
    "        a_d_sq[i]  = rho * a_d_sq[i] + (1-rho) * (dai ** 2)\n",
    "        b_d_sq[j]  = rho * b_d_sq[j] + (1-rho) * (dbj ** 2)\n",
    "        X_d_sq[i,:]  = rho * X_d_sq[i,:] + (1-rho) * (grad_xi ** 2)\n",
    "        Y_d_sq[:,j]  = rho * Y_d_sq[:,j] + (1-rho) * (grad_yj ** 2)\n",
    "        \n",
    "        mu[0]+= dmu\n",
    "        a[i] += dai\n",
    "        b[j] += dbj\n",
    "        X[i,:] = X[i,:] + dXi\n",
    "        Y[:,j] = Y[:,j] + dYj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "K = 50\n",
    "id_cnt = 10000\n",
    "urlfr_cnt = 3000000\n",
    "epochs = 15\n",
    "step,lmbd = [[[1,1,1],[0.0001, 0.0001, 0.0001]]][0]\n",
    "rho = 1e-6\n",
    "stat = []\n",
    "prev_id = -1\n",
    "uf_visited= []\n",
    "neg_sig_share = 2\n",
    "rho = 0.9\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu, mu_gr_sq, mu_d_sq = np.random.rand(1) - 0.5 -6, np.zeros(1), np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu_gr_sq[0] = rho * mu_gr_sq[0] + (1-rho) * (grad_mu[0] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00316226])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmu = -(mu_d_sq + eps) ** 0.5 / (mu_gr_sq + eps) ** 0.5 * grad_mu\n",
    "dmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99967312])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.70989463])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
