{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Кредитный скоринг\".\n",
    "### Определение одобренных заявок среди полных на базе обзвона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "\n",
    "sc.stop()\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 20)\n",
    "        .set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "        .set('spark.driver.memory','16g')\n",
    "        .set(\"spark.executor.memory\", '8g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 1048)        \n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_kposminin.ccall_scoring_train \n",
    "#user_kposminin.ccall_scoring_train \n",
    "select_train_query = '''\n",
    "select phone_mobile, approve, cast(urlfr_hash as int) as urlfr_hash,cnt, call_ymd from user_kposminin.ccall_scoring_train    \n",
    "lateral view explode(array(conv(substr(md5(urlfr),0,5),16,10),conv(substr(md5(concat(urlfr,'sdfa')),0,5),16,10))) a as urlfr_hash\n",
    "\n",
    "'''\n",
    "def drop_duplicates(l):\n",
    "    '''Drop duplicates in l keys. l is a list of key,value tuples.'''\n",
    "    v = sorted(l,key = lambda e:e[0])\n",
    "    return [(int(e[0]),int(e[1])) for e in v[0:1] + [v[i] for i in range(1,len(v)) if v[i][0] != v[i-1][0]]]\n",
    "\n",
    "#ymd = '2016-12-01'\n",
    "\n",
    "df_train = (hc.sql(select_train_query)\n",
    "            .rdd\n",
    "            .filter(lambda row: (row['call_ymd'] < '2016-12-01'))\n",
    "            .map(lambda row: ((row['phone_mobile'],row['approve']),(row['urlfr_hash'],1)))\n",
    "            .groupByKey()\n",
    "            .map(lambda (k,v):LabeledPoint(k[1], SparseVector(16 ** 5, drop_duplicates(v))))\n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = df_train[0][1]\n",
    "#.map(lambda (k,v):LabeledPoint(k[1], SparseVector(16 ** 5, [(int(e[0]),e[1]) for e in v])))\n",
    "lrm = LogisticRegressionWithSGD.train(df_train, iterations=10)\n",
    "lrm.clearThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-07 16:49:16.067854\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test = (hc.sql(select_train_query)\n",
    "            .rdd\n",
    "            .filter(lambda row: (row['call_ymd'] >= '2016-12-01'))\n",
    "            .map(lambda row: ((row['phone_mobile'],row['approve']),(row['urlfr_hash'],1)))\n",
    "            .groupByKey()\n",
    "            .map(lambda (k,v):LabeledPoint(k[1], SparseVector(16 ** 5, drop_duplicates(v))))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.487468533123\n",
      "Area under ROC = 0.636068098722\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = df_test.map(lambda lp: (float(lrm.predict(lp.features)), lp.label))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "\n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = df_test.map(lambda lp: (float(lrm.predict(lp.features)), lp.label)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(predictionAndLabels_train) # python list of train predictionAndLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def metrics(y_true,y_score,lift = None, return_str = False):\n",
    "    import sklearn\n",
    "    import collections\n",
    "    \n",
    "    if True:\n",
    "        \n",
    "        res = collections.OrderedDict()\n",
    "        samp_size = len(y_true)\n",
    "        res['Sample size'] = samp_size\n",
    "        res['Posit share'] = sum(y_true) * 1./ samp_size\n",
    "        res['Sample size'] = len(y_true)\n",
    "        res['AUC ROC'] = sklearn.metrics.roc_auc_score(y_true = y_true, y_score = y_score)\n",
    "        res['AUC PR'] = sklearn.metrics.auc(\n",
    "                        *sklearn.metrics.precision_recall_curve(y_true = y_true, probas_pred  = y_score)[:2],\n",
    "                        reorder = True\n",
    "        )\n",
    "        res['Log loss'] = sklearn.metrics.log_loss(y_true = y_true, y_pred = y_score)\n",
    "        if lift:\n",
    "            predictions_and_labels = sorted(zip(y_score,y_true), key = lambda e:-e[0])\n",
    "            for l in lift:\n",
    "                res['Lift ' + str(l)] = sum([e[1] for e in predictions_and_labels[:int(l * samp_size)]]) * 1. / int(l * samp_size) / res['Posit share']\n",
    "                \n",
    "        if return_str:\n",
    "            res = '\\n'.join(['{:<12}: {:.5f}'.format(k,v) for (k,v) in res.items()]) + '.'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regressioin Performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.64797\n",
      "AUC PR      : 0.12356\n",
      "Log loss    : 0.77634\n",
      "Lift 0.01   : 1.51883\n",
      "Lift 0.02   : 1.54252\n",
      "Lift 0.05   : 1.51027\n",
      "Lift 0.1    : 1.47730\n",
      "Lift 0.2    : 1.42460\n",
      "Lift 0.5    : 1.26562.\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regressioin Performance on Test data\\n' + \n",
    "      metrics(\n",
    "        y_true = [e[1] for e in res], \n",
    "        y_score = [e[0] for e in res],\n",
    "        lift = [0.01,0.02,0.05,0.1,0.2,0.5], \n",
    "        return_str = True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regressioin Performance on Train data\n",
      "Sample size : 391496.00000\n",
      "Posit share : 0.37008\n",
      "AUC ROC     : 0.63607\n",
      "AUC PR      : 0.11866\n",
      "Log loss    : 0.73104\n",
      "Lift 0.01   : 1.67554\n",
      "Lift 0.02   : 1.61113\n",
      "Lift 0.05   : 1.56131\n",
      "Lift 0.1    : 1.50764\n",
      "Lift 0.2    : 1.42963\n",
      "Lift 0.5    : 1.24667.\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regressioin Performance on Train data\\n' + \n",
    "      metrics(\n",
    "        y_true = [e[1] for e in predictionAndLabels_train], \n",
    "        y_score = [e[0] for e in predictionAndLabels_train],\n",
    "        lift = [0.01,0.02,0.05,0.1,0.2,0.5], \n",
    "        return_str = True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save in vowpal wabbit format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df_train\n",
    " .map(lambda r:('1' if r.label == 1 else '-1') + ' | ' + ' '.join(['{}:{}'.format(*e) for e in zip(r.features.indices,r.features.values)])) \n",
    " .saveAsTextFile('url_text_fullapp_train_vw')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df_test\n",
    " .map(lambda r:('1' if r.label == 1 else '-1') + ' | ' + ' '.join(['{}:{}'.format(*e) for e in zip(r.features.indices,r.features.values)])) \n",
    " .saveAsTextFile('url_text_fullapp_test_vw')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "clfNB = NaiveBayes.train(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba_NB_2(f, model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability for 2-class classification.\n",
    "    f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Output: probability of class 1 (type float).\n",
    "    '''\n",
    "    if len(model.theta) != 2:\n",
    "        print('Model is NOT a 2-class classifier')\n",
    "        return None\n",
    "    logp = [f.dot(model.theta[i]) + model.pi[i] for i in range(2)]    \n",
    "    return 1./(1. + np.exp(logp[0] - logp[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_lab_NB = (df_test\n",
    "               .map(lambda lp:(float(predict_proba_NB_2(lp.features, clfNB)),lp.label))\n",
    "               .collect()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.64559\n",
      "AUC PR      : 0.18222\n",
      "Log loss    : 7.75342\n",
      "Lift 0.05   : 1.43483\n",
      "Lift 0.1    : 1.41667\n",
      "Lift 0.2    : 1.41055\n",
      "Lift 0.5    : 1.27331.\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes Performance on Test data\\n' + metrics(y_true = [e[1] for e in pred_lab_NB], y_score = [e[0] for e in pred_lab_NB], lift = [0.05,0.1,0.2,0.5], return_str = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34576"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999998, 1.0)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = sorted(pred_lab_NB,reverse = True)\n",
    "a[7230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5540802213001383, 0.20910458121240166)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=7230\n",
    "sum([e[1] for e in a[:n]])*1./n,n*1./len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = clfNB.theta\n",
    "pi = clfNB.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-14.214210979859354, -14.200472365240667)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[0][0],theta[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean(l):\n",
    "    try:\n",
    "        return sum(l) * 1./len(l)\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def NB_scores(f, theta_dif):\n",
    "    f = list(f)\n",
    "    assert len(f) == len(theta_dif)\n",
    "    p_dif = sorted([f[i]*theta_dif[i] for i in range(len(f))],reverse = True)\n",
    "    n = len(p_dif)\n",
    "    return (\n",
    "          max(p_dif),\n",
    "          min(p_dif)\n",
    "          mean(p_dif),\n",
    "          mean(p_dif[:int(n * 0.05)]),\n",
    "          mean(p_dif[:int(n * 0.1)]),\n",
    "          mean(p_dif[:int(n * 0.3)]),\n",
    "          mean(p_dif[:int(n * 0.5)]),\n",
    "          mean(p_dif[:int(n * 0.7)]),\n",
    "          mean(p_dif[:int(n * 0.9)]),\n",
    "          mean(p_dif[:3]),\n",
    "          mean(p_dif[:5]),\n",
    "          mean(p_dif[:10]),\n",
    "          sum(p_dif)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.49836773308340021,\n",
       "  2.7788135282289811e-05,\n",
       "  0.0080623584404414892,\n",
       "  0.0040311407756798917,\n",
       "  0.0013437093203319634,\n",
       "  0.00080622354186147009,\n",
       "  0.00057587411538572244,\n",
       "  0.48938118146744475,\n",
       "  0.48147389861723899,\n",
       "  0.46136024910430307,\n",
       "  29.137971741762321),\n",
       " 0.0)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lab_NB_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_lab_NB_1 = (df_test\n",
    "               .map(lambda lp:((NB_scores(lp.features, theta[1] - theta[0])),lp.label))\n",
    "               .collect()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.54654\n",
      "AUC PR      : 0.04852\n",
      "Log loss    : 0.76236\n",
      "Lift 0.05   : 1.27212\n",
      "Lift 0.1    : 1.21482\n",
      "Lift 0.2    : 1.16733\n",
      "Lift 0.5    : 1.08745.\n",
      "\n",
      "\n",
      "1 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.64629\n",
      "AUC PR      : 0.14031\n",
      "Log loss    : 8.21339\n",
      "Lift 0.05   : 1.46294\n",
      "Lift 0.1    : 1.44847\n",
      "Lift 0.2    : 1.41942\n",
      "Lift 0.5    : 1.27331.\n",
      "\n",
      "\n",
      "2 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.53429\n",
      "AUC PR      : 0.02889\n",
      "Log loss    : 2.67382\n",
      "Lift 0.05   : 1.14047\n",
      "Lift 0.1    : 1.15493\n",
      "Lift 0.2    : 1.11299\n",
      "Lift 0.5    : 1.06188.\n",
      "\n",
      "\n",
      "3 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.53429\n",
      "AUC PR      : 0.02889\n",
      "Log loss    : 2.94246\n",
      "Lift 0.05   : 1.14047\n",
      "Lift 0.1    : 1.15493\n",
      "Lift 0.2    : 1.11299\n",
      "Lift 0.5    : 1.06188.\n",
      "\n",
      "\n",
      "4 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.53429\n",
      "AUC PR      : 0.02889\n",
      "Log loss    : 3.36912\n",
      "Lift 0.05   : 1.14047\n",
      "Lift 0.1    : 1.15493\n",
      "Lift 0.2    : 1.11299\n",
      "Lift 0.5    : 1.06188.\n",
      "\n",
      "\n",
      "5 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.53429\n",
      "AUC PR      : 0.02889\n",
      "Log loss    : 3.56767\n",
      "Lift 0.05   : 1.14047\n",
      "Lift 0.1    : 1.15493\n",
      "Lift 0.2    : 1.11299\n",
      "Lift 0.5    : 1.06188.\n",
      "\n",
      "\n",
      "6 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.53429\n",
      "AUC PR      : 0.02889\n",
      "Log loss    : 3.69848\n",
      "Lift 0.05   : 1.14047\n",
      "Lift 0.1    : 1.15493\n",
      "Lift 0.2    : 1.11299\n",
      "Lift 0.5    : 1.06188.\n",
      "\n",
      "\n",
      "7 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.55548\n",
      "AUC PR      : 0.06286\n",
      "Log loss    : 0.76224\n",
      "Lift 0.05   : 1.39637\n",
      "Lift 0.1    : 1.30355\n",
      "Lift 0.2    : 1.19912\n",
      "Lift 0.5    : 1.10224.\n",
      "\n",
      "\n",
      "8 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.55902\n",
      "AUC PR      : 0.06570\n",
      "Log loss    : 0.76680\n",
      "Lift 0.05   : 1.43779\n",
      "Lift 0.1    : 1.31685\n",
      "Lift 0.2    : 1.23460\n",
      "Lift 0.5    : 1.10150.\n",
      "\n",
      "\n",
      "9 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.56227\n",
      "AUC PR      : 0.16545\n",
      "Log loss    : 0.77924\n",
      "Lift 0.05   : 1.45702\n",
      "Lift 0.1    : 1.34199\n",
      "Lift 0.2    : 1.24976\n",
      "Lift 0.5    : 1.10978.\n",
      "\n",
      "\n",
      "10 metrics performance on Test data\n",
      "Sample size : 34576.00000\n",
      "Posit share : 0.39123\n",
      "AUC ROC     : 0.64629\n",
      "AUC PR      : 0.14031\n",
      "Log loss    : 12.47075\n",
      "Lift 0.05   : 1.46294\n",
      "Lift 0.1    : 1.44847\n",
      "Lift 0.2    : 1.41942\n",
      "Lift 0.5    : 1.27331.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_lab_NB_1[1][0])):\n",
    "    print(('\\n'*2) + str(i) + ' metrics performance on Test data\\n' + \n",
    "          metrics(y_true = [e[1] for e in pred_lab_NB_1], y_score = [e[0][i] for e in pred_lab_NB_1], lift = [0.05,0.1,0.2,0.5], return_str = True)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучшие: min(score diff) ?? и sum(score diff). Но это все хуже просто Наивного Байеса по AUC ROC и AUC PR, но ~лучше лифт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "          max(p_dif),\n",
    "          min(p_dif)\n",
    "          mean(p_dif),\n",
    "          mean(p_dif[:int(n * 0.05)]),\n",
    "          mean(p_dif[:int(n * 0.1)]),\n",
    "          mean(p_dif[:int(n * 0.3)]),\n",
    "          mean(p_dif[:int(n * 0.5)]),\n",
    "          mean(p_dif[:int(n * 0.7)]),\n",
    "          mean(p_dif[:int(n * 0.9)]),\n",
    "          mean(p_dif[:3]),\n",
    "          mean(p_dif[:5]),\n",
    "          mean(p_dif[:10]),\n",
    "          sum(p_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
