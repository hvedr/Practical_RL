{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание таблицы факторов по кукам для кред скоринга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class calc_cred_score():\n",
    "\n",
    "    init_query = '''\n",
    "    set hive.vectorized.execution.enabled=true;\n",
    "    set mapreduce.map.memory.mb=4096;\n",
    "    set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "    set mapreduce.task.io.sort.mb=1024;\n",
    "    set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "    set mapreduce.reduce.memory.mb=7000;\n",
    "    set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "    set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "    set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "    set hive.optimize.ppd=true;\n",
    "    set hive.merge.smallfiles.avgsize=536870912;\n",
    "    set hive.merge.mapredfiles=true;\n",
    "    set hive.merge.mapfiles=true;\n",
    "    set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "    set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "    set hive.exec.parallel=true;\n",
    "    set hive.exec.max.created.files=10000000;\n",
    "    set hive.exec.compress.output=true;\n",
    "    set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "    set hive.exec.max.dynamic.partitions=1000000;\n",
    "    set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "    set io.seqfile.compression.type=BLOCK;\n",
    "    set mapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec;\n",
    "    set mapreduce.map.failures.maxpercent=5;\n",
    "\n",
    "    set hive.tez.auto.reducer.parallelism=true;\n",
    "    set hive.tez.min.partition.factor=0.25;\n",
    "    set hive.tez.max.partition.factor=2.0;\n",
    "    set tez.runtime.pipelined.sorter.lazy-allocate.memory=true;\n",
    "    set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "    '''\n",
    "\n",
    "    create_accum_query = '''\n",
    "    CREATE TABLE IF NOT EXISTS `user_kposminin.id_feat_accum`(\n",
    "          `id` string, \n",
    "          `load_src` string, \n",
    "          `first_id_ymd` string, \n",
    "          `last_id_ymd` string, \n",
    "          `ymd_cnt` int, \n",
    "          `urlfr_cnt` bigint, -- `cnt` bigint, \n",
    "          `visits_cnt` bigint, \n",
    "          `hits` bigint, \n",
    "          `emailru_sum` bigint, \n",
    "          `mobile_sum` double, \n",
    "          `vk_sum` double, \n",
    "          `social_sum` double, \n",
    "          `work_hours_hits_sum` double, \n",
    "          `avg_hour_sum_sq` bigint, \n",
    "          `avg_hour_sum` bigint, \n",
    "          `max_score1` double, \n",
    "          `max_score2` double, \n",
    "          `max_score3` double, \n",
    "          `max_score4` double, \n",
    "          `max_score5` double, \n",
    "          `max_score6` double, \n",
    "          `min_score1` double, \n",
    "          `min_score2` double, \n",
    "          `min_score3` double, \n",
    "          `min_score4` double, \n",
    "          `min_score5` double, \n",
    "          `min_score6` double, \n",
    "          `sum_score1` double, \n",
    "          `sum_score2` double, \n",
    "          `sum_score3` double, \n",
    "          `sum_score4` double, \n",
    "          `sum_score5` double, \n",
    "          `sum_score6` double, \n",
    "          `cnt_score1` int, \n",
    "          `cnt_score2` int, \n",
    "          `cnt_score3` int, \n",
    "          `cnt_score4` int, \n",
    "          `cnt_score5` int, \n",
    "          `cnt_score6` int, \n",
    "          `good_urlfr_sum_score1` double, \n",
    "          `good_urlfr_sum_score2` double, \n",
    "          `good_urlfr_sum_score3` double,\n",
    "          `good_urlfr_sum_score4` double,\n",
    "          `good_urlfr_sum_score5` double,\n",
    "          `good_urlfr_sum_score6` double)\n",
    "    partitioned by (\n",
    "          `first_calc_ymd` string, \n",
    "          `last_calc_ymd` string      \n",
    "          )\n",
    "    ;\n",
    "\n",
    "    '''\n",
    "\n",
    "    feat_1d_query_pattern = '''\n",
    "\n",
    "    -- #ymd. Id_feats 1 day calc\n",
    "    with mymd as \n",
    "     (select\n",
    "       target,\n",
    "       max(ymd) as max_ymd\n",
    "      from\n",
    "       user_kposminin.urlfr_scores\n",
    "      where \n",
    "        ymd < date_add('#ymd',-3)\n",
    "      group by target\n",
    "     )\n",
    "\n",
    "    insert overwrite table user_kposminin.id_feat_accum partition (first_calc_ymd, last_calc_ymd)\n",
    "    select \n",
    "     id,\n",
    "     load_src, \n",
    "     ymd as first_id_ymd, \n",
    "     ymd as last_id_ymd,\n",
    "     1 as ymd_cnt,\n",
    "     count(distinct urlfr) as urlfr_cnt,\n",
    "     count(urlfr) as visits_cnt,\n",
    "     sum(cnt) as hits,\n",
    "     sum(if(urlfr like 'e.mail.ru%',1,0)) as emailru_sum,\n",
    "     sum(if(urlfr like 'm.%',1,0)) as mobile_sum,\n",
    "     sum(if(urlfr rlike '^(m\\\\.)?vk.com', 1, 0)) as vk_sum,\n",
    "     sum(if(urlfr rlike '^(m\\\\.)?vk.com' or urlfr rlike '^(m\\\\.)?(ok|odnoklassniki)\\\\.ru' or urlfr rlike '^(m\\\\.)?my.mail.ru',1,0)) as social_sum,\n",
    "     sum(if(avg_hour >= 9 and avg_hour <= 20,cnt,0)) as work_hours_hits_sum,\n",
    "     sum( avg_hour * avg_hour) as avg_hour_sum_sq,\n",
    "     sum(avg_hour) as avg_hour_sum,\n",
    "     max(score1) as max_score1,\n",
    "     max(score2) as max_score2,\n",
    "     max(score3) as max_score3,\n",
    "     max(score4) as max_score4,\n",
    "     max(score5) as max_score5,\n",
    "     max(score6) as max_score6,\n",
    "     min(score1) as min_score1,\n",
    "     min(score2) as min_score2,\n",
    "     min(score3) as min_score3,\n",
    "     min(score4) as min_score4,\n",
    "     min(score5) as min_score5,\n",
    "     min(score6) as min_score6,\n",
    "     sum(score1) as sum_score1,\n",
    "     sum(score2) as sum_score2,\n",
    "     sum(score3) as sum_score3,\n",
    "     sum(score4) as sum_score4, \n",
    "     sum(score5) as sum_score5,\n",
    "     sum(score6) as sum_score6, \n",
    "     count(score1) as cnt_score1,\n",
    "     count(score2) as cnt_score2,\n",
    "     count(score3) as cnt_score3,\n",
    "     count(score4) as cnt_score4, \n",
    "     count(score5) as cnt_score5,\n",
    "     count(score6) as cnt_score6, \n",
    "     count( if(score1 > -0.2, urlfr,Null)) as good_urlfr_sum_score1,\n",
    "     count( if(score2 > -9, urlfr,Null)) as good_urlfr_sum_score2,\n",
    "     count( if(score3 > -9, urlfr,Null)) as good_urlfr_sum_score3,\n",
    "     count( if(score4 > -2, urlfr,Null)) as good_urlfr_sum_score4,\n",
    "     count( if(score5 > -9, urlfr,Null)) as good_urlfr_sum_score5,\n",
    "     count( if(score6 > -0.2, urlfr,Null)) as good_urlfr_sum_score6,\n",
    "     '#ymd' as first_calc_ymd, \n",
    "     '#ymd' as last_calc_ymd\n",
    "\n",
    "    from\n",
    "     (select\n",
    "        v.id,\n",
    "        'LI.02' as load_src, -- !!!! bug\n",
    "        v.ymd,\n",
    "        v.urlfr,\n",
    "        unix_timestamp(v.ymd, 'yyyy-MM-dd')/60/60 + v.avg_hour  as time_h,\n",
    "        1 as time_std,\n",
    "        v.cnt as cnt,\n",
    "        v.avg_hour as avg_hour,\n",
    "        t1.score as score1,\n",
    "        t2.score as score2,\n",
    "        t3.score as score3,\n",
    "        t4.score as score4,\n",
    "        t5.score as score5,\n",
    "        log((t2.cnt_positive + 0.1)/(t3.cnt_positive - t2.cnt_positive + 0.1)) as score6\n",
    "      from\n",
    "        user_kposminin.ccall_visits v\n",
    "        left join (\n",
    "            select urlfr,score\n",
    "              from mymd td\n",
    "             inner join user_kposminin.urlfr_scores t on t.target = td.target and t.ymd = td.max_ymd\n",
    "             where td.target = 'ccall_tinkoff_approve_from_fullapp'\n",
    "        ) t1 on t1.urlfr = v.urlfr\n",
    "        left join (\n",
    "            select urlfr,score,positive as cnt_positive\n",
    "              from mymd td\n",
    "             inner join user_kposminin.urlfr_scores t on t.target = td.target and t.ymd = td.max_ymd\n",
    "             where td.target = 'tinkoff_platinum_approved_application03@tinkoff_action' \n",
    "        ) t2 on t2.urlfr = v.urlfr\n",
    "        left join (\n",
    "            select urlfr,score,positive as cnt_positive\n",
    "              from mymd td\n",
    "             inner join user_kposminin.urlfr_scores t on t.target = td.target and t.ymd = td.max_ymd\n",
    "             where td.target = 'tinkoff_platinum_complete_application03@tinkoff_action'\n",
    "        ) t3 on t3.urlfr = v.urlfr\n",
    "        left join (\n",
    "            select urlfr,score\n",
    "              from mymd td\n",
    "             inner join user_kposminin.urlfr_scores t on t.target = td.target and t.ymd = td.max_ymd\n",
    "             where td.target = 'tinkoff_LON_CCR_default'\n",
    "        ) t4 on t4.urlfr = v.urlfr\n",
    "        left join (\n",
    "            select urlfr,score\n",
    "              from mymd td\n",
    "             inner join user_kposminin.urlfr_scores t on t.target = td.target and t.ymd = td.max_ymd\n",
    "             where td.target = 'tinkoff_platinum_approved_application03_1m'\n",
    "        ) t5 on t5.urlfr = v.urlfr\n",
    "      where \n",
    "        v.ymd = '#ymd' \n",
    "     ) a \n",
    "    group by\n",
    "      id,load_src,ymd\n",
    "    ;\n",
    "    '''\n",
    "\n",
    "    accumulator_merge_pattern = '''\n",
    "\n",
    "    insert overwrite table user_kposminin.id_feat_accum partition (first_calc_ymd,last_calc_ymd)\n",
    "    select\n",
    "      nvl(a.id,b.id) as id,\n",
    "      nvl(a.load_src,b.load_src) as load_src,\n",
    "      least(a.first_id_ymd,b.first_id_ymd) as first_id_ymd,\n",
    "      greatest(a.last_id_ymd,b.last_id_ymd) as last_id_ymd,\n",
    "      nvl(a.ymd_cnt,0) + nvl(b.ymd_cnt,0) as ymd_cnt,\n",
    "      nvl(a.urlfr_cnt,0) + nvl(b.urlfr_cnt,0) as urlfr_cnt,\n",
    "      nvl(a.visits_cnt,0) + nvl(b.visits_cnt,0) as visits_cnt,\n",
    "      nvl(a.hits,0) + nvl(b.hits,0) as hits,\n",
    "      nvl(a.emailru_sum,0) + nvl(b.emailru_sum,0) as emailru_sum,\n",
    "      nvl(a.mobile_sum,0) + nvl(b.mobile_sum,0) as mobile_sum,\n",
    "      nvl(a.vk_sum,0) + nvl(b.vk_sum,0) as vk_sum,\n",
    "      nvl(a.social_sum,0) + nvl(b.social_sum,0) as social_sum,\n",
    "      nvl(a.work_hours_hits_sum,0) + nvl(b.work_hours_hits_sum,0) as work_hours_hits_sum,\n",
    "      nvl(a.avg_hour_sum_sq,0) + nvl(b.avg_hour_sum_sq,0) as avg_hour_sum_sq,\n",
    "      nvl(a.avg_hour_sum,0) + nvl(b.avg_hour_sum,0) as avg_hour_sum,\n",
    "      greatest(a.max_score1,b.max_score1) as max_score1,\n",
    "      greatest(a.max_score2,b.max_score2) as max_score2,\n",
    "      greatest(a.max_score3,b.max_score3) as max_score3,\n",
    "      greatest(a.max_score4,b.max_score4) as max_score4,\n",
    "      greatest(a.max_score5,b.max_score5) as max_score5,\n",
    "      greatest(a.max_score6,b.max_score6) as max_score6,\n",
    "      least(a.min_score1, b.min_score1) as min_score1,\n",
    "      least(a.min_score2, b.min_score2) as min_score2,\n",
    "      least(a.min_score3, b.min_score3) as min_score3,\n",
    "      least(a.min_score4, b.min_score4) as min_score4,\n",
    "      least(a.min_score5, b.min_score5) as min_score5,\n",
    "      least(a.min_score6, b.min_score6) as min_score6,\n",
    "      nvl(a.sum_score1,0) + nvl(b.sum_score1,0) as sum_score1,\n",
    "      nvl(a.sum_score2,0) + nvl(b.sum_score2,0) as sum_score2,\n",
    "      nvl(a.sum_score3,0) + nvl(b.sum_score3,0) as sum_score3,\n",
    "      nvl(a.sum_score4,0) + nvl(b.sum_score4,0) as sum_score4,\n",
    "      nvl(a.sum_score5,0) + nvl(b.sum_score5,0) as sum_score5,\n",
    "      nvl(a.sum_score6,0) + nvl(b.sum_score6,0) as sum_score6,\n",
    "      nvl(a.cnt_score1,0) + nvl(b.cnt_score1,0) as cnt_score1,\n",
    "      nvl(a.cnt_score2,0) + nvl(b.cnt_score2,0) as cnt_score2,\n",
    "      nvl(a.cnt_score3,0) + nvl(b.cnt_score3,0) as cnt_score3,\n",
    "      nvl(a.cnt_score4,0) + nvl(b.cnt_score4,0) as cnt_score4,\n",
    "      nvl(a.cnt_score5,0) + nvl(b.cnt_score5,0) as cnt_score5,\n",
    "      nvl(a.cnt_score6,0) + nvl(b.cnt_score6,0) as cnt_score6,\n",
    "      nvl(a.good_urlfr_sum_score1,0) + nvl(b.good_urlfr_sum_score1,0) as good_urlfr_sum_score1,\n",
    "      nvl(a.good_urlfr_sum_score2,0) + nvl(b.good_urlfr_sum_score2,0) as good_urlfr_sum_score2,\n",
    "      nvl(a.good_urlfr_sum_score3,0) + nvl(b.good_urlfr_sum_score3,0) as good_urlfr_sum_score3,\n",
    "      nvl(a.good_urlfr_sum_score4,0) + nvl(b.good_urlfr_sum_score4,0) as good_urlfr_sum_score4,\n",
    "      nvl(a.good_urlfr_sum_score5,0) + nvl(b.good_urlfr_sum_score5,0) as good_urlfr_sum_score5,\n",
    "      nvl(a.good_urlfr_sum_score6,0) + nvl(b.good_urlfr_sum_score6,0) as good_urlfr_sum_score6,\n",
    "      '#new_first_calc_ymd' as first_calc_ymd,\n",
    "      '#new_last_calc_ymd' as last_calc_ymd\n",
    "    from \n",
    "      (select * from user_kposminin.id_feat_accum a where a.first_calc_ymd = '#a_first_calc_ymd' and a.last_calc_ymd = '#a_last_calc_ymd') a\n",
    "      full join (select * from user_kposminin.id_feat_accum b where b.first_calc_ymd = '#b_first_calc_ymd' and b.last_calc_ymd = '#b_last_calc_ymd') b \n",
    "        on a.id = b.id and a.load_src = b.load_src\n",
    "    ;\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    clear_partition_query = '''\n",
    "    alter table user_kposminin.id_feat_accum drop partition (first_calc_ymd = '#first_calc_ymd', last_calc_ymd = '#last_calc_ymd');\n",
    "    '''\n",
    "\n",
    "    create_feat_table_query = '''\n",
    "\n",
    "    create table user_kposminin.id_feat_ccall as\n",
    "    select \n",
    "         a.phone_mobile, \n",
    "         count(distinct a.id) as id_cnt,\n",
    "         count(distinct acc.id) as acc_id_cnt,\n",
    "         a.call_ymd as call_ymd,\n",
    "         max(a.approve) as approve,\n",
    "         sum(acc.urlfr_cnt) as urlfr_cnt,\n",
    "         sum(acc.visits_cnt) as visits_cnt, \n",
    "         sum(acc.hits) as hits,\n",
    "         max(acc.max_score1) as max_score1,\n",
    "         sum(acc.sum_score1) / sum(acc.cnt_score1) as avg_score1,\n",
    "         min(acc.min_score1) as min_score1,\n",
    "         max(acc.max_score2) as max_score2,\n",
    "         sum(acc.sum_score2) / sum(acc.cnt_score2) as avg_score2,\n",
    "         min(acc.min_score2) as min_score2,\n",
    "         max(acc.max_score3) as max_score3,\n",
    "         sum(acc.sum_score3) / sum(acc.cnt_score3) as avg_score3,\n",
    "         min(acc.min_score3) as min_score3,\n",
    "         max(acc.max_score4) as max_score4,\n",
    "         sum(acc.sum_score4) / sum(acc.cnt_score4) as avg_score4,\n",
    "         min(acc.min_score4) as min_score4,\n",
    "         max(acc.max_score5) as max_score5,\n",
    "         sum(acc.sum_score5) / sum(acc.cnt_score4) as avg_score5,\n",
    "         min(acc.min_score5) as min_score5,\n",
    "         max(acc.max_score6) as max_score6,\n",
    "         sum(acc.sum_score6) / sum(acc.cnt_score4) as avg_score6,\n",
    "         min(acc.min_score6) as min_score6,\n",
    "         sum(acc.emailru_sum) / sum(acc.visits_cnt) as emailru_share,\n",
    "         sum(acc.mobile_sum) / sum(acc.visits_cnt) as mobile_share,\n",
    "         sum(acc.vk_sum) / sum(acc.visits_cnt) as vk_share,\n",
    "         sum(acc.social_sum) / sum(acc.visits_cnt) as social_share,\n",
    "         sum(acc.work_hours_hits_sum) / sum(acc.hits) as work_hours_hits_share,\n",
    "         sqrt(sum(acc.avg_hour_sum_sq)/(sum(acc.visits_cnt)-1) - power(sum(acc.avg_hour_sum)/(sum(acc.visits_cnt) - 1), 2)) as hour_std,\n",
    "         sum(acc.good_urlfr_sum_score1) / sum(acc.cnt_score1) as good_urlfr_share_score1, \n",
    "         sum(acc.good_urlfr_sum_score2) / sum(acc.cnt_score2) as good_urlfr_share_score2,\n",
    "         sum(acc.good_urlfr_sum_score3) / sum(acc.cnt_score3) as good_urlfr_share_score3, \n",
    "         sum(acc.good_urlfr_sum_score4) / sum(acc.cnt_score4) as good_urlfr_share_score4, \n",
    "         sum(acc.good_urlfr_sum_score5) / sum(acc.cnt_score5) as good_urlfr_share_score5,\n",
    "         sum(acc.good_urlfr_sum_score6) / sum(acc.cnt_score6) as good_urlfr_share_score6,\n",
    "         max(trim(pc.provider)) as mob_provider,\n",
    "         max(r.ind) as ind,\n",
    "         max(r.pop_country_share) as pop_country_share, \n",
    "         max(r.pop_city_share) as pop_city_share, \n",
    "         max(r.population / r.area_sq_km) as density,\n",
    "         max(r.area_sq_km) as area_sq_km,\n",
    "         max(trim(r.federal_district)) as federal_district, \n",
    "         max(r.avg_salary_2015_rub) as avg_salary_2015_rub, \n",
    "         max(r.utc_time_zone_val) as utc_time_zone_val\n",
    "\n",
    "\n",
    "      from\n",
    "         user_kposminin.ccall_aza_id a\n",
    "         inner join user_kposminin.id_feat_accum acc on acc.id = a.id and acc.last_calc_ymd = date_add(a.call_ymd, -1)\n",
    "         left join dds_dic.phone_codes pc on trim(pc.phone_code) = substr(a.phone_mobile,2,9)\n",
    "         left join dds_dic.region_stat r on r.ind = pc.region_id\n",
    "     group by\n",
    "             a.phone_mobile,\n",
    "             a.call_ymd\n",
    "    ;\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, hc = None, n_threads = 10, init_query = True):\n",
    "        import datetime\n",
    "        if(init_query):\n",
    "            self.query = self.init_query + self.create_accum_query\n",
    "        else:\n",
    "            self.query = ''\n",
    "        \n",
    "    def calc_days(self, days, merge = True, clean = True):\n",
    "        ''' Calc 1d feat and accum it for days (datetime.datetime list)'''\n",
    "        days = sorted(days)\n",
    "        acc_first_calc_ymd, acc_last_calc_ymd = [days[0]] * 2\n",
    "        for day in days:\n",
    "            new_first_calc_ymd = min(day,acc_first_calc_ymd)\n",
    "            new_last_calc_ymd  = max(day,acc_last_calc_ymd)\n",
    "            \n",
    "            self.query += self.feat_1d_query_pattern.replace('#ymd',day.strftime('%Y-%m-%d'))\n",
    "            if merge & (days.index(day) > 0):\n",
    "                self.query += (self.accumulator_merge_pattern \n",
    "                       .replace('#a_first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#a_last_calc_ymd', acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_first_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_last_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_first_calc_ymd', new_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_last_calc_ymd',  new_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                               )\n",
    "                if clean & (days.index(day) > 1):\n",
    "                    self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd', acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "                if ((clean == 'full_clean') & (days.index(day) > 1)): \n",
    "                    self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "            acc_first_calc_ymd = new_first_calc_ymd\n",
    "            acc_last_calc_ymd = new_last_calc_ymd\n",
    "    \n",
    "    def calc_day_range(self, first_day = None, last_day = None, n_days = None, merge = True, clean = True):        \n",
    "        assert (first_day is None) + (last_day is None) + (n_days is None) == 1, '''calc_day_range Error:\n",
    "              exactly two of three params must be filled: first_day, last_day, n_days'''.replace('\\n',' ')\n",
    "        if first_day is None:\n",
    "            day_range = [last_day + datetime.timedelta(days = i) for i in range(-n_days + 1,1)]\n",
    "        elif last_day is None:\n",
    "            day_range = [first_day + datetime.timedelta(days = i) for i in range(n_days)]\n",
    "        else:\n",
    "            first_day,last_day = min(first_day,last_day), max(first_day,last_day)\n",
    "            day_range = [first_day + datetime.timedelta(days = i) for i in range((last_day - first_day).days + 1)]\n",
    "        self.calc_days(day_range, merge, clean)\n",
    "        \n",
    "    def get_query(self):\n",
    "        return self.query\n",
    "\n",
    "    def merge_days(self, day_tuples, clean = False):\n",
    "        ''' day_tuples is a list of (first_day,last_day) to merge'''\n",
    "        day_tuples = sorted(day_tuples)\n",
    "        acc_first_calc_ymd, acc_last_calc_ymd = day_tuples[0]\n",
    "        first = True\n",
    "        for (first_day,last_day) in day_tuples[1:]:\n",
    "            new_first_calc_ymd = min(first_day,acc_first_calc_ymd)\n",
    "            new_last_calc_ymd  = max(last_day,acc_last_calc_ymd)\n",
    "            self.query += (self.accumulator_merge_pattern \n",
    "                       .replace('#a_first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#a_last_calc_ymd',   acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_first_calc_ymd', first_day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_last_calc_ymd',   last_day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_first_calc_ymd', new_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_last_calc_ymd',   new_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                               )\n",
    "            if (not clean is False) & ((not first) or (clean == 'full_clean')):\n",
    "                self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd',   acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "            if (clean == 'full_clean'): \n",
    "                self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', first_day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd',   last_day.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "            acc_first_calc_ymd = new_first_calc_ymd\n",
    "            acc_last_calc_ymd = new_last_calc_ymd\n",
    "            first = False\n",
    "            \n",
    "    def calc_full_feat(self):\n",
    "        c.query += self.create_feat_table_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! nohup /opt/anaconda/bin/python cred_scor_feat_table_calc_4.py 2016-12-01 2016-12-15 > cred_scor_feat_table_calc_27.log 2>&1 &\n",
    "#os.popen('beeline -u \"jdbc:hive2://ds-hadoop-cs01p:10000/\" -n kposminin -e \"' + ' '.join(c.get_query().split(';')[30].split('\\n')[5:])+ '\"').read() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обсчитываем 2016 год по дням и собираем в пачки по 15 дней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    c = calc_cred_score(hc)\n",
    "    c.calc_day_range(first_day = datetime.datetime(2016,i,1) ,last_day = datetime.datetime(2016,i,15),merge = True, clean = True)\n",
    "    print(c.get_query())\n",
    "    print('-'*100)\n",
    "    \n",
    "    c = calc_cred_score(hc)\n",
    "    c.calc_day_range(first_day = datetime.datetime(2016,i,16) ,last_day = datetime.datetime(2016,i+1,1) - datetime.timedelta(days=1),merge = True, clean = True)\n",
    "    print(c.get_query())\n",
    "    print('-'*500)\n",
    "\n",
    "    def calc_days(self, days, merge = True, clean = True):\n",
    "        ''' Calc 1d feat and accum it for days (datetime.datetime list)'''\n",
    "        days = sorted(days)\n",
    "        acc_first_calc_ymd, acc_last_calc_ymd = [days[0]] * 2\n",
    "        for day in days:\n",
    "            new_first_calc_ymd = min(day,acc_first_calc_ymd)\n",
    "            new_last_calc_ymd  = max(day,acc_last_calc_ymd)\n",
    "            \n",
    "            self.query += self.feat_1d_query_pattern.replace('#ymd',day.strftime('%Y-%m-%d'))\n",
    "            if merge & (days.index(day) > 0):\n",
    "                self.query += (self.accumulator_merge_pattern \n",
    "                       .replace('#a_first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#a_last_calc_ymd', acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_first_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#b_last_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_first_calc_ymd', new_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#new_last_calc_ymd',  new_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                               )\n",
    "                if clean & (days.index(day) > 1):\n",
    "                    self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', acc_first_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd', acc_last_calc_ymd.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "                if ((clean == 'full_clean') & (days.index(day) > 1)): \n",
    "                    self.query += (self.clear_partition_query \n",
    "                       .replace('#first_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                       .replace('#last_calc_ymd', day.strftime('%Y-%m-%d'))\n",
    "                                  )\n",
    "            acc_first_calc_ymd = new_first_calc_ymd\n",
    "            acc_last_calc_ymd = new_last_calc_ymd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполняем промежутки по 15 дней. В итоге весь год посчитан. История за 2 месяца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "day_tuples = sorted([(datetime.datetime(2016,i,1),datetime.datetime(2016,i,15)) for i in range(1,13)] + \n",
    "             [(datetime.datetime(2016,i,16),datetime.datetime(2016,i+1,1) - datetime.timedelta(days=1)) for i in range(1,12)] + \n",
    "             [(datetime.datetime(2016,12,16),datetime.datetime(2016,12,31))])\n",
    "import datetime\n",
    "for i in range(len(day_tuples) - 4):\n",
    "    c = calc_cred_score(hc, init_query = False)\n",
    "    c.merge_days(day_tuples[i:i+4], clean = 'clean')\n",
    "    day = day_tuples[i+3][1] + datetime.timedelta(days=1)\n",
    "    inner_day_tuple = [(min([e[0] for e in day_tuples[i:i+4]]),max([e[1] for e in day_tuples[i:i+4]]))]\n",
    "    while day < day_tuples[i+4][1]:\n",
    "        inner_day_tuple.append((day,day))\n",
    "        day += datetime.timedelta(days=1)\n",
    "    c.merge_days(inner_day_tuple, clean = False)\n",
    "    #print(c.get_query())\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    create table user_kposminin.id_feat_ccall as\n",
      "    select \n",
      "         a.phone_mobile, \n",
      "         count(distinct a.id) as id_cnt,\n",
      "         count(distinct acc.id) as acc_id_cnt,\n",
      "         a.call_ymd as call_ymd,\n",
      "         max(a.approve) as approve,\n",
      "         sum(acc.urlfr_cnt) as urlfr_cnt,\n",
      "         sum(acc.visits_cnt) as visits_cnt, \n",
      "         sum(acc.hits) as hits,\n",
      "         max(acc.max_score1) as max_score1,\n",
      "         sum(acc.sum_score1) / sum(acc.cnt_score1) as avg_score1,\n",
      "         min(acc.min_score1) as min_score1,\n",
      "         max(acc.max_score2) as max_score2,\n",
      "         sum(acc.sum_score2) / sum(acc.cnt_score2) as avg_score2,\n",
      "         min(acc.min_score2) as min_score2,\n",
      "         max(acc.max_score3) as max_score3,\n",
      "         sum(acc.sum_score3) / sum(acc.cnt_score3) as avg_score3,\n",
      "         min(acc.min_score3) as min_score3,\n",
      "         max(acc.max_score4) as max_score4,\n",
      "         sum(acc.sum_score4) / sum(acc.cnt_score4) as avg_score4,\n",
      "         min(acc.min_score4) as min_score4,\n",
      "         max(acc.max_score5) as max_score5,\n",
      "         sum(acc.sum_score5) / sum(acc.cnt_score4) as avg_score5,\n",
      "         min(acc.min_score5) as min_score5,\n",
      "         max(acc.max_score6) as max_score6,\n",
      "         sum(acc.sum_score6) / sum(acc.cnt_score4) as avg_score6,\n",
      "         min(acc.min_score6) as min_score6,\n",
      "         sum(acc.emailru_sum) / sum(acc.visits_cnt) as emailru_share,\n",
      "         sum(acc.mobile_sum) / sum(acc.visits_cnt) as mobile_share,\n",
      "         sum(acc.vk_sum) / sum(acc.visits_cnt) as vk_share,\n",
      "         sum(acc.social_sum) / sum(acc.visits_cnt) as social_share,\n",
      "         sum(acc.work_hours_hits_sum) / sum(acc.hits) as work_hours_hits_share,\n",
      "         sqrt(sum(acc.avg_hour_sum_sq)/(sum(acc.visits_cnt)-1) - power(sum(acc.avg_hour_sum)/(sum(acc.visits_cnt) - 1), 2)) as hour_std,\n",
      "         sum(acc.good_urlfr_sum_score1) / sum(acc.cnt_score1) as good_urlfr_share_score1, \n",
      "         sum(acc.good_urlfr_sum_score2) / sum(acc.cnt_score2) as good_urlfr_share_score2,\n",
      "         sum(acc.good_urlfr_sum_score3) / sum(acc.cnt_score3) as good_urlfr_share_score3, \n",
      "         sum(acc.good_urlfr_sum_score4) / sum(acc.cnt_score4) as good_urlfr_share_score4, \n",
      "         sum(acc.good_urlfr_sum_score5) / sum(acc.cnt_score5) as good_urlfr_share_score5,\n",
      "         sum(acc.good_urlfr_sum_score6) / sum(acc.cnt_score6) as good_urlfr_share_score6,\n",
      "         max(trim(pc.provider)) as mob_provider,\n",
      "         max(r.ind) as ind,\n",
      "         max(r.pop_country_share) as pop_country_share, \n",
      "         max(r.pop_city_share) as pop_city_share, \n",
      "         max(r.population / r.area_sq_km) as density,\n",
      "         max(r.area_sq_km) as area_sq_km,\n",
      "         max(trim(r.federal_district)) as federal_district, \n",
      "         max(r.avg_salary_2015_rub) as avg_salary_2015_rub, \n",
      "         max(r.utc_time_zone_val) as utc_time_zone_val\n",
      "\n",
      "\n",
      "      from\n",
      "         user_kposminin.ccall_aza_id a\n",
      "         inner join user_kposminin.id_feat_accum acc on acc.id = a.id and acc.last_calc_ymd = date_add(a.call_ymd, -1)\n",
      "         left join dds_dic.phone_codes pc on trim(pc.phone_code) = substr(a.phone_mobile,2,9)\n",
      "         left join dds_dic.region_stat r on r.ind = pc.region_id\n",
      "     group by\n",
      "             a.phone_mobile,\n",
      "             a.call_ymd\n",
      "    ;\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "query = '''create table user_kposminin.ccall_aza_id as \n",
    "select distinct phone_mobile, approve, call_ymd, id from user_kposminin.ccall_visits\n",
    ";'''\n",
    "\n",
    "c = calc_cred_score(hc, init_query = False)\n",
    "c.calc_full_feat()\n",
    "print(c.get_query())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Таблица построена. Проверяем работоспособность - строим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "\n",
    "sc.stop()\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 2)\n",
    "        .set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "        .set('spark.driver.memory','4g')\n",
    "        .set(\"spark.executor.memory\", '2g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 1048)\n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def metrics(y_true,y_score,lift = None, return_str = False):\n",
    "    import sklearn\n",
    "    import collections\n",
    "    \n",
    "    if True:\n",
    "        \n",
    "        res = collections.OrderedDict()\n",
    "        samp_size = len(y_true)\n",
    "        res['Sample size'] = samp_size\n",
    "        res['Posit share'] = sum(y_true) * 1./ samp_size\n",
    "        res['Sample size'] = len(y_true)\n",
    "        res['AUC ROC'] = sklearn.metrics.roc_auc_score(y_true = y_true, y_score = y_score)\n",
    "        res['AUC PR'] = sklearn.metrics.average_precision_score( y_true,  y_score)\n",
    "        res['Log loss'] = sklearn.metrics.log_loss(y_true = y_true, y_pred = y_score)\n",
    "        if lift:\n",
    "            predictions_and_labels = sorted(zip(y_score,y_true), key = lambda e:-e[0])\n",
    "            for l in lift:\n",
    "                res['Lift ' + str(l)] = sum([e[1] for e in predictions_and_labels[:int(l * samp_size)]]) * 1. / int(l * samp_size) / res['Posit share']                \n",
    "        if return_str:\n",
    "            res = '\\n'.join(['{:<12}: {:.5f}'.format(k,v) for (k,v) in res.items()]) + '.'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(clf, X, y, folds = 5, metrics = 'roc_auc,pr_auc'):\n",
    "    '''calc cross-validation metrics for clf classfier (actually LightGBM classifier) on X,y data '''\n",
    "    assert X.shape[0] == len(y), 'X and y lengths doesnt match'\n",
    "    idx = range(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    fold_idx = []\n",
    "    for i in range(folds):\n",
    "        fold_idx.append(idx[i*len(idx)/folds:(i+1)*len(idx)/folds])\n",
    "    res = {k:[] for k in metrics.split(',')}\n",
    "    \n",
    "    for i in range(folds):\n",
    "        train_idx = reduce(lambda x,y: x+y,(fold_idx[:i] + fold_idx[(i+1):]))\n",
    "        valid_idx = fold_idx[i]\n",
    "        \n",
    "        clf.fit(X[train_idx],y[train_idx])\n",
    "        valid_pred = clf.predict_proba(X[valid_idx])[:,1]\n",
    "        \n",
    "        if('roc_auc' in metrics):\n",
    "            res['roc_auc'].append(\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = y[valid_idx],\n",
    "                  y_score = valid_pred\n",
    "                )\n",
    "            )\n",
    "        if('pr_auc' in metrics):\n",
    "            res['pr_auc'].append(\n",
    "                sklearn.metrics.average_precision_score(\n",
    "                  y_true = y[valid_idx],\n",
    "                  y_score = valid_pred\n",
    "                )\n",
    "            )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import os\n",
    "import sklearn, sklearn.cross_validation\n",
    "from pylightgbm.models import GBMClassifier\n",
    "\n",
    "federal_districts = [u'ЦФО',u'СЗФО',u'ЮФО',u'СКФО',u'ПФО',u'УФО',u'СФО',u'ДВФО'] # todo\n",
    "\n",
    "def encode(v, classes, default_value = -1):\n",
    "    '''Encode text value v which values are from classes list. Returns v index and -1 if it wasn't found in the list.'''\n",
    "    try:\n",
    "        return classes.index(v)\n",
    "    except ValueError:\n",
    "        return default_value\n",
    "\n",
    "\n",
    "exec_path = \"/opt/share/LightGBM-master/lightgbm\"\n",
    "os.environ[\"LIGHTGBM_EXEC\"] = exec_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_train.loc[:,'mob_provider'] = le.fit_transform(df_train['mob_provider'])\n",
    "df_test.loc[:,'mob_provider']  = le.fit(df_test['mob_provider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((333259, 47), (28946, 47))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = (hc.sql('select * from user_kposminin.id_feat_ccall')        \n",
    "        .toPandas()\n",
    "         )\n",
    "\n",
    "df_all.loc[:,'federal_district'] = df_all.federal_district.map(lambda v:encode(v, federal_districts))\n",
    "df_train = df_all[df_all['call_ymd'] <  '2016-12-01']\n",
    "df_test  = df_all[df_all['call_ymd'] >= '2016-12-01']\n",
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.iloc[0]\n",
    "feats, label = df_train.columns[5:], 'approve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 4.908701 seconds\n",
      "[LightGBM] [Info] Number of postive: 121590, number of negative: 211669\n",
      "[LightGBM] [Info] Number of data: 333259, number of features: 41\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Iteration:1, valid_1 auc : 0.655998\n",
      "[LightGBM] [Info] 0.305862 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Iteration:2, valid_1 auc : 0.659003\n",
      "[LightGBM] [Info] 0.619111 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Iteration:3, valid_1 auc : 0.660028\n",
      "[LightGBM] [Info] 0.924887 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Iteration:4, valid_1 auc : 0.662381\n",
      "[LightGBM] [Info] 1.205869 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Iteration:5, valid_1 auc : 0.663368\n",
      "[LightGBM] [Info] 1.505006 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Iteration:6, valid_1 auc : 0.664105\n",
      "[LightGBM] [Info] 1.795276 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Iteration:7, valid_1 auc : 0.664728\n",
      "[LightGBM] [Info] 2.081688 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Iteration:8, valid_1 auc : 0.665021\n",
      "[LightGBM] [Info] 2.390465 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Iteration:9, valid_1 auc : 0.665552\n",
      "[LightGBM] [Info] 2.702215 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Iteration:10, valid_1 auc : 0.665763\n",
      "[LightGBM] [Info] 3.012677 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Iteration:11, valid_1 auc : 0.666707\n",
      "[LightGBM] [Info] 3.301747 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Iteration:12, valid_1 auc : 0.667057\n",
      "[LightGBM] [Info] 3.618776 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Iteration:13, valid_1 auc : 0.667195\n",
      "[LightGBM] [Info] 3.920179 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Iteration:14, valid_1 auc : 0.667444\n",
      "[LightGBM] [Info] 4.215409 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Iteration:15, valid_1 auc : 0.668085\n",
      "[LightGBM] [Info] 4.513764 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Iteration:16, valid_1 auc : 0.668293\n",
      "[LightGBM] [Info] 4.814068 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Iteration:17, valid_1 auc : 0.668498\n",
      "[LightGBM] [Info] 5.256896 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Iteration:18, valid_1 auc : 0.668764\n",
      "[LightGBM] [Info] 5.779801 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Iteration:19, valid_1 auc : 0.668994\n",
      "[LightGBM] [Info] 6.277839 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Iteration:20, valid_1 auc : 0.669274\n",
      "[LightGBM] [Info] 6.705349 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Iteration:21, valid_1 auc : 0.669424\n",
      "[LightGBM] [Info] 7.065504 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Iteration:22, valid_1 auc : 0.669574\n",
      "[LightGBM] [Info] 7.410722 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Iteration:23, valid_1 auc : 0.669617\n",
      "[LightGBM] [Info] 7.850202 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Iteration:24, valid_1 auc : 0.669790\n",
      "[LightGBM] [Info] 8.223671 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Iteration:25, valid_1 auc : 0.670133\n",
      "[LightGBM] [Info] 8.538230 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Iteration:26, valid_1 auc : 0.670220\n",
      "[LightGBM] [Info] 8.885898 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Iteration:27, valid_1 auc : 0.670563\n",
      "[LightGBM] [Info] 9.398133 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Iteration:28, valid_1 auc : 0.670611\n",
      "[LightGBM] [Info] 9.902792 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Iteration:29, valid_1 auc : 0.670826\n",
      "[LightGBM] [Info] 10.404552 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Iteration:30, valid_1 auc : 0.670950\n",
      "[LightGBM] [Info] 10.879105 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Iteration:31, valid_1 auc : 0.670997\n",
      "[LightGBM] [Info] 11.241021 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Iteration:32, valid_1 auc : 0.671071\n",
      "[LightGBM] [Info] 11.680195 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Iteration:33, valid_1 auc : 0.671347\n",
      "[LightGBM] [Info] 12.068000 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Iteration:34, valid_1 auc : 0.671447\n",
      "[LightGBM] [Info] 12.400603 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Iteration:35, valid_1 auc : 0.671630\n",
      "[LightGBM] [Info] 12.705349 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Iteration:36, valid_1 auc : 0.671672\n",
      "[LightGBM] [Info] 13.113059 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Iteration:37, valid_1 auc : 0.671756\n",
      "[LightGBM] [Info] 13.654351 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Iteration:38, valid_1 auc : 0.671873\n",
      "[LightGBM] [Info] 14.003745 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Iteration:39, valid_1 auc : 0.672036\n",
      "[LightGBM] [Info] 14.312852 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Iteration:40, valid_1 auc : 0.672168\n",
      "[LightGBM] [Info] 14.631430 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Iteration:41, valid_1 auc : 0.672321\n",
      "[LightGBM] [Info] 14.938873 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Iteration:42, valid_1 auc : 0.672413\n",
      "[LightGBM] [Info] 15.180826 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Iteration:43, valid_1 auc : 0.672465\n",
      "[LightGBM] [Info] 15.425397 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Iteration:44, valid_1 auc : 0.672529\n",
      "[LightGBM] [Info] 15.687639 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Iteration:45, valid_1 auc : 0.672587\n",
      "[LightGBM] [Info] 15.938276 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Iteration:46, valid_1 auc : 0.672630\n",
      "[LightGBM] [Info] 16.216105 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Iteration:47, valid_1 auc : 0.672695\n",
      "[LightGBM] [Info] 16.480884 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Iteration:48, valid_1 auc : 0.672772\n",
      "[LightGBM] [Info] 16.717460 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Iteration:49, valid_1 auc : 0.672754\n",
      "[LightGBM] [Info] 16.984661 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Iteration:50, valid_1 auc : 0.672787\n",
      "[LightGBM] [Info] 17.400865 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Iteration:51, valid_1 auc : 0.672859\n",
      "[LightGBM] [Info] 17.777872 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Iteration:52, valid_1 auc : 0.672906\n",
      "[LightGBM] [Info] 18.106213 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Iteration:53, valid_1 auc : 0.673037\n",
      "[LightGBM] [Info] 18.666008 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Iteration:54, valid_1 auc : 0.673345\n",
      "[LightGBM] [Info] 18.959826 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Iteration:55, valid_1 auc : 0.673524\n",
      "[LightGBM] [Info] 19.199473 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Iteration:56, valid_1 auc : 0.673541\n",
      "[LightGBM] [Info] 19.458531 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Iteration:57, valid_1 auc : 0.673604\n",
      "[LightGBM] [Info] 19.738219 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Iteration:58, valid_1 auc : 0.673616\n",
      "[LightGBM] [Info] 19.981601 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Iteration:59, valid_1 auc : 0.673892\n",
      "[LightGBM] [Info] 20.310720 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Iteration:60, valid_1 auc : 0.673823\n",
      "[LightGBM] [Info] 20.569749 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Iteration:61, valid_1 auc : 0.673945\n",
      "[LightGBM] [Info] 20.907291 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Iteration:62, valid_1 auc : 0.674134\n",
      "[LightGBM] [Info] 21.158540 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Iteration:63, valid_1 auc : 0.674281\n",
      "[LightGBM] [Info] 21.397722 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Iteration:64, valid_1 auc : 0.674369\n",
      "[LightGBM] [Info] 21.627507 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Iteration:65, valid_1 auc : 0.674483\n",
      "[LightGBM] [Info] 21.919288 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Iteration:66, valid_1 auc : 0.674548\n",
      "[LightGBM] [Info] 22.258343 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Iteration:67, valid_1 auc : 0.674611\n",
      "[LightGBM] [Info] 22.612110 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Iteration:68, valid_1 auc : 0.674675\n",
      "[LightGBM] [Info] 22.840216 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Iteration:69, valid_1 auc : 0.674759\n",
      "[LightGBM] [Info] 23.100797 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Iteration:70, valid_1 auc : 0.674650\n",
      "[LightGBM] [Info] 23.459015 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Iteration:71, valid_1 auc : 0.674770\n",
      "[LightGBM] [Info] 23.897579 seconds elapsed, finished iteration 71\n",
      "[LightGBM] [Info] Iteration:72, valid_1 auc : 0.674835\n",
      "[LightGBM] [Info] 24.175854 seconds elapsed, finished iteration 72\n",
      "[LightGBM] [Info] Iteration:73, valid_1 auc : 0.674794\n",
      "[LightGBM] [Info] 24.428571 seconds elapsed, finished iteration 73\n",
      "[LightGBM] [Info] Iteration:74, valid_1 auc : 0.674734\n",
      "[LightGBM] [Info] 24.737515 seconds elapsed, finished iteration 74\n",
      "[LightGBM] [Info] Iteration:75, valid_1 auc : 0.674786\n",
      "[LightGBM] [Info] 24.987208 seconds elapsed, finished iteration 75\n",
      "[LightGBM] [Info] Iteration:76, valid_1 auc : 0.674875\n",
      "[LightGBM] [Info] 25.308071 seconds elapsed, finished iteration 76\n",
      "[LightGBM] [Info] Iteration:77, valid_1 auc : 0.674913\n",
      "[LightGBM] [Info] 25.607883 seconds elapsed, finished iteration 77\n",
      "[LightGBM] [Info] Iteration:78, valid_1 auc : 0.674928\n",
      "[LightGBM] [Info] 25.846833 seconds elapsed, finished iteration 78\n",
      "[LightGBM] [Info] Iteration:79, valid_1 auc : 0.674852\n",
      "[LightGBM] [Info] 26.075755 seconds elapsed, finished iteration 79\n",
      "[LightGBM] [Info] Iteration:80, valid_1 auc : 0.674732\n",
      "[LightGBM] [Info] 26.387842 seconds elapsed, finished iteration 80\n",
      "[LightGBM] [Info] Iteration:81, valid_1 auc : 0.674880\n",
      "[LightGBM] [Info] 26.671112 seconds elapsed, finished iteration 81\n",
      "[LightGBM] [Info] Iteration:82, valid_1 auc : 0.674976\n",
      "[LightGBM] [Info] 26.925632 seconds elapsed, finished iteration 82\n",
      "[LightGBM] [Info] Iteration:83, valid_1 auc : 0.674979\n",
      "[LightGBM] [Info] 27.175921 seconds elapsed, finished iteration 83\n",
      "[LightGBM] [Info] Iteration:84, valid_1 auc : 0.675033\n",
      "[LightGBM] [Info] 27.411563 seconds elapsed, finished iteration 84\n",
      "[LightGBM] [Info] Iteration:85, valid_1 auc : 0.675108\n",
      "[LightGBM] [Info] 27.613425 seconds elapsed, finished iteration 85\n",
      "[LightGBM] [Info] Iteration:86, valid_1 auc : 0.675172\n",
      "[LightGBM] [Info] 27.853802 seconds elapsed, finished iteration 86\n",
      "[LightGBM] [Info] Iteration:87, valid_1 auc : 0.675302\n",
      "[LightGBM] [Info] 28.158083 seconds elapsed, finished iteration 87\n",
      "[LightGBM] [Info] Iteration:88, valid_1 auc : 0.675190\n",
      "[LightGBM] [Info] 28.373819 seconds elapsed, finished iteration 88\n",
      "[LightGBM] [Info] Iteration:89, valid_1 auc : 0.675115\n",
      "[LightGBM] [Info] 28.642247 seconds elapsed, finished iteration 89\n",
      "[LightGBM] [Info] Iteration:90, valid_1 auc : 0.675096\n",
      "[LightGBM] [Info] 29.110054 seconds elapsed, finished iteration 90\n",
      "[LightGBM] [Info] Iteration:91, valid_1 auc : 0.675264\n",
      "[LightGBM] [Info] 29.589898 seconds elapsed, finished iteration 91\n",
      "[LightGBM] [Info] Iteration:92, valid_1 auc : 0.675352\n",
      "[LightGBM] [Info] 30.024628 seconds elapsed, finished iteration 92\n",
      "[LightGBM] [Info] Iteration:93, valid_1 auc : 0.675281\n",
      "[LightGBM] [Info] 30.444973 seconds elapsed, finished iteration 93\n",
      "[LightGBM] [Info] Iteration:94, valid_1 auc : 0.675282\n",
      "[LightGBM] [Info] 30.724127 seconds elapsed, finished iteration 94\n",
      "[LightGBM] [Info] Iteration:95, valid_1 auc : 0.675308\n",
      "[LightGBM] [Info] 31.024894 seconds elapsed, finished iteration 95\n",
      "[LightGBM] [Info] Iteration:96, valid_1 auc : 0.675352\n",
      "[LightGBM] [Info] 31.417044 seconds elapsed, finished iteration 96\n",
      "[LightGBM] [Info] Iteration:97, valid_1 auc : 0.675350\n",
      "[LightGBM] [Info] 31.637476 seconds elapsed, finished iteration 97\n",
      "[LightGBM] [Info] Iteration:98, valid_1 auc : 0.675387\n",
      "[LightGBM] [Info] 31.882061 seconds elapsed, finished iteration 98\n",
      "[LightGBM] [Info] Iteration:99, valid_1 auc : 0.675214\n",
      "[LightGBM] [Info] 32.187294 seconds elapsed, finished iteration 99\n",
      "[LightGBM] [Info] Iteration:100, valid_1 auc : 0.675155\n",
      "[LightGBM] [Info] 32.518627 seconds elapsed, finished iteration 100\n",
      "[LightGBM] [Info] Iteration:101, valid_1 auc : 0.675147\n",
      "[LightGBM] [Info] 32.779983 seconds elapsed, finished iteration 101\n",
      "[LightGBM] [Info] Iteration:102, valid_1 auc : 0.675062\n",
      "[LightGBM] [Info] 33.070579 seconds elapsed, finished iteration 102\n",
      "[LightGBM] [Info] Iteration:103, valid_1 auc : 0.674903\n",
      "[LightGBM] [Info] 33.322879 seconds elapsed, finished iteration 103\n",
      "[LightGBM] [Info] Iteration:104, valid_1 auc : 0.674841\n",
      "[LightGBM] [Info] 33.721456 seconds elapsed, finished iteration 104\n",
      "[LightGBM] [Info] Iteration:105, valid_1 auc : 0.674705\n",
      "[LightGBM] [Info] 34.018378 seconds elapsed, finished iteration 105\n",
      "[LightGBM] [Info] Iteration:106, valid_1 auc : 0.674651\n",
      "[LightGBM] [Info] 34.207588 seconds elapsed, finished iteration 106\n",
      "[LightGBM] [Info] Iteration:107, valid_1 auc : 0.674673\n",
      "[LightGBM] [Info] 34.415685 seconds elapsed, finished iteration 107\n",
      "[LightGBM] [Info] Iteration:108, valid_1 auc : 0.674792\n",
      "[LightGBM] [Info] 34.747949 seconds elapsed, finished iteration 108\n",
      "[LightGBM] [Info] Iteration:109, valid_1 auc : 0.674853\n",
      "[LightGBM] [Info] 34.989944 seconds elapsed, finished iteration 109\n",
      "[LightGBM] [Info] Iteration:110, valid_1 auc : 0.674708\n",
      "[LightGBM] [Info] 35.326533 seconds elapsed, finished iteration 110\n",
      "[LightGBM] [Info] Iteration:111, valid_1 auc : 0.674742\n",
      "[LightGBM] [Info] 35.527513 seconds elapsed, finished iteration 111\n",
      "[LightGBM] [Info] Iteration:112, valid_1 auc : 0.674573\n",
      "[LightGBM] [Info] 35.785389 seconds elapsed, finished iteration 112\n",
      "[LightGBM] [Info] Iteration:113, valid_1 auc : 0.674610\n",
      "[LightGBM] [Info] 36.091206 seconds elapsed, finished iteration 113\n",
      "[LightGBM] [Info] Iteration:114, valid_1 auc : 0.674547\n",
      "[LightGBM] [Info] 36.244382 seconds elapsed, finished iteration 114\n",
      "[LightGBM] [Info] Iteration:115, valid_1 auc : 0.674647\n",
      "[LightGBM] [Info] 36.403176 seconds elapsed, finished iteration 115\n",
      "[LightGBM] [Info] Iteration:116, valid_1 auc : 0.674460\n",
      "[LightGBM] [Info] 36.599568 seconds elapsed, finished iteration 116\n",
      "[LightGBM] [Info] Iteration:117, valid_1 auc : 0.674255\n",
      "[LightGBM] [Info] 36.841380 seconds elapsed, finished iteration 117\n",
      "[LightGBM] [Info] Iteration:118, valid_1 auc : 0.674246\n",
      "[LightGBM] [Info] 37.059143 seconds elapsed, finished iteration 118\n",
      "[LightGBM] [Info] Iteration:119, valid_1 auc : 0.674232\n",
      "[LightGBM] [Info] 37.481114 seconds elapsed, finished iteration 119\n",
      "[LightGBM] [Info] Iteration:120, valid_1 auc : 0.674206\n",
      "[LightGBM] [Info] 37.776565 seconds elapsed, finished iteration 120\n",
      "[LightGBM] [Info] Finished training\n"
     ]
    }
   ],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf=50,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 120,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 127,\n",
    "        learning_rate = 0.05,\n",
    "        metric = 'auc',\n",
    "    )\n",
    "#clf.fit(df_train[feats], df_train[label])\n",
    "#df_test['pred'] = clf.predict_proba(df_test[feats])[:,1]\n",
    "\n",
    "clf.fit(df_train[feats], df_train[label], test_data = [(df_test[feats], df_test[label])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Это успех"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics(y_true = df_test[label], y_score = df_test.pred, lift = None, return_str = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = [f for f in feats if not f == 'mob_provider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
