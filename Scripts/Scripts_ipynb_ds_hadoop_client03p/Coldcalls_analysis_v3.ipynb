{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Холодные звонки\n",
    "\n",
    "Тест эффективности скоров текущей модели lookalike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import datetime\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 2).set(\"spark.driver.maxResultSize\", \"1g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_codes = {(int(e.split('\\t')[0]),int(e.split('\\t')[1])) for e in open('phone_codes.txt','r').read().split('\\n')}\n",
    "len(phone_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[931] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_query = '''\n",
    "select v.ymd, v.urlfr, v.id, v.visit_lag, v.label, s.approve_ccall_score, s.la_score, s.cnt_approve, s.cnt_ccall, s.cnt_total\n",
    "from      (select * from user_kposminin.ccalls_visits_1 where ymd = '2016-05-12') v\n",
    "left join user_kposminin.ccalls_scores_3 s on s.urlfr = v.urlfr\n",
    "'''\n",
    "simple_query = '''\n",
    "select v.ymd, v.phone_num, max(v.full_app) as label, collect_set(v.urlfr) as urlfr_set\n",
    "from user_kposminin.ccalls_visits_1 v\n",
    "left semi join user_kposminin.cold_calls_matched_5 m on m.phone_num = v.phone_num and m.ymd = v.ymd and m.havent_started = 0\n",
    "group by v.ymd, v.phone_num\n",
    "'''\n",
    "\n",
    "tf = HashingTF(numFeatures = 10 ** 7)\n",
    "\n",
    "data = hc.sql(simple_query).rdd\n",
    "train_data = data.filter(lambda row: row['ymd'] < '2016-05-16').map(lambda r: LabeledPoint(r.label,tf.transform(r.urlfr_set)))\n",
    "test_data  = data.filter(lambda row: row['ymd'] >= '2016-05-16').map(lambda r: LabeledPoint(r.label,tf.transform(r.urlfr_set)))\n",
    "train_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1457] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_data = train_data.filter(lambda row: row.label == 1 or hash(row) % 5 == 0)\n",
    "sampled_train_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train NaiveBayes model\n",
    "\n",
    "modelNB = NaiveBayes.train(sampled_train_data)\n",
    "\n",
    "def predict_proba_NB(f,model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability. f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Function selects winning class with it probability.\n",
    "    Output: tuple with model selected class number as first element (type int) and it probability as second (type float).\n",
    "    '''\n",
    "    logp = [[i,f.dot(model.theta[i]) + model.pi[i]] for i in range(len(model.theta))] # classes with log probabilities\n",
    "    wi = sorted(logp, key = lambda e:  - e[1])[0][0] #winning index\n",
    "    prob = 1./sum([np.exp(e[1] - logp[wi][1]) for e in logp]) #winning class probability\n",
    "    return wi, prob\n",
    "\n",
    "def predict_proba_NB_2(f, model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability for 2-class classification.\n",
    "    f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Output: probability of class 1 (type float).\n",
    "    '''\n",
    "    if len(model.theta) != 2:\n",
    "        print('Model is NOT a 2-class classifier')\n",
    "        return None\n",
    "    logp = [f.dot(model.theta[i]) + model.pi[i] for i in range(2)]    \n",
    "    return 1./(1. + np.exp(logp[0] - logp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LogisticRegression model\n",
    "modelLR = LogisticRegressionWithSGD.train(sampled_train_data, regType = 'l1',intercept = True,iterations = 100)\n",
    "modelLR.clearThreshold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = train_data.map( lambda lp: pyspark.sql.Row(\n",
    "        Label = lp.label,\n",
    "        NaiveBayes = float(predict_proba_NB_2(lp.features, modelNB)),\n",
    "        LogisticRegression = float(modelLR.predict(lp.features))\n",
    "    )).toDF().toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing result\n",
    "\n",
    "df_test = test_data.map( lambda lp: pyspark.sql.Row(\n",
    "        Label = lp.label,\n",
    "        NaiveBayes = float(predict_proba_NB_2(lp.features, modelNB)),\n",
    "        LogisticRegression = float(modelLR.predict(lp.features))\n",
    "    )).toDF().toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple classification using bow\n",
      "AUC ROC LogisticRegression: 0.507775525483\n",
      "AUC ROC NaiveBayes: 0.574180345827\n"
     ]
    }
   ],
   "source": [
    "print('Simple classification using bow')\n",
    "for c in df_test.columns[1:]:\n",
    "    print('AUC ROC {0}: {1}'.format(\n",
    "            c,\n",
    "            sk.metrics.roc_auc_score(y_true = df_test['Label'], y_score = df_test[c])\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-8.3333405433752876, 2654516),\n",
       " (-8.2719067509145674, 1564592),\n",
       " (-8.2589152067770293, 4245776),\n",
       " (-8.2312249657378764, 1205133),\n",
       " (-8.229802214414649, 9120838),\n",
       " (-8.1516403569619591, 3613394),\n",
       " (-8.1150251426058073, 8076448),\n",
       " (-8.0785916526457466, 6682023),\n",
       " (-8.0577002936143707, 9198106),\n",
       " (-8.0241034673616767, 514778),\n",
       " (-8.0050314495377179, 8242203),\n",
       " (-7.9055724885141068, 3803127),\n",
       " (-7.8569603553225349, 4629236),\n",
       " (-7.8083948945349864, 8185864),\n",
       " (-7.8053466279917352, 9178293),\n",
       " (-7.8051775519916706, 987141),\n",
       " (-7.7413260800051376, 6631867),\n",
       " (-7.7364213949098968, 7334991),\n",
       " (-7.7327979171367502, 6494112),\n",
       " (-7.652235185506207, 7245588),\n",
       " (-7.6269500222332045, 2879431),\n",
       " (-7.6261016058927193, 241806),\n",
       " (-7.6255363946299681, 4571660),\n",
       " (-7.6052602333073374, 426142),\n",
       " (-7.6013917565294165, 8705472),\n",
       " (-7.598568938034802, 2050506),\n",
       " (-7.5893302067955961, 413322),\n",
       " (-7.5631102173435618, 165058),\n",
       " (-7.556166893036405, 2487665),\n",
       " (-7.5439193024054756, 9772281),\n",
       " (-7.5158062899490456, 6973937),\n",
       " (-7.4992354864726476, 2198708),\n",
       " (-7.4843444207406833, 1926664),\n",
       " (-7.461246185502084, 5425546),\n",
       " (-7.4192885541485243, 1317058),\n",
       " (-7.3091523789253223, 6314864),\n",
       " (-7.2761915417126311, 9246508),\n",
       " (-7.2433663734928118, 6619584),\n",
       " (-7.2252170549871355, 6303968),\n",
       " (-6.9673922484721658, 9965008)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefs = sorted(zip(modelNB.theta[1],range(10000000)),key = lambda e: -abs(e[0]))\n",
    "coefs[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score_ccall_total: 0.494700742802\n",
      "AUC ROC score_ccall_approve_total: 0.4945728616\n",
      "AUC ROC score_ccall_not_approve_total: 0.494643174739\n",
      "AUC ROC score_ccall_approve_ccall_not_approve: 0.499852839217\n",
      "AUC ROC score_ccall_approve_total_weekly: 0.496008184489\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "import sklearn.ensemble\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feat_cols = data.columns[2:]\n",
    "for c in feat_cols:\n",
    "    print('AUC ROC {0}: {1}'.format(\n",
    "            c,\n",
    "            sk.metrics.roc_auc_score(y_true = data['label'], y_score = data[c])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars AUCROC:    0.499420712538\n",
      "LinRegr AUCROC:    0.499614418514\n",
      "Ridge AUCROC:    0.499540562512\n",
      "ElasticNet AUCROC:    0.5\n",
      "BayesianRidge AUCROC:    0.49910585097\n",
      "Lasso AUCROC:    0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:170: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  elif Gram == 'auto':\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lin_models = {\n",
    "    'Ridge': linear_model.Ridge (alpha = .5),\n",
    "    'Lasso': linear_model.Lasso(),\n",
    "    'ElasticNet': linear_model.ElasticNet(),\n",
    "    'Lars': linear_model.Lars(),\n",
    "    'LinRegr': linear_model.LinearRegression(),\n",
    "    'BayesianRidge':  linear_model.BayesianRidge()\n",
    "}\n",
    "for m in lin_models:\n",
    "    lin_models[m].fit(train_s,train['label']) \n",
    "    print('{0} AUCROC:    {1}'.format(m,sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = lin_models[m].predict(test_s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest AUCROC: 0.500557547026\n",
      "GBM AUCROC: 0.498993750524\n",
      "SVC AUCROC: 0.504130646261\n",
      "LogRegr AUCROC: 0.499160279512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:209: ConvergenceWarning: Solver terminated early (max_iter=40).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from sklearn import svm\n",
    "clf = {\n",
    "    'SVC': sk.svm.SVC(probability = True,max_iter = 40),\n",
    "    'LogRegr': sk.linear_model.LogisticRegression(),\n",
    "    'RandomForest': sk.ensemble.RandomForestClassifier(max_depth = 4,n_estimators = 500),\n",
    "    'GBM': sk.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(train[feat_cols],train['label']) \n",
    "    print('{0} AUCROC: {1}'.format(m,sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(test[feat_cols])]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn.ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight={0: 0.02, 1: 0.98}, coef0=0.0,\n",
       "  degree=3, gamma=0.0, kernel='rbf', max_iter=150, probability=True,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sk.svm.SVC(probability = True,max_iter = 150, kernel  = 'rbf',class_weight={0:0.02,1:0.98})\n",
    "svc.fit(train_s,train['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC AUCROC: 0.497827251926\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('SVC',sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = [e[1] for e in svc.predict_proba(test_s)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'score_ccall_total', u'score_ccall_approve_total',\n",
       "       u'score_ccall_not_approve_total',\n",
       "       u'score_ccall_approve_ccall_not_approve',\n",
       "       u'score_ccall_approve_total_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sk.svm.SVC(probability = True,max_iter = 350, kernel  = 'rbf',class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my AUCROC: 0.497828753091\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('my',sk.metrics.roc_auc_score(\n",
    "                y_true = train['label'] , \n",
    "                y_score = train['score_ccall_approve_total'] - train['score_ccall_not_approve_total'] \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'score_ccall_total', u'score_ccall_approve_total',\n",
       "       u'score_ccall_not_approve_total',\n",
       "       u'score_ccall_approve_ccall_not_approve',\n",
       "       u'score_ccall_approve_total_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score_ccall_total</th>\n",
       "      <th>score_ccall_approve_total</th>\n",
       "      <th>score_ccall_not_approve_total</th>\n",
       "      <th>score_ccall_approve_ccall_not_approve</th>\n",
       "      <th>score_ccall_approve_total_weekly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98400.540344</td>\n",
       "      <td>2.486468</td>\n",
       "      <td>3.385411</td>\n",
       "      <td>2.495839</td>\n",
       "      <td>1.142230</td>\n",
       "      <td>2.880102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98304.240137</td>\n",
       "      <td>2.472259</td>\n",
       "      <td>3.329577</td>\n",
       "      <td>2.483151</td>\n",
       "      <td>1.119151</td>\n",
       "      <td>2.851024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  score_ccall_total  score_ccall_approve_total  \\\n",
       "label                                                               \n",
       "0      98400.540344           2.486468                   3.385411   \n",
       "1      98304.240137           2.472259                   3.329577   \n",
       "\n",
       "       score_ccall_not_approve_total  score_ccall_approve_ccall_not_approve  \\\n",
       "label                                                                         \n",
       "0                           2.495839                               1.142230   \n",
       "1                           2.483151                               1.119151   \n",
       "\n",
       "       score_ccall_approve_total_weekly  \n",
       "label                                    \n",
       "0                              2.880102  \n",
       "1                              2.851024  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('label').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for long() with base 10: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a84f87cc42bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLabeledPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSparseVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabeledPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSparseVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/mllib/linalg/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size, *args)\u001b[0m\n\u001b[0;32m    509\u001b[0m                 \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[1;34m\"\"\" A list of indices corresponding to active entries. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for long() with base 10: 'a'"
     ]
    }
   ],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "tst = sc.parallelize([LabeledPoint(1.0,SparseVector(100,{'a':1, 'b':1})),LabeledPoint(0.0,SparseVector(100,{'a':1, 'c':1}))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "import numpy as np\n",
    "sc.parallelize(np.random.randint(10,size=(20,3))) \\\n",
    "  .map(lambda r: (1,SparseVector(11,{e:1.0 for e in r}))) \\\n",
    "  .toDF() \\\n",
    "  .write.saveAsTable(\"user_kposminin.test_tmp_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 8, 7, 9, 8, 9, 5, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10,size=(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 3, 6, 7, 8, 0, 0, 3, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(np.random.randint(10,size=(10))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.mllib.linalg.SparseVector"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = hc.sql('select * from user_kposminin.test_tmp_2').collect()\n",
    "type(df[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = list(u'abcdefghijklmnopqrstuvwxyz0123456789 %&-./=?_абвгдеёжзийклмнопрстуфхцчшщъыьэюя')\n",
    "abc.index(u'а')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 43 % 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
