{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import sklearn\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 4).set(\"spark.driver.maxResultSize\", \"2g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_6_query = '''\n",
    "insert into user_kposminin.ccalls_scores_6\n",
    "select\n",
    "  v.ymd,\n",
    "  v.phone_num,\n",
    "  max(v.label) as approve,\n",
    "  max(v.full_app) as full_app,\n",
    "  log(max((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1))) as max_tcs_score,\n",
    "  log(max((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1))) as max_approve_score,\n",
    "  log(max((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1))) as max_full_app_score,\n",
    "  count(distinct v.urlfr) as cnt,\n",
    "  sum(v.cnt) as hits,\n",
    "  sum(if(v.avg_hour>9 and v.avg_hour<20,v.cnt,0)) as work_hours_hits,\n",
    "  min(v.avg_hour) as min_avg_hour, \n",
    "  max(v.avg_hour) as max_avg_hour,\n",
    "  avg(v.avg_hour) as avg_avg_hour,\n",
    "  sum(duration) as sum_dur,\n",
    "  max(v.visit_lag) as max_visit_lag,\n",
    "  count(distinct v.visit_lag) as cnt_visit_lag,\n",
    "  count(distinct v.id) as id_cnt,\n",
    "  sum(if(v.urlfr like 'e.mail.ru%',1,0)) as emailru,\n",
    "  sum(if(v.urlfr like 'm.%',1,0))/sum(1) as mobile_share,\n",
    "  sum(if(v.urlfr like 'vk.com%' or v.urlfr like 'ok.ru%' or v.urlfr like 'm.vk.com%' or v.urlfr like 'm.odnoklassniki.ru%' or v.urlfr like 'm.my.mail.ru'or v.urlfr like 'my.mail.ru',1,0))/sum(1) as social_share,\n",
    "  stddev(v.visit_lag) as std1,\n",
    "  stddev(-24 * v.visit_lag + avg_hour) as std2,\n",
    "  avg(v.visit_lag) as avg_visit_lag,\n",
    "  avg(distinct visit_lag) as avg_dist_visit_lag,\n",
    "  max(trim(pc.provider)) as mob_provider,\n",
    "  max(trim(pc.region)) as region,\n",
    "  log(avg((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1))) as avg_tcs_score,\n",
    "  log(avg((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1))) as avg_approve_score,\n",
    "  log(avg((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1))) as avg_full_app_score,\n",
    "  sum(log((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1))) as sum_tcs_score,\n",
    "  sum(log((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1))) as sum_approve_score,\n",
    "  sum(log((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1))) as sum_full_app_score,\n",
    "  log(min((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1))) as min_tcs_score,\n",
    "  log(min((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1))) as min_approve_score,\n",
    "  log(min((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1))) as min_full_app_score,\n",
    "  log(percentile_approx((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1),0.75)) as q75_tcs_score,\n",
    "  log(percentile_approx((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1),0.75)) as q75_approve_score,\n",
    "  log(percentile_approx((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1),0.75)) as q75_full_app_score,\n",
    "  log(percentile_approx((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1),0.25)) as q25_tcs_score,\n",
    "  log(percentile_approx((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1),0.25)) as q25_approve_score,\n",
    "  log(percentile_approx((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1),0.25)) as q25_full_app_score,\n",
    "  log(percentile_approx((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1),0.5)) as q50_tcs_score,\n",
    "  log(percentile_approx((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1),0.5)) as q50_approve_score,\n",
    "  log(percentile_approx((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1),0.5)) as q50_full_app_score,\n",
    "  log(percentile_approx((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1),0.9)) as q90_tcs_score,\n",
    "  log(percentile_approx((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1),0.9)) as q90_approve_score,\n",
    "  log(percentile_approx((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1),0.9)) as q90_full_app_score,\n",
    "  count(distinct if((t2.cnt_full_app  + 0.1)/(t2.cnt_ccall - t2.cnt_full_app  + 0.1) > - 1.5,t2.urlfr,Null)) as la_app_full_urlfr_cnt,\n",
    "  count(distinct if((t2.cnt_approve + 0.1)/(t2.cnt_ccall - t2.cnt_approve + 0.1) > - 2,t2.urlfr,Null)) as la_approve_urlfr_cnt,\n",
    "  count(distinct if((t1.cnt_positive + 0.1)/(t1.cnt_total - t1.cnt_positive + 0.1) > -4, t2.urlfr,Null)) as la_tcs_urlfr_cnt\n",
    "  \n",
    "from user_kposminin.ccalls_visits_1 v\n",
    "  left join (\n",
    "     select * \n",
    "     from user_kposminin.urlfr_tgt_cnt \n",
    "     where ymd = '2016-05-01' \n",
    "       and target  = 'tinkoff_platinum_complete_application@tinkoff_action_cumul_month'\n",
    "       and (cnt_total > 25000 or cnt_positive > 100)\n",
    "  ) t1 on t1.urlfr = v.urlfr\n",
    "  left join (\n",
    "     select * \n",
    "     from user_kposminin.urlfr_tgt_cnt_ccall \n",
    "     where ymd = '2016-05-01' \n",
    "     and target='ccall_monthly_phone_cumul_full'\n",
    "     and (cnt_ccall > 200 or cnt_full_app > 20)\n",
    "  ) t2 on t2.urlfr = v.urlfr  \n",
    "  left semi join user_kposminin.cold_calls_matched_5 m on m.id = v.id and m.ymd = v.ymd and m.havent_started = 0\n",
    "  left join hermes.phone_codes pc on pc.phone_code = substr(v.phone_num,2,9)\n",
    "  where \n",
    "    v.ymd between '2016-05-21' and '2016-05-30' \n",
    "    and v.visit_lag > 0          \n",
    "group by v.ymd, v.phone_num\n",
    ";\n",
    "\n",
    "\n",
    "insert into user_kposminin.ccalls_visits_clusters_20160530_2\n",
    "select\n",
    "  ymd,\n",
    "  phone_num,\n",
    "  max(label) as label,\n",
    "  max(full_app) as full_app,\n",
    "  collect_set(cluster) as features,\n",
    "  concat_ws(\",\",\n",
    "      collect_list(\n",
    "        concat(\n",
    "          cluster,\" \"\n",
    "          ,cnt,\" \"\n",
    "          ,avg_hour,\" \"\n",
    "          ,sum_duration,\" \"\n",
    "        )\n",
    "      )\n",
    "  ) as additional_features\n",
    "from \n",
    "  (select\n",
    "    v.ymd,\n",
    "    v.phone_num,\n",
    "    max(cast(v.label as tinyint)) as label,\n",
    "    max(cast(v.full_app as tinyint)) as full_app,   \n",
    "  --  cast(v.visit_lag as tinyint) as visit_lag,\n",
    "    cast(c.cluster as int) as cluster,\n",
    "    count(cluster) as cnt,\n",
    "    avg(v.avg_hour) as avg_hour,\n",
    "    sum(duration) as sum_duration\n",
    "  from user_kposminin.ccalls_visits_1 v\n",
    "  inner join user_kposminin.domain_clusters c on c.domain = split(v.urlfr,'#')[0]  \n",
    "  left semi join user_kposminin.cold_calls_matched_5 m on m.id = v.id and m.ymd = v.ymd and m.havent_started = 0\n",
    "  where v.ymd between '2016-06-01' and '2016-06-30'\n",
    "  group by v.ymd, v.phone_num, c.cluster\n",
    "  ) a\n",
    "group by phone_num, ymd;\n",
    "\n",
    "insert into user_kposminin.ccalls_scores_8\n",
    "select \n",
    "  a.*,\n",
    "  pc.provider as mob_provider1,\n",
    "  trim(pc.region) as region1, \n",
    "  b.features,  \n",
    "  b.additional_features\n",
    "from \n",
    "  user_kposminin.ccalls_scores_6 a\n",
    "  left join user_kposminin.ccalls_visits_clusters_20160530_2 b on b.phone_num = a.phone_num and a.ymd = b.ymd\n",
    "  left join hermes.phone_codes pc on trim(pc.phone_code) = substr(a.phone_num,2,9)\n",
    ";\n",
    "\n",
    "\n",
    "create table user_kposminin.ccalls_scores_10 as\n",
    "select \n",
    "  a.ymd, \n",
    "  a.phone_num,\n",
    "  a.approve, \n",
    "  a.full_app,   \n",
    "  b.stop_cond, \n",
    "  b.target, \n",
    "  b.no_need, \n",
    "  nb.ot_started, \n",
    "  b.util_30, \n",
    "  b.status,\n",
    "  a.max_tcs_score, max_approve_score, max_full_app_score, cnt, hits, work_hours_hits, min_avg_hour, sum_dur, max_visit_lag, cnt_visit_lag, id_cnt, \n",
    "  social_share, emailru, mobile_share, std1, std2, avg_visit_lag, avg_dist_visit_lag, avg_tcs_score, avg_approve_score, avg_full_app_score, sum_tcs_score, sum_approve_score, sum_full_app_score,\n",
    "  min_tcs_score, min_approve_score, min_full_app_score, q75_tcs_score, q75_approve_score, q75_full_app_score, q25_tcs_score, q25_approve_score, q25_full_app_score, q50_tcs_score, q50_approve_score, \n",
    "  q50_full_app_score, q90_tcs_score, q90_approve_score, q90_full_app_score, la_app_full_urlfr_cnt, la_approve_urlfr_cnt, la_tcs_urlfr_cnt, mob_provider1, region1, features, additional_features,\n",
    "  weekday, raw_hour, ind, pop_country_share, pop_city_share, density, area_sq_km, federal_district, avg_salary_2015_rub, utc_time_zone_val, \n",
    "  no_need_xgboost, not_started_xgboost, target_xgboost, full_app_xgboost, approve_xgboost, train_sample  \n",
    "from \n",
    "  user_kposminin.ccalls_scores_8 a\n",
    "  left join user_kposminin.ccalls_phones_only b on a.ymd = b.ymd abd a.phone_num = b.phone_num -- результаты классификаторов только на основе номера телефона\n",
    ";\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "query = '''\n",
    "select \n",
    "  a.*\n",
    "from user_kposminin.ccalls_scores_10 a\n",
    "'''\n",
    "\n",
    "data = hc.sql(query) \n",
    "\n",
    "train_data = data \\\n",
    "    .filter(\"ymd < '2016-06-10'\") \\\n",
    "    .toPandas() \\\n",
    "    \n",
    "test_data = data \\\n",
    "    .filter(\"ymd >= '2016-06-10'\") \\\n",
    "    .toPandas() \\\n",
    "\n",
    "#phone_codes = hc.sql('select distinct substr(phone_num,2,4) as code from user_kposminin.cold_calls_matched_5') \\\n",
    "#    .map(lambda r:r[0]) \\\n",
    "#    .collect()\n",
    "top_clusters = hc.sql('select * from user_kposminin.top_clusters') \\\n",
    "    .map(lambda r:r[0]) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control_data = hc.sql('select * from user_kposminin.ccalls_scores_10_test').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['mob_provider1','region1','federal_district']:\n",
    "    for c in pd.concat([train_data[col],test_data[col]]).dropna().unique():\n",
    "        control_data[col + '_' + c] = control_data[col].map(lambda v: 1 * (c == v))\n",
    "        \n",
    "for c in top_clusters:\n",
    "    control_data['cluster_' + str(c)] = control_data['features'].map(lambda f: 1 * (1 in f) if f else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['mob_provider1','region1','federal_district']:\n",
    "    for c in pd.concat([train_data,test_data])[col].dropna().unique():\n",
    "        train_data[col + '_' + c] = train_data[col].map(lambda v: 1 * (c == v))\n",
    "        test_data[col + '_' + c]  =  test_data[col].map(lambda v: 1 * (c == v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in top_clusters:\n",
    "    train_data['cluster_' + str(c)] = train_data['features'].map(lambda f: 1 * (1 in f) if f else 0)\n",
    "    test_data['cluster_' + str(c)]  =  test_data['features'].map(lambda f: 1 * (1 in f) if f else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_cols = [c for c in train_data.columns if not c in [u'ymd', u'phone_num', u'approve', u'full_app',u'features',\n",
    "                                                       'additional_features','mob_provider1','region1','mob_provider','region',\n",
    "                                                       'stop_cond','target', 'no_need', 'not_started', 'util_30','train_sample',\n",
    "                                                       'status','raw_hour','federal_district','full_app_XGBoost_2']\n",
    "                                                       and not 'region' in c and not 'federal_district' in c\n",
    "                                                       and not 'mob_provider' in c and not 'cluster' in c\n",
    "        ]\n",
    "#feat_cols1 = [c for c in train_data.columns if not (c in [u'ymd', u'phone_num', u'approve', u'full_app',u'features',\n",
    "#                                                       'additional_features','mob_provider1','region1','mob_provider','region']\n",
    "#                                                   or 'mob_provider' in c or 'region' in c)]\n",
    "\n",
    "label_col = 'full_app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283937,)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_ind_train = train_data[label_col].isnull() | (train_data['not_started'] == 1)\n",
    "drop_ind_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "drop_ind_train = train_data[label_col].isnull() | (train_data['not_started'] == 1)\n",
    "drop_ind_test  = test_data[label_col].isnull()\n",
    "X, y  = imp.fit_transform(train_data[~drop_ind_train][feat_cols]), train_data[~drop_ind_train][label_col]\n",
    "Xt,yt = imp.transform(test_data[~drop_ind_test][feat_cols])     , test_data[~drop_ind_test][label_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xc = imp.transform(control_data[feat_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=4, seed=27, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "clfXGB = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators=200,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight = 4,\n",
    " seed=27\n",
    " )\n",
    "\n",
    "clfXGB.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC: 0.599909103813\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfXGB.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC train: 0.724992471787\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC train: {1}'.format('XGBoost',sklearn.metrics.roc_auc_score(\n",
    "                y_true = y, \n",
    "                y_score = [e[1] for e in clfXGB.predict_proba(X)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targ_boost = train_data[~drop_ind_train][[u'ymd', u'phone_num','full_app']]\n",
    "targ_boost['train'] = 1\n",
    "targ_boost['full_app_XGBoost'] = [e[1] for e in clfXGB.predict_proba(X)]\n",
    "targ_boostt = test_data[~drop_ind_test][[u'ymd', u'phone_num','full_app']]\n",
    "targ_boostt['train'] = 0\n",
    "targ_boostt['full_app_XGBoost'] = [e[1] for e in clfXGB.predict_proba(Xt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['full_app_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(imp.transform(train_data[feat_cols]))]\n",
    "test_data['full_app_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(imp.transform(test_data[feat_cols]))]\n",
    "control_data['full_app_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(Xc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([               u'ymd',          u'phone_num',      u'max_tcs_score',\n",
       "        u'max_approve_score', u'max_full_app_score',                u'cnt',\n",
       "                     u'hits',    u'work_hours_hits',       u'min_avg_hour',\n",
       "                  u'sum_dur', \n",
       "       ...\n",
       "            u'cluster_39036',      u'cluster_39467',      u'cluster_39548',\n",
       "            u'cluster_39563',      u'cluster_39801',      u'cluster_39928',\n",
       "            u'cluster_40122',      u'cluster_40852',      u'cluster_40857',\n",
       "         u'full_app_XGBoost'],\n",
       "      dtype='object', length=363)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17329   620 0.0357781753131\n",
      "29284  1298 0.0443245458271\n",
      "26254  1436 0.0546964272111\n",
      "12484   772 0.0618391541173\n",
      "11772   830 0.0705062861026\n",
      "11237   904 0.0804485182878\n",
      "10316   901 0.0873400542846\n",
      " 5085   538 0.105801376598\n",
      " 3520   425 0.120738636364\n",
      "  674   107 0.158753709199\n"
     ]
    }
   ],
   "source": [
    "ql = targ_boost['full_app_XGBoost'].quantile([0,0.1,0.3,0.5,0.6,0.7,0.8,0.9,0.95,0.99,1]).tolist()\n",
    "res = []\n",
    "for i in range(1,len(ql)):\n",
    "    data = targ_boostt[(targ_boostt['full_app_XGBoost'] >= ql[i-1]) & (targ_boostt['full_app_XGBoost'] < ql[i])]\n",
    "    res.append([\n",
    "            ql[i-1],\n",
    "            ql[i],\n",
    "            data['full_app_XGBoost'].min(),\n",
    "            len(data),\n",
    "            data['full_app'].sum(),\n",
    "            data['full_app'].mean(),\n",
    "            ])\n",
    "print('\\n'.join(['{0:>5} {1:>5} {2:>8}'.format(*e[3:])  for e in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['full_app_XGBoost_2'] = train_data[['phone_num','ymd']].join(targ_boost.groupby(['phone_num','ymd']).max(), on = ['phone_num','ymd'])['full_app_XGBoost']\n",
    "test_data['full_app_XGBoost_2'] = test_data[['phone_num','ymd']].join(targ_boostt.groupby(['phone_num','ymd']).max(), on = ['phone_num','ymd'])['full_app_XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.115314150231706"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_boostt[targ_boostt['full_app_XGBoost'] > targ_boost['full_app_XGBoost'].quantile(0.9)]['full_app'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061198333867350206"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_boostt[targ_boostt['full_app_XGBoost'] > -99]['full_app'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier AUCROC: 0.60044459136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clfAB = AdaBoostClassifier(learning_rate = 1, n_estimators = 100)\n",
    "clfAB.fit(X,y)\n",
    "print('{0} AUCROC: {1}'.format('AdaBoostClassifier',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfAB.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_feat = sorted(zip(clfAB.feature_importances_,feat_cols),reverse = True)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "mLR = sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 1, class_weight = 'auto')\n",
    "mLR.fit(X,y)\n",
    "print('{0} AUCROC: {1}'.format('LogisticRegression',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in mLR.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier AUCROC: 0.599244432587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfRF = RandomForestClassifier(max_depth = 7,n_estimators = 200)\n",
    "clfRF.fit(X,y)\n",
    "print('{0} AUCROC: {1}'.format('RandomForestClassifier',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfRF.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.087294819676607543, 'avg_full_app_score'),\n",
       " (0.072106936504737595, 'max_tcs_score'),\n",
       " (0.060674639551852899, 'avg_tcs_score'),\n",
       " (0.057203839370221943, 'max_full_app_score'),\n",
       " (0.049002700401562398, 'q90_full_app_score'),\n",
       " (0.047898409434973442, 'avg_approve_score'),\n",
       " (0.045419874811463125, 'q25_full_app_score'),\n",
       " (0.040252270899571209, 'q50_full_app_score'),\n",
       " (0.034555592866182393, 'approve_xgboost'),\n",
       " (0.033285208712136513, 'target_xgboost'),\n",
       " (0.032287254606961711, 'q75_full_app_score'),\n",
       " (0.031820136767433713, 'full_app_xgboost'),\n",
       " (0.025745800030184243, 'no_need_xgboost'),\n",
       " (0.021454798540367068, 'q25_approve_score'),\n",
       " (0.018865471548612824, 'q90_tcs_score'),\n",
       " (0.018679632000106174, 'min_full_app_score'),\n",
       " (0.018529650697542373, 'not_started_xgboost'),\n",
       " (0.017395889438985516, 'q75_approve_score'),\n",
       " (0.017200372594373584, 'q25_tcs_score'),\n",
       " (0.016005400245942297, 'q50_approve_score'),\n",
       " (0.014881308497761092, 'q50_tcs_score'),\n",
       " (0.014790668401888403, 'q90_approve_score'),\n",
       " (0.013588686660321541, 'q75_tcs_score'),\n",
       " (0.010063814660963835, 'std1'),\n",
       " (0.0099420435574040806, 'min_tcs_score'),\n",
       " (0.0099032531851855413, 'min_avg_hour'),\n",
       " (0.0097055129581410018, 'std2'),\n",
       " (0.0092474609654568801, 'min_approve_score'),\n",
       " (0.0089044660208020716, 'max_approve_score'),\n",
       " (0.0088404597536847693, 'sum_approve_score'),\n",
       " (0.0087600441543435586, 'avg_visit_lag'),\n",
       " (0.0087456576340455075, 'sum_tcs_score'),\n",
       " (0.008296089133015749, 'sum_full_app_score'),\n",
       " (0.0079353327928035899, 'cnt'),\n",
       " (0.0079097649224514083, 'hits'),\n",
       " (0.0078927647733113993, 'work_hours_hits'),\n",
       " (0.0077133597416132304, 'sum_dur'),\n",
       " (0.007134329533871925, 'social_share'),\n",
       " (0.0071239634822451332, 'mobile_share'),\n",
       " (0.0068228506739821341, 'la_app_full_urlfr_cnt')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feat1 = sorted(zip(clfRF.feature_importances_,feat_cols),reverse = True)[:40]\n",
    "top_feat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_feat2 = list(set([e[1] for e in top_feat[:20]]).union([e[1] for e in top_feat1[:20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "ind_train = train_data[(train_data[label_col] == 1)].index.append(train_data[(train_data[label_col] == 0)].sample(frac = 0.3).index )\n",
    "drop_ind_test  = test_data[label_col].isnull()\n",
    "X, y  = imp.fit_transform(train_data.loc[ind_train][top_feat2]), train_data.loc[ind_train][label_col]\n",
    "Xt,yt = imp.transform(test_data[~drop_ind_test][top_feat2])     , test_data[~drop_ind_test][label_col]\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "clfXGB = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators=200,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight = 1,\n",
    " seed=27\n",
    " )\n",
    "\n",
    "clfXGB.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC: 0.602027850942\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfXGB.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152663,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[ind_train][label_col].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283937,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[label_col].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_app = train_data[train_data['full_app'] == 1]\n",
    "test_app = test_data[test_data['full_app'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_cols = [c for c in train_data.columns if not c in [u'ymd', u'phone_num', u'approve', u'full_app',u'features',\n",
    "                                                       'additional_features','mob_provider1','region1','mob_provider','region',\n",
    "                                                       'stop_cond','target', 'no_need', 'not_started', 'util_30','train_sample',\n",
    "                                                       'status','raw_hour','federal_district']]\n",
    "label_col = 'approve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "drop_ind_train  = train_app[label_col].isnull()\n",
    "drop_ind_test  = test_app[label_col].isnull()\n",
    "X, y  = imp.fit_transform(train_app.loc[~drop_ind_train][feat_cols]), train_app.loc[~drop_ind_train][label_col]\n",
    "Xt,yt = imp.transform(test_app[~drop_ind_test][feat_cols]), test_app[~drop_ind_test][label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=50, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "clfXGBs = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators=50,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight = 1,\n",
    " seed=27\n",
    " )\n",
    "\n",
    "clfXGBs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost new AUCROC: 0.556308557489\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost new',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [(b**0.7)*e[1] for e,b in zip(clfXGB.predict_proba(Xt),test_data[~drop_ind_test]['full_app_XGBoost2'])]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "drop_ind_train  = train_data[label_col].isnull()\n",
    "drop_ind_test  = test_data[label_col].isnull()\n",
    "X, y  = imp.fit_transform(train_data.loc[~drop_ind_train][feat_cols]), train_data.loc[~drop_ind_train][label_col]\n",
    "Xt,yt = imp.transform(test_data[~drop_ind_test][feat_cols]), test_data[~drop_ind_test][label_col]\n",
    "Xc = imp.transform(control_data[feat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=50, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "clfXGB = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators=50,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight = 1,\n",
    " seed=27\n",
    " )\n",
    "\n",
    "clfXGB.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC: 0.546673451898\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfXGB.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train AUCROC: 0.673264722502\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost train',sklearn.metrics.roc_auc_score(\n",
    "                y_true = y, \n",
    "                y_score = [e[1] for e in clfXGB.predict_proba(X)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost new AUCROC: 0.556319593028\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('XGBoost new',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [b*e[1] for e,b in zip(clfXGB.predict_proba(Xt),test_data[~drop_ind_test]['full_app_XGBoost2'])]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['approve_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(imp.transform(train_data[feat_cols]))]\n",
    "test_data['approve_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(imp.transform(test_data[feat_cols]))]\n",
    "control_data['approve_XGBoost2'] = [e[1] for e in clfXGB.predict_proba(Xc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#control_data.to_csv('/data/control_ccalls.csv',encoding = 'utf-8')\n",
    "cols_to_export = [c for c in control_data.columns if not 'ind_' in c and not 'mob_provider_' in c and not 'federal_district_' in c\n",
    "                  and not 'mob_provider1_' in c and not 'federal_district1_' in c and not 'region1_' in c and not 'cluster' in c]\n",
    "control_data[cols_to_export].to_csv('./data/control_ccalls.csv',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ymd</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>full_app_XGBoost2</th>\n",
       "      <th>approve_XGBoost2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>89000249412</td>\n",
       "      <td>0.243957</td>\n",
       "      <td>0.038010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>89002005075</td>\n",
       "      <td>0.240351</td>\n",
       "      <td>0.036008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>89002143665</td>\n",
       "      <td>0.114222</td>\n",
       "      <td>0.012963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>89002382938</td>\n",
       "      <td>0.210126</td>\n",
       "      <td>0.036045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>89003204523</td>\n",
       "      <td>0.145384</td>\n",
       "      <td>0.036089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ymd    phone_num  full_app_XGBoost2  approve_XGBoost2\n",
       "0  2016-08-01  89000249412           0.243957          0.038010\n",
       "1  2016-08-01  89002005075           0.240351          0.036008\n",
       "2  2016-08-01  89002143665           0.114222          0.012963\n",
       "3  2016-08-01  89002382938           0.210126          0.036045\n",
       "4  2016-08-01  89003204523           0.145384          0.036089"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cols = ['ymd', 'phone_num', 'full_app_XGBoost2', 'approve_XGBoost2']\n",
    "control_data[res_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc.sql('drop table if exists new_data1')\n",
    "hc.registerDataFrameAsTable(hc.createDataFrame(control_data[res_cols]), 'new_data1')\n",
    "hc.sql('drop table if exists user_kposminin.ccalls_phone_data_only_test')\n",
    "hc.sql('create table user_kposminin.ccalls_control_log_res as select * from new_data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3d6bbc6a5c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclfAB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclfAB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m print('{0} AUCROC: {1}'.format('AdaBoostClassifier',sklearn.metrics.roc_auc_score(\n\u001b[0;32m      6\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \"\"\"\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    375\u001b[0m                                            max_leaf_nodes, self.min_impurity_split)\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clfAB = AdaBoostClassifier(learning_rate = 1, n_estimators = 100)\n",
    "clfAB.fit(X,y)\n",
    "print('{0} AUCROC: {1}'.format('AdaBoostClassifier',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt, \n",
    "                y_score = [e[1] for e in clfAB.predict_proba(Xt)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.059999999999999998, 'max_full_app_score'),\n",
       " (0.050000000000000003, 'q25_tcs_score'),\n",
       " (0.050000000000000003, 'avg_full_app_score'),\n",
       " (0.040000000000000001, 'sum_dur'),\n",
       " (0.040000000000000001, 'no_need_xgboost'),\n",
       " (0.040000000000000001, 'min_tcs_score'),\n",
       " (0.029999999999999999, 'weekday'),\n",
       " (0.029999999999999999, 'social_share'),\n",
       " (0.029999999999999999, 'q75_approve_score'),\n",
       " (0.029999999999999999, 'not_started_xgboost'),\n",
       " (0.029999999999999999, 'min_full_app_score'),\n",
       " (0.029999999999999999, 'hits'),\n",
       " (0.029999999999999999, 'density'),\n",
       " (0.02, 'work_hours_hits'),\n",
       " (0.02, 'std1'),\n",
       " (0.02, 'q90_full_app_score'),\n",
       " (0.02, 'q90_approve_score'),\n",
       " (0.02, 'q25_approve_score'),\n",
       " (0.02, 'pop_city_share'),\n",
       " (0.02, 'mobile_share'),\n",
       " (0.02, 'min_approve_score'),\n",
       " (0.02, 'max_tcs_score'),\n",
       " (0.02, 'max_approve_score'),\n",
       " (0.02, 'cnt'),\n",
       " (0.02, 'avg_visit_lag'),\n",
       " (0.02, 'avg_tcs_score'),\n",
       " (0.02, 'approve_xgboost'),\n",
       " (0.01, 'utc_time_zone_val'),\n",
       " (0.01, 'sum_tcs_score'),\n",
       " (0.01, 'sum_full_app_score'),\n",
       " (0.01, 'std2'),\n",
       " (0.01,\n",
       "  u'region1_\\u0421\\u0442\\u0430\\u0432\\u0440\\u043e\\u043f\\u043e\\u043b\\u044c\\u0441\\u043a\\u0438\\u0439 \\u043a\\u0440\\u0430\\u0439'),\n",
       " (0.01,\n",
       "  u'region1_\\u0420\\u0435\\u0441\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u0430 \\u0422\\u0430\\u0442\\u0430\\u0440\\u0441\\u0442\\u0430\\u043d'),\n",
       " (0.01,\n",
       "  u'region1_\\u0420\\u0435\\u0441\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u0430 \\u0418\\u043d\\u0433\\u0443\\u0448\\u0435\\u0442\\u0438\\u044f'),\n",
       " (0.01,\n",
       "  u'region1_\\u0412\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440\\u0441\\u043a\\u0430\\u044f \\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\\u044c'),\n",
       " (0.01, 'q90_tcs_score'),\n",
       " (0.01, 'q50_tcs_score'),\n",
       " (0.01, 'q50_approve_score'),\n",
       " (0.01, u'mob_provider1_\\u0420\\u0422-\\u041c\\u043e\\u0431\\u0430\\u0439\\u043b'),\n",
       " (0.01, u'mob_provider1_\\u041c\\u0435\\u0433\\u0430\\u0444\\u043e\\u043d')]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clfAB.feature_importances_,feat_cols),reverse = True)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
