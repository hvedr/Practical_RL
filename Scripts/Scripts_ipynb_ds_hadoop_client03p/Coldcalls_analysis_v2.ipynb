{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Холодные звонки\n",
    "\n",
    "Тест эффективности скоров текущей модели lookalike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_query = '''\n",
    "select \n",
    "    ymd, \n",
    "    ccall_approve_label as label, \n",
    "    score_ccall_total, \n",
    "    score_ccall_approve_total, \n",
    "    score_ccall_not_approve_total, \n",
    "    score_ccall_approve_ccall_not_approve, \n",
    "    score_ccall_approve_total_weekly\n",
    "from user_kposminin.ccalls_scores_2\n",
    "'''\n",
    "\n",
    "read_ccalls_visits_clusters_query = '''\n",
    "select \n",
    "    ymd, \n",
    "    label, \n",
    "    features\n",
    "from user_kposminin.ccalls_visits_clusters\n",
    "'''\n",
    "\n",
    "\n",
    "data = hc.sql(read_query).toPandas()\n",
    "\n",
    "# Doesn't convert into int and has fraction values.\n",
    "data['label'] = data['label'].map(lambda v: 0 if v == u'0.0' else 1)\n",
    "data['ymd'] = pd.to_datetime(data['ymd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ymd', u'label', u'score_ccall_total', u'score_ccall_approve_total',\n",
       "       u'score_ccall_not_approve_total',\n",
       "       u'score_ccall_approve_ccall_not_approve',\n",
       "       u'score_ccall_approve_total_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[u'score_ccall_approve_total_weekly'] = data[u'score_ccall_approve_total_weekly'].map(lambda v: -10 if v == 0 else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score_ccall_total: 0.494700742802\n",
      "AUC ROC score_ccall_approve_total: 0.4945728616\n",
      "AUC ROC score_ccall_not_approve_total: 0.494643174739\n",
      "AUC ROC score_ccall_approve_ccall_not_approve: 0.499852839217\n",
      "AUC ROC score_ccall_approve_total_weekly: 0.496008184489\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "import sklearn.ensemble\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feat_cols = data.columns[2:]\n",
    "for c in feat_cols:\n",
    "    print('AUC ROC {0}: {1}'.format(\n",
    "            c,\n",
    "            sk.metrics.roc_auc_score(y_true = data['label'], y_score = data[c])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train test = train_test_split(data, test_size = 0.4)\n",
    "train, test = data[data['ymd'] < datetime.date(2016,5,1)].reset_index(),data[data['ymd'] >= datetime.date(2016,5,1)].reset_index()\n",
    "#test = data.drop(train.index).reset_index()\n",
    "test.dropna(how='any',inplace = True)\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "train_s = scaler.fit_transform(train[feat_cols])\n",
    "test_s = scaler.transform(test[feat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars AUCROC:    0.499420712538\n",
      "LinRegr AUCROC:    0.499614418514\n",
      "Ridge AUCROC:    0.499540562512\n",
      "ElasticNet AUCROC:    0.5\n",
      "BayesianRidge AUCROC:    0.49910585097\n",
      "Lasso AUCROC:    0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:170: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  elif Gram == 'auto':\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lin_models = {\n",
    "    'Ridge': linear_model.Ridge (alpha = .5),\n",
    "    'Lasso': linear_model.Lasso(),\n",
    "    'ElasticNet': linear_model.ElasticNet(),\n",
    "    'Lars': linear_model.Lars(),\n",
    "    'LinRegr': linear_model.LinearRegression(),\n",
    "    'BayesianRidge':  linear_model.BayesianRidge()\n",
    "}\n",
    "for m in lin_models:\n",
    "    lin_models[m].fit(train_s,train['label']) \n",
    "    print('{0} AUCROC:    {1}'.format(m,sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = lin_models[m].predict(test_s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest AUCROC: 0.500557547026\n",
      "GBM AUCROC: 0.498993750524\n",
      "SVC AUCROC: 0.504130646261\n",
      "LogRegr AUCROC: 0.499160279512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:209: ConvergenceWarning: Solver terminated early (max_iter=40).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from sklearn import svm\n",
    "clf = {\n",
    "    'SVC': sk.svm.SVC(probability = True,max_iter = 40),\n",
    "    'LogRegr': sk.linear_model.LogisticRegression(),\n",
    "    'RandomForest': sk.ensemble.RandomForestClassifier(max_depth = 4,n_estimators = 500),\n",
    "    'GBM': sk.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(train[feat_cols],train['label']) \n",
    "    print('{0} AUCROC: {1}'.format(m,sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(test[feat_cols])]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sklearn.ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight={0: 0.02, 1: 0.98}, coef0=0.0,\n",
       "  degree=3, gamma=0.0, kernel='rbf', max_iter=150, probability=True,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sk.svm.SVC(probability = True,max_iter = 150, kernel  = 'rbf',class_weight={0:0.02,1:0.98})\n",
    "svc.fit(train_s,train['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC AUCROC: 0.497827251926\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('SVC',sk.metrics.roc_auc_score(\n",
    "                y_true = test['label'] , \n",
    "                y_score = [e[1] for e in svc.predict_proba(test_s)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'score_ccall_total', u'score_ccall_approve_total',\n",
       "       u'score_ccall_not_approve_total',\n",
       "       u'score_ccall_approve_ccall_not_approve',\n",
       "       u'score_ccall_approve_total_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = sk.svm.SVC(probability = True,max_iter = 350, kernel  = 'rbf',class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my AUCROC: 0.497828753091\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC: {1}'.format('my',sk.metrics.roc_auc_score(\n",
    "                y_true = train['label'] , \n",
    "                y_score = train['score_ccall_approve_total'] - train['score_ccall_not_approve_total'] \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'score_ccall_total', u'score_ccall_approve_total',\n",
       "       u'score_ccall_not_approve_total',\n",
       "       u'score_ccall_approve_ccall_not_approve',\n",
       "       u'score_ccall_approve_total_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score_ccall_total</th>\n",
       "      <th>score_ccall_approve_total</th>\n",
       "      <th>score_ccall_not_approve_total</th>\n",
       "      <th>score_ccall_approve_ccall_not_approve</th>\n",
       "      <th>score_ccall_approve_total_weekly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98400.540344</td>\n",
       "      <td>2.486468</td>\n",
       "      <td>3.385411</td>\n",
       "      <td>2.495839</td>\n",
       "      <td>1.142230</td>\n",
       "      <td>2.880102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98304.240137</td>\n",
       "      <td>2.472259</td>\n",
       "      <td>3.329577</td>\n",
       "      <td>2.483151</td>\n",
       "      <td>1.119151</td>\n",
       "      <td>2.851024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  score_ccall_total  score_ccall_approve_total  \\\n",
       "label                                                               \n",
       "0      98400.540344           2.486468                   3.385411   \n",
       "1      98304.240137           2.472259                   3.329577   \n",
       "\n",
       "       score_ccall_not_approve_total  score_ccall_approve_ccall_not_approve  \\\n",
       "label                                                                         \n",
       "0                           2.495839                               1.142230   \n",
       "1                           2.483151                               1.119151   \n",
       "\n",
       "       score_ccall_approve_total_weekly  \n",
       "label                                    \n",
       "0                              2.880102  \n",
       "1                              2.851024  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('label').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
