{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение auc precision-recall curve запросом в hql. \n",
    "### Построение запроса сравнения коэффициентов урлфрагментов в задаче lookalike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "import sklearn,sklearn.metrics\n",
    "\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "try:\n",
    "    sc.stop()\n",
    "except: pass\n",
    "\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 2)\n",
    "        .set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "        .set('spark.driver.memory','16g')\n",
    "       # .set(\"spark.executor.memory\", '8g')\n",
    "       # .set(\"spark.yarn.executor.memoryOverhead\", 2048)        \n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = np.random.choice(2,size = 100000,p=[0.9,0.1])\n",
    "y_score = y_true + np.random.randn(y_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартный AUC ROC, AUC PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_roc = sklearn.metrics.roc_auc_score(y_true = y_true, y_score = y_score)\n",
    "auc_pr_wrong = sklearn.metrics.auc(\n",
    "                        *sklearn.metrics.precision_recall_curve(y_true = y_true, probas_pred  = y_score)[:2],\n",
    "                        reorder = True)\n",
    "auc_pr = sklearn.metrics.average_precision_score(y_true = y_true, y_score = y_score)\n",
    "logloss = sklearn.metrics.log_loss(y_true = y_true, y_pred = y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение AUC PR вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sorted = [e[1] for e in sorted(zip(y_score,y_true),reverse = True)]\n",
    "precision = []\n",
    "pos = 0\n",
    "n = 0\n",
    "for e in y_sorted:\n",
    "    n += 1\n",
    "    if e == 1:\n",
    "        pos += 1\n",
    "        precision.append(float(pos)/n)\n",
    "auc_pr_manual = sum(precision)/len(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2869752348023623, 0.2869016252829576)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pr_manual, auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет AUC PR вручную и стандартной библиотекой дают ~одинаковый результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sc.parallelize(zip([int(e) for e in y_true],[float(e) for e in y_score])).toDF(['label','score'])\n",
    "hc.registerDataFrameAsTable(df, 'label_score_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "query2 = '''\n",
    "with\n",
    "st1 as (select * from label_score_data a),\n",
    "cs1 as (\n",
    "  select \n",
    "    (1-label)*sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision\n",
    "  from st1),\n",
    "cs3 as (select sum(label) as cnt_positive from st1)\n",
    "select \n",
    "  'First' as name, \n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/max(cnt_positive) as auc_pr\n",
    "from cs1 a inner join cs3 b\n",
    "'''\n",
    "\n",
    "calc_metrics_query = '''\n",
    "with\n",
    "st1 as (select * from label_score_data a),\n",
    "cs1 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label\n",
    "  from st1)\n",
    "select \n",
    "  'First' as name, \n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr\n",
    "from cs1 a \n",
    "'''\n",
    "\n",
    "calc_metrics_query_new = '''\n",
    "with\n",
    "st1 as (select * from label_score_data a),\n",
    "cs1 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
    "    rank() OVER (ORDER BY score DESC) as rank,\n",
    "    label\n",
    "  from st1)\n",
    "select \n",
    "  'First' as name, \n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr,\n",
    "  avg(logloss) as logloss,\n",
    "  sum(if(rank < 1000,label,0))/1000 *count(*)/ sum(label) as lift_1k,\n",
    "  sum(if(rank < 20000,label,0))/20000 *count(*)/ sum(label) as lift_20k,\n",
    "  sum(label)/count(*) as pos_share\n",
    "from cs1 a \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+------------------+----------------+------------------+---------+\n",
      "| name|           auc_roc|            auc_pr|           logloss|         lift_1k|          lift_20k|pos_share|\n",
      "+-----+------------------+------------------+------------------+----------------+------------------+---------+\n",
      "|First|0.7565796607120473|0.2869752348023623|0.7654592867044155|5.37529319781079|2.4970680218921033|  0.10232|\n",
      "+-----+------------------+------------------+------------------+----------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hc.sql(calc_metrics_query_new).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7565796607120473, 0.2869752348023623, 5.7761216106481195)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_roc,auc_pr_manual,logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Успех"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_query = '''\n",
    "with p as \n",
    " (\n",
    "  select \n",
    "    v.id, \n",
    "    max(if(u.id is Null,0,1)) as label, \n",
    "    max(t1.score) as score1, \n",
    "    max(t2.score) as score2 \n",
    "  from\n",
    "   (select id, url_fragment as urlfr from prod_odd.visit_feature where ymd = '2017-02-28') v\n",
    "   left join \n",
    "    (\n",
    "      select id\n",
    "      from prod_features_liveinternet.user_action \n",
    "      where ymd between '#ymd' and date_add('#ymd',3)\n",
    "      and action_type = 'tinkoff_platinum_approved_application'\n",
    "    ) u on u.id = v.id\n",
    "   left join prod_lookalike.urlfr_coeff t1 on t1.urlfr = v.urlfr and t1.segment_nm = 'la_apppr_ccall_2'\n",
    "   left join\n",
    "    (\n",
    "    select\n",
    "      urlfr,\n",
    "      score\n",
    "    from\n",
    "      prod_features_liveinternet.urlfr_tgt_cnt_cumulative2\n",
    "    where\n",
    "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
    "      and ymd = '2016-12-26'\n",
    "      and (cnt_total > 300000 or cnt_positive > 10)\n",
    "    ) t2 on t2.urlfr = v.urlfr \n",
    "   group by\n",
    "    v.id\n",
    " ),\n",
    "st1 as (select a.score1 as score, a.label as label from p a),\n",
    "st2 as (select a.score2 as score, a.label as label from p a),\n",
    "cs1 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
    "    rank() OVER (ORDER BY score DESC) as rank,\n",
    "    label\n",
    "  from st1),\n",
    "cs2 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
    "    rank() OVER (ORDER BY score DESC) as rank,\n",
    "    label\n",
    "  from st2)\n",
    "  \n",
    "select \n",
    "  'Old coeffs' as name, \n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr,\n",
    "  avg(logloss) as logloss,\n",
    "  sum(if(rank < 1000,label,0))/1000 *count(*)/ sum(label) as lift_1k,\n",
    "  sum(if(rank < 20000,label,0))/20000 *count(*)/ sum(label) as lift_20k,\n",
    "  sum(label)/count(*) as pos_share\n",
    "from cs1\n",
    "\n",
    "union all\n",
    "\n",
    "select \n",
    "  'New coeffs' as name, \n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr,\n",
    "  avg(logloss) as logloss,\n",
    "  sum(if(rank < 1000,label,0))/1000 *count(*)/ sum(label) as lift_1k,\n",
    "  sum(if(rank < 20000,label,0))/20000 *count(*)/ sum(label) as lift_20k,\n",
    "  sum(label)/count(*) as pos_share\n",
    "from cs2 a \n",
    ";\n",
    "\n",
    "'''\n",
    "\n",
    "compare_query1 = '''\n",
    "-- la_apppr_ccall2. Url coefs comparison\n",
    "with \n",
    "mymd_t as\n",
    " (\n",
    " select \n",
    "   max(ymd) as max_ymd\n",
    " from \n",
    "   prod_features_liveinternet.urlfr_tgt_cnt_cumulative2\n",
    " where\n",
    "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
    "      and ymd < date_add('#ymd',-3)\n",
    " ),\n",
    "p as \n",
    " (\n",
    "  select \n",
    "    v.id, \n",
    "    max(if(u.id is Null,0,1)) as label, \n",
    "    max(t1.score) as score1, \n",
    "    max(t2.score) as score2 \n",
    "  from\n",
    "   (select id, url_fragment as urlfr from prod_odd.visit_feature where ymd = '#ymd') v\n",
    "   left join \n",
    "    (\n",
    "      select id\n",
    "      from prod_features_liveinternet.user_action \n",
    "      where ymd between '#ymd' and date_add('#ymd',3)\n",
    "      and action_type = 'tinkoff_platinum_approved_application'\n",
    "    ) u on u.id = v.id\n",
    "   left join prod_lookalike.urlfr_coeff t1 on t1.urlfr = v.urlfr and t1.segment_nm = 'la_apppr_ccall_2'\n",
    "   left join\n",
    "    (\n",
    "    select\n",
    "      urlfr,\n",
    "      score\n",
    "    from\n",
    "      mymd_t my      \n",
    "      inner join prod_features_liveinternet.urlfr_tgt_cnt_cumulative2 t on t.ymd = my.max_ymd\n",
    "    where\n",
    "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
    "      and (cnt_total > 300000 or cnt_positive > 10)\n",
    "    ) t2 on t2.urlfr = v.urlfr \n",
    "   group by\n",
    "    v.id\n",
    " ),\n",
    "st1 as (select nvl(a.score1,-100) as score, a.label as label from p a),\n",
    "st2 as (select nvl(a.score2,-100) as score, a.label as label from p a),\n",
    "cs1 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
    "    row_number() OVER (ORDER BY score DESC) as rank,\n",
    "    label\n",
    "  from st1),\n",
    "cs2 as (\n",
    "  select \n",
    "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
    "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
    "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
    "    row_number() OVER (ORDER BY score DESC) as rank,\n",
    "    label\n",
    "  from st2)\n",
    "  \n",
    "select \n",
    "  'Old coeffs' as name,\n",
    "  '#ymd' as test_ymd,\n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr,\n",
    "  avg(logloss) as logloss,\n",
    "  sum(if(rank < 10000,label,0))/10000 *count(*)/ sum(label) as lift_10k,\n",
    "  sum(if(rank < 50000,label,0))/50000 *count(*)/ sum(label) as lift_50k,\n",
    "  sum(label)/count(*) as pos_share,\n",
    "  count(*) as cnt\n",
    "from cs1\n",
    "\n",
    "union all\n",
    "\n",
    "select \n",
    "  concat('New coeffs ',max(my.max_ymd)) as name, \n",
    "  '#ymd' as test_ymd,\n",
    "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
    "  sum(precision)/sum(label) as auc_pr,\n",
    "  avg(logloss) as logloss,\n",
    "  sum(if(rank < 10000,label,0))/10000 *count(*)/ sum(label) as lift_10k,\n",
    "  sum(if(rank < 50000,label,0))/50000 *count(*)/ sum(label) as lift_50k,\n",
    "  sum(label)/count(*) as pos_share,\n",
    "  count(*) as cnt\n",
    "from cs2 a \n",
    "inner join mymd_t my\n",
    ";\n",
    "\n",
    "'''\n",
    "\n",
    "update_query = '''\n",
    "-- la_apppr_ccall2. Url coefs update\n",
    "with \n",
    "mymd_t as\n",
    " (\n",
    " select \n",
    "   max(ymd) as max_ymd\n",
    " from \n",
    "   prod_features_liveinternet.urlfr_tgt_cnt_cumulative2\n",
    " where\n",
    "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
    "      and ymd < date_add('#ymd',-3)\n",
    " )\n",
    "\n",
    "insert overwrite table prod_lookalike.urlfr_coeff partition (segment_nm = 'la_apppr_ccall_2')\n",
    "select\n",
    "      urlfr,\n",
    "      score,\n",
    "      current_timestamp() as load_dttm\n",
    "from\n",
    "      mymd_t my      \n",
    "      inner join prod_features_liveinternet.urlfr_tgt_cnt_cumulative2 t on t.ymd = my.max_ymd\n",
    "where\n",
    "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
    "      and (cnt_total > 300000 or cnt_positive > 10)\n",
    ";\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- la_apppr_ccall2. Url coefs comparison\n",
      "with \n",
      "mymd_t as\n",
      " (\n",
      " select \n",
      "   max(ymd) as max_ymd\n",
      " from \n",
      "   prod_features_liveinternet.urlfr_tgt_cnt_cumulative2\n",
      " where\n",
      "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
      "      and ymd < date_add('2017-04-19',-3)\n",
      " ),\n",
      "p as \n",
      " (\n",
      "  select \n",
      "    v.id, \n",
      "    max(if(u.id is Null,0,1)) as label, \n",
      "    max(t1.score) as score1, \n",
      "    max(t2.score) as score2 \n",
      "  from\n",
      "   (select id, url_fragment as urlfr from prod_odd.visit_feature where ymd = '2017-04-19') v\n",
      "   left join \n",
      "    (\n",
      "      select id\n",
      "      from prod_features_liveinternet.user_action \n",
      "      where ymd between '2017-04-19' and date_add('2017-04-19',3)\n",
      "      and action_type = 'tinkoff_platinum_approved_application'\n",
      "    ) u on u.id = v.id\n",
      "   left join prod_lookalike.urlfr_coeff t1 on t1.urlfr = v.urlfr and t1.segment_nm = 'la_apppr_ccall_2'\n",
      "   left join\n",
      "    (\n",
      "    select\n",
      "      urlfr,\n",
      "      score\n",
      "    from\n",
      "      mymd_t my      \n",
      "      inner join prod_features_liveinternet.urlfr_tgt_cnt_cumulative2 t on t.ymd = my.max_ymd\n",
      "    where\n",
      "      target = 'tinkoff_platinum_approved_application03@tinkoff_action'\n",
      "      and (cnt_total > 300000 or cnt_positive > 10)\n",
      "    ) t2 on t2.urlfr = v.urlfr \n",
      "   group by\n",
      "    v.id\n",
      " ),\n",
      "st1 as (select nvl(a.score1,-100) as score, a.label as label from p a),\n",
      "st2 as (select nvl(a.score2,-100) as score, a.label as label from p a),\n",
      "cs1 as (\n",
      "  select \n",
      "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
      "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
      "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
      "    row_number() OVER (ORDER BY score DESC) as rank,\n",
      "    label\n",
      "  from st1),\n",
      "cs2 as (\n",
      "  select \n",
      "    (1-label) * sum(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sl,\n",
      "    label * avg(label) OVER (ORDER BY score DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as precision,\n",
      "    label * log(1 + exp(-score)) + (1 - label) * log(1 + exp(score)) as logloss,\n",
      "    row_number() OVER (ORDER BY score DESC) as rank,\n",
      "    label\n",
      "  from st2)\n",
      "  \n",
      "select \n",
      "  'Old coeffs' as name,\n",
      "  '2017-04-19' as test_ymd,\n",
      "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
      "  sum(precision)/sum(label) as auc_pr,\n",
      "  avg(logloss) as logloss,\n",
      "  sum(if(rank < 10000,label,0))/10000 *count(*)/ sum(label) as lift_10k,\n",
      "  sum(if(rank < 50000,label,0))/50000 *count(*)/ sum(label) as lift_50k,\n",
      "  sum(label)/count(*) as pos_share,\n",
      "  count(*) as cnt\n",
      "from cs1\n",
      "\n",
      "union all\n",
      "\n",
      "select \n",
      "  concat('New coeffs ',max(my.max_ymd)) as name, \n",
      "  '2017-04-19' as test_ymd,\n",
      "  sum(sl)*1.0/((count(*)-max(sl))*max(sl)) as auc_roc,\n",
      "  sum(precision)/sum(label) as auc_pr,\n",
      "  avg(logloss) as logloss,\n",
      "  sum(if(rank < 10000,label,0))/10000 *count(*)/ sum(label) as lift_10k,\n",
      "  sum(if(rank < 50000,label,0))/50000 *count(*)/ sum(label) as lift_50k,\n",
      "  sum(label)/count(*) as pos_share,\n",
      "  count(*) as cnt\n",
      "from cs2 a \n",
      "inner join mymd_t my\n",
      ";\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ymd = (datetime.datetime.now().date() - datetime.timedelta(days = 7)).strftime('%Y-%m-%d')\n",
    "print(compare_query1.replace('#ymd', ymd))\n",
    "\n",
    "update = False\n",
    "if(update):\n",
    "    print(update_query.replace('#ymd', ymd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
