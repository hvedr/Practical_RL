{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "#sc.setCheckpointDir('/user/kposminin/checkpointdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End. Time of work 0:01:24.128930.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def repart(filename):\n",
    "    starttime = datetime.datetime.now()\n",
    "    sc.textFile(filename).repartition(32*8).saveAsTextFile('.'.join(filename.split('.')[:-1]))\n",
    "    print('End. Time of work {0}.'.format(datetime.datetime.now() - starttime))\n",
    "#repart(\"/user/kposminin/la_20160824.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "\n",
    "# Load and parse the data file.\n",
    "train = sc.textFile(\"/user/kposminin/la_20160817\") \\\n",
    "    .filter(lambda r: r.count('\\t') == 28) \\\n",
    "    .filter(lambda s: (s[0] == '1') or (hash(s) % 10000 == 1)) \\\n",
    "    .map(lambda r:r.split('\\t')) \\\n",
    "    .map(lambda r:[int(e) for e in r]) \\\n",
    "    .collect()\n",
    "\n",
    "test = sc.textFile(\"/user/kposminin/la_20160824\") \\\n",
    "    .filter(lambda r: r.count('\\t') == 28) \\\n",
    "    .filter(lambda s: (s[0] == '1') or (int(np.random.rand()*100) == 0)) \\\n",
    "    .map(lambda r:r.split('\\t')) \\\n",
    "    .map(lambda r:[int(e) for e in r]) \\\n",
    "    .collect()\n",
    "\n",
    "test_rdd = sc.textFile(\"/user/kposminin/la_20160824\") \\\n",
    "    .filter(lambda r: r.count('\\t') == 28) \\\n",
    "    .map(lambda r:r.split('\\t')) \\\n",
    "    .map(lambda r:[int(e) for e in r]) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Варьируем размер семплирования  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17907\n",
      "9460\n",
      "4581\n",
      "3004\n",
      "2083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "modelGBT = {}\n",
    "AUCROC={}\n",
    "\n",
    "for f in [1,2,5,10,20]:\n",
    "    train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    test1 = [r for r in test if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    s = len(train1)\n",
    "    print(s)\n",
    "    modelGBT[s] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=300, learning_rate=0.1,\n",
    "       max_depth=6, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC[s] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test1], \n",
    "        y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in test1])]\n",
    "    )\n",
    "    AUCROC['train '+ str(s)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train1], \n",
    "        y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in train1])]\n",
    "    )\n",
    "    AUCROC['smax '+ str(s)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test1], \n",
    "        y_score = [e[1] for e in test1]\n",
    "    )\n",
    "    AUCROC['train smax '+ str(s)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train1], \n",
    "        y_score = [e[1] for e in train1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1745159"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in modelGBT.keys():\n",
    "    AUCROC['test_full on {0}-model'.format(s)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in test])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC score from sample number:\n",
      "2083 0.99163\n",
      "3004 0.99337\n",
      "4581 0.99272\n",
      "9460 0.99299\n",
      "17907 0.99115\n",
      "smax 17907 0.85920\n",
      "smax 2083 0.85927\n",
      "smax 3004 0.85916\n",
      "smax 4581 0.85882\n",
      "smax 9460 0.85926\n",
      "test_full on 17907-model 0.99115\n",
      "test_full on 2083-model 0.99104\n",
      "test_full on 3004-model 0.99309\n",
      "test_full on 4581-model 0.99193\n",
      "test_full on 9460-model 0.99240\n",
      "train 17907 1.00000\n",
      "train 2083 1.00000\n",
      "train 3004 1.00000\n",
      "train 4581 1.00000\n",
      "train 9460 1.00000\n",
      "train smax 17907 0.85632\n",
      "train smax 2083 0.85822\n",
      "train smax 3004 0.85949\n",
      "train smax 4581 0.85605\n",
      "train smax 9460 0.85534\n"
     ]
    }
   ],
   "source": [
    "print('AUCROC score from sample number:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC.items())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Качество классификатора растет при снижении объема выборки вплоть до уровня паритета вероятности классов в выборке.\n",
    "Выбираем объем обучающей выборки немного с запасом в 9 тыс. примеров. Это соотвествует соотношению классов 5 к 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#append avg scores \n",
    "def append_param(sample):\n",
    "    return [r+[sum(r[14:16])/2,sum(r[14:17])/3,sum(r[14:18])/4,sum(r[14:19])/5,sum(r[14:21])/7,(r[14]+r[24])/2] for r in sample]\n",
    "train = append_param([r for r in train if int(np.random.rand()*2) == 0])\n",
    "test = append_param(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8911"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open('test2.txt','w').write(str(AUCROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_table_to_file(table, filename):\n",
    "    f = open(filename,'w+')\n",
    "    #f.write('label,' + ','.join(columns)+'\\n')\n",
    "    f.write('\\n'.join([','.join([str(e) for e in r]) for r in table]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = '''smax ,savg ,ssum ,smedian ,sstd ,cntrepeat ,cntuniq \n",
    ",duration ,mobile ,emailru ,vkru ,okru ,social_other , s1 ,s2 ,s3 ,s4 ,s5 ,s6 ,s7 ,s8 ,s9 ,s10 , \n",
    "sm1 ,sm2 ,sm3 ,sm4 ,sm5'''.replace(' ','').replace('\\n','').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [r for r in train if (r[0] == 1) or int(np.random.rand()*10) == 0]\n",
    "test = [r for r in test if (r[0] == 1) or int(np.random.rand()*1) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Варьируем количество деревьев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a GradientBoostedTrees model.\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "modelGBT = {}\n",
    "AUCROC1={}\n",
    "for n in [20,30,50,80,100,200,300,500,800]:\n",
    "    modelGBT[n] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=n, learning_rate=0.1,\n",
    "       max_depth=6, random_state=0).fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "    AUCROC1[n] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[n].predict_proba([e[1:] for e in test])]\n",
    "    )\n",
    "    AUCROC1['train '+str(n)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [r[1] for r in modelGBT[n].predict_proba([e[1:] for e in train])]\n",
    "    )\n",
    "AUCROC1['smax'] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    ")\n",
    "AUCROC1['train smax'] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [e[1] for e in train]\n",
    ")\n",
    "#print(AUCROC)\n",
    "# Evaluate model on test instances and compute test error\n",
    "##predictions = model.predict(test.map(lambda x: x.features))\n",
    "#predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC test sample score from GBT trees number:\n",
      "20 0.99083\n",
      "30 0.99142\n",
      "50 0.99347\n",
      "80 0.99266\n",
      "100 0.99240\n",
      "200 0.98955\n",
      "300 0.98644\n",
      "500 0.97686\n",
      "800 0.97573\n",
      "smax 0.85920\n",
      "train 100 1.00000\n",
      "train 20 0.99841\n",
      "train 200 1.00000\n",
      "train 30 0.99890\n",
      "train 300 1.00000\n",
      "train 50 0.99972\n",
      "train 500 1.00000\n",
      "train 80 0.99998\n",
      "train 800 1.00000\n",
      "train smax 0.84172\n"
     ]
    }
   ],
   "source": [
    "print('AUCROC test sample score from GBT trees number:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC1.items())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Если брать более 100 деревьев, то происходит переобучение на выборке.\n",
    "Выбираем 80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Вариация глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted(zip(modelGBT[80].feature_importances_,columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#modelGBT = {}\n",
    "#AUCROC1 = {'smax':AUCROC1['smax'], 'train smax':AUCROC1['train smax']}\n",
    "for m in [1,3,4,5,6,7,8,9,10,11,15]:\n",
    "    modelGBT[m] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=80, learning_rate=0.1,\n",
    "       max_depth=m, random_state=0).fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "    AUCROC1[m] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[m].predict_proba([e[1:] for e in test])]\n",
    "    )\n",
    "    AUCROC1['train '+str(m)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [r[1] for r in modelGBT[m].predict_proba([e[1:] for e in train])]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC test sample score from GBT tree depth:\n",
      "1 0.99055\n",
      "3 0.99292\n",
      "4 0.99108\n",
      "5 0.99282\n",
      "6 0.99240\n",
      "7 0.99263\n",
      "8 0.99152\n",
      "9 0.99073\n",
      "10 0.99075\n",
      "11 0.98913\n",
      "15 0.98571\n",
      "smax 0.85920\n",
      "train 1 0.98673\n",
      "train 10 1.00000\n",
      "train 11 1.00000\n",
      "train 15 1.00000\n",
      "train 3 0.99752\n",
      "train 4 0.99943\n",
      "train 5 0.99992\n",
      "train 6 1.00000\n",
      "train 7 1.00000\n",
      "train 8 1.00000\n",
      "train 9 1.00000\n",
      "train smax 0.84172\n"
     ]
    }
   ],
   "source": [
    "print('AUCROC test sample score from GBT tree depth:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC1.items())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### До глубины 7 разница несущественна, далее начинается переобучение.\n",
    "Выбираем глубину в 6 нодов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = modelGBT[6]\n",
    "import pickle\n",
    "pickle.dump(model,open('modelGBT.pck','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99239522347437292"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model.feature_importances_,columns))\n",
    "sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in model.predict_proba([e[1:] for e in test])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = sorted([(r[0],int(10**4 * model.predict_proba(r[1:])[0][1])) for r in test],key = lambda r: -r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1745159, 1135)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postot = sum([r[0] for r in res])\n",
    "len(res),postot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of positives in sample top quantile\n",
      "quantile\tpositive rate\tclass share\n",
      "0.001\t60.53%\t64.93%\n",
      "0.005\t82.56%\t12.03%\n",
      "0.01\t86.96%\t5.99%\n",
      "0.02\t91.19%\t3.06%\n",
      "0.03\t93.57%\t2.07%\n",
      "0.05\t96.30%\t1.27%\n",
      "0.1\t98.41%\t0.64%\n"
     ]
    }
   ],
   "source": [
    "print('Share of positives in sample top quantile\\nquantile\\tpositive rate\\tclass share')\n",
    "for q in [0.001,0.005,0.01,0.02,0.03,0.05,0.1]:\n",
    "    t = int(len(res) * q)\n",
    "    p = sum([r[0] for r in res[:t]])\n",
    "    print('{0}\\t{1:.2%}\\t{2:.2%}'.format(q,1.*p/postot,p*1./(t-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res1 = test_rdd.map(lambda r:(float(r[0]),model.predict_proba(r[1:])[0][1])).collect()\n",
    "ar = sklearn.metrics.roc_auc_score(y_true = [e[0] for e in res1], y_score = [e[1] for e in res1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o28.defaultParallelism.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:234)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\npy4j.Gateway.invoke(Gateway.java:214)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:79)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:68)\npy4j.GatewayConnection.run(GatewayConnection.java:209)\njava.lang.Thread.run(Thread.java:745)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:106)\n\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2086)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b3ffd49c7376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36mparallelize\u001b[1;34m(self, c, numSlices)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \"\"\"\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mnumSlices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumSlices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnumSlices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultParallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/context.py\u001b[0m in \u001b[0;36mdefaultParallelism\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    346\u001b[0m         reduce tasks)\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultParallelism\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 813\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    307\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    309\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o28.defaultParallelism.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:234)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\npy4j.Gateway.invoke(Gateway.java:214)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:79)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:68)\npy4j.GatewayConnection.run(GatewayConnection.java:209)\njava.lang.Thread.run(Thread.java:745)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:106)\n\tat org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2086)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model feature importances\n",
      "smax 0.11443\n",
      "s1 0.11212\n",
      "ssum 0.07378\n",
      "duration 0.06721\n",
      "sm1 0.05852\n",
      "sstd 0.05731\n",
      "cntrepeat 0.05340\n",
      "savg 0.05099\n",
      "sm5 0.02901\n",
      "smedian 0.02864\n",
      "s3 0.02492\n",
      "s4 0.02281\n",
      "s2 0.02069\n",
      "sm2 0.01928\n",
      "s10 0.01853\n",
      "s5 0.01323\n",
      "cntuniq 0.01192\n",
      "s6 0.01077\n",
      "s8 0.01075\n",
      "sm3 0.01050\n",
      "vkru 0.00992\n",
      "sm4 0.00879\n",
      "s7 0.00876\n",
      "s9 0.00752\n",
      "emailru 0.00590\n",
      "okru 0.00163\n",
      "mobile 0.00148\n",
      "social_other 0.00004\n"
     ]
    }
   ],
   "source": [
    "print('Model feature importances\\n'+'\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(zip(columns,model.feature_importances_), key = lambda r:-r[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = sc.parallelize(range(1000)).map(lambda r: (1,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[499, 399, 299, 199, 99, 49, 29, 19, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "prob = [0.5,0.6,0.7,0.8,0.9,0.95,0.97,0.98,0.99,1]\n",
    "res = r \\\n",
    "    .map(lambda r:[r[0] * (r[1]>p*1000) for p in prob]) \\\n",
    "    .reduce(lambda x,y:[x[i]+y[i] for i in range(len(x))])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
