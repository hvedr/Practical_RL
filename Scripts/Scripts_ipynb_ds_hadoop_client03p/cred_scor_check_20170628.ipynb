{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка работоспособности кредитного скора, поставленного на регламент, на периоде 2017-06-05 -- 2017-06-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 1)\n",
    "        .set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "        .set('spark.driver.memory','4g')\n",
    "        .set(\"spark.executor.memory\", '2g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 1048)\n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metrics(y_true,y_score,lift = None, return_str = False):\n",
    "    import sklearn\n",
    "    import collections\n",
    "    \n",
    "    if True:\n",
    "        \n",
    "        res = collections.OrderedDict()\n",
    "        samp_size = len(y_true)\n",
    "        res['Sample size'] = samp_size\n",
    "        res['Posit share'] = sum(y_true) * 1./ samp_size\n",
    "        res['Sample size'] = len(y_true)\n",
    "        res['AUC ROC'] = sklearn.metrics.roc_auc_score(y_true = y_true, y_score = y_score)\n",
    "        res['AUC PR'] = sklearn.metrics.average_precision_score( y_true,  y_score)\n",
    "        res['Log loss'] = sklearn.metrics.log_loss(y_true = y_true, y_pred = y_score)\n",
    "        if lift:\n",
    "            predictions_and_labels = sorted(zip(y_score,y_true), key = lambda e:-e[0])\n",
    "            for l in lift:\n",
    "                res['Lift ' + str(l)] = sum([e[1] for e in predictions_and_labels[:int(l * samp_size)]]) * 1. / int(l * samp_size) / res['Posit share']                \n",
    "        if return_str:\n",
    "            res = '\\n'.join(['{:<12}: {:.5f}'.format(k,v) for (k,v) in res.items()]) + '.'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sas_query = '''\n",
    "\n",
    "%mAssignHadooplibs;\n",
    "\n",
    "proc sql;\n",
    "create table hd_ccall.full_app_201706 as \n",
    "select\n",
    "  put(datepart(create_dt),YYMMDD10.) as ymd,\n",
    "  b.phone_mobile,\n",
    "  b.utm_campaign,\n",
    "  b.hl_rk,  \n",
    "  case when status = 'В работе' then 1 else 0 end as in_work,\n",
    "  case when a.financial_application_rk is not Null then 1 else 0 end as full_app,\n",
    "  case when a.decision_dt is not Null then 1 else 0 end as considered,\n",
    "  case when a.decision_approve_dt is not Null then 1 else 0 end as approve,\n",
    "  case when a.utilization_dt is not Null then 1 else 0 end as utilization\n",
    "  \n",
    "from emart.short_applications_current b \n",
    "  inner join emart.financial_account_application a on b.financial_application_rk = a.financial_application_rk\n",
    "where (not b.status in ('Дубль', 'Черный список'))\n",
    " and (a.financial_application_rk is not Null)\n",
    " and (b.phone_mobile is not Null)\n",
    " and create_dt >= '05Jun2017:0:0:0'dt  \n",
    ";\n",
    "quit;\n",
    "'''\n",
    "\n",
    "hive_query = '''\n",
    "\n",
    "-- cred score efficiency check\n",
    "create table user_kposminin.cred_scor_test_201706 as\n",
    "select\n",
    "  a.*,ps.score\n",
    "  from prod_ccall.full_app_201706 a\n",
    " inner join prod_lookalike.phone_x_segment ps on substr(ps.phone_num,3,20) = substr(a.phone_mobile, 2,20) and ps.ymd = date_add(a.ymd, -1)\n",
    " where ps.segment_nm = 'cred_score_1'   \n",
    ";\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ymd</th>\n",
       "      <th>phone_mobile</th>\n",
       "      <th>utm_campaign</th>\n",
       "      <th>hl_rk</th>\n",
       "      <th>in_work</th>\n",
       "      <th>full_app</th>\n",
       "      <th>considered</th>\n",
       "      <th>approve</th>\n",
       "      <th>utilization</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>89203681890</td>\n",
       "      <td>cold_psp</td>\n",
       "      <td>113612094.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>89507651959</td>\n",
       "      <td>cold_psp_rj</td>\n",
       "      <td>113570643.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>89108991330</td>\n",
       "      <td>None</td>\n",
       "      <td>113670685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>89180429138</td>\n",
       "      <td>None</td>\n",
       "      <td>113847803.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>89822992377</td>\n",
       "      <td>cold_mail_void</td>\n",
       "      <td>113701711.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ymd phone_mobile    utm_campaign        hl_rk  in_work  full_app  \\\n",
       "0  2017-06-08  89203681890        cold_psp  113612094.0      0.0       1.0   \n",
       "1  2017-06-08  89507651959     cold_psp_rj  113570643.0      0.0       1.0   \n",
       "2  2017-06-08  89108991330            None  113670685.0      0.0       1.0   \n",
       "3  2017-06-08  89180429138            None  113847803.0      0.0       1.0   \n",
       "4  2017-06-08  89822992377  cold_mail_void  113701711.0      0.0       1.0   \n",
       "\n",
       "   considered  approve  utilization     score  \n",
       "0         1.0      0.0          0.0  0.394834  \n",
       "1         1.0      0.0          0.0  0.258343  \n",
       "2         1.0      0.0          0.0  0.433169  \n",
       "3         1.0      1.0          0.0  0.433586  \n",
       "4         1.0      0.0          0.0  0.402059  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hc.sql('select * from user_kposminin.cred_scor_test_201706 where considered = 1').toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.groupby('utm_campaign').count().sort_values('ymd', ascending = False)\n",
    "df1 = df [df['utm_campaign'].map(lambda v: 'cold_liru' in v if v else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all segments\n",
      "AUC ROC 0.6636, AUC PR 0.5330, avg_label 0.3903,count 27943\n",
      "Avg approve for score > 0.35 is 0.50088822568\n",
      "Binning by score\n",
      "      approve  utilization  min_score   cnt\n",
      "scb                                        \n",
      "0.0  0.145311     0.022190   0.030455  2794\n",
      "1.0  0.240157     0.034717   0.189089  2794\n",
      "2.0  0.304223     0.037938   0.243828  2794\n",
      "3.0  0.329277     0.039370   0.283426  2794\n",
      "4.0  0.377818     0.040072   0.317585  2795\n",
      "5.0  0.400859     0.049392   0.351297  2794\n",
      "6.0  0.448819     0.046528   0.387890  2794\n",
      "7.0  0.506800     0.057981   0.426188  2794\n",
      "8.0  0.538296     0.061560   0.468499  2794\n",
      "9.0  0.611449     0.087299   0.519920  2795\n",
      "----------------------------------------\n",
      "\n",
      "cold segments\n",
      "AUC ROC 0.6596, AUC PR 0.6060, avg_label 0.4699,count 14070\n",
      "Avg approve for score > 0.35 is 0.574786605384\n",
      "Binning by score\n",
      "      approve  utilization  min_score   cnt\n",
      "scb                                        \n",
      "0.0  0.201991     0.022048   0.036851  1406\n",
      "1.0  0.309168     0.029140   0.203014  1407\n",
      "2.0  0.375977     0.019900   0.256892  1407\n",
      "3.0  0.432125     0.027008   0.296546  1407\n",
      "4.0  0.470505     0.029851   0.330742  1407\n",
      "5.0  0.486141     0.029851   0.364396  1407\n",
      "6.0  0.542289     0.037669   0.401288  1407\n",
      "7.0  0.589197     0.036247   0.438714  1407\n",
      "8.0  0.614072     0.036247   0.477550  1407\n",
      "9.0  0.677328     0.055437   0.525219  1407\n",
      "----------------------------------------\n",
      "\n",
      "cold_liru segments\n",
      "AUC ROC 0.7380, AUC PR 0.5143, avg_label 0.2938,count 953\n",
      "Avg approve for score > 0.35 is 0.495652173913\n",
      "Binning by score\n",
      "      approve  utilization  min_score  cnt\n",
      "scb                                       \n",
      "0.0  0.063158     0.000000   0.038116   95\n",
      "1.0  0.084211     0.010526   0.102889   95\n",
      "2.0  0.157895     0.021053   0.147559   95\n",
      "3.0  0.157895     0.031579   0.196408   95\n",
      "4.0  0.260417     0.041667   0.237379   96\n",
      "5.0  0.347368     0.000000   0.282661   95\n",
      "6.0  0.315789     0.052632   0.332733   95\n",
      "7.0  0.463158     0.052632   0.382565   95\n",
      "8.0  0.473684     0.042105   0.435884   95\n",
      "9.0  0.614583     0.072917   0.488912   96\n",
      "----------------------------------------\n",
      "\n",
      "cold_liru_test segment\n",
      "AUC ROC 0.7092, AUC PR 0.3512, avg_label 0.1769,count 458\n",
      "Avg approve for score > 0.35 is 0.369047619048\n",
      "Binning by score\n",
      "      approve  utilization  min_score  cnt\n",
      "scb                                       \n",
      "0.0  0.111111     0.000000   0.038116   45\n",
      "1.0  0.021739     0.000000   0.082014   46\n",
      "2.0  0.065217     0.021739   0.116821   46\n",
      "3.0  0.111111     0.022222   0.144149   45\n",
      "4.0  0.065217     0.021739   0.176423   46\n",
      "5.0  0.152174     0.021739   0.213692   46\n",
      "6.0  0.333333     0.066667   0.242893   45\n",
      "7.0  0.195652     0.000000   0.288513   46\n",
      "8.0  0.260870     0.065217   0.340200   46\n",
      "9.0  0.456522     0.021739   0.425719   46\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def measure_dataset(df1):\n",
    "    print('AUC ROC {:.4f}, AUC PR {:.4f}, avg_label {:.4f},count {}'.format(\n",
    "            sklearn.metrics.roc_auc_score(y_true = df1['approve'],y_score = df1['score']),\n",
    "            sklearn.metrics.average_precision_score(y_true = df1['approve'],y_score = df1['score']),\n",
    "            df1['approve'].mean(),\n",
    "            df1['approve'].count()\n",
    "        ))\n",
    "    df1['scb'] = pd.cut(df1['score'], bins = df1['score'].quantile(np.arange(0,1.1,0.1)).values, labels  = False).values\n",
    "    print('Avg approve for score > 0.35 is {}'.format(df1.query('score > 0.35')['approve'].mean()))\n",
    "    df_res = df1.groupby('scb')[['approve','utilization']].mean()\n",
    "    df_res['min_score'] = df1.groupby('scb')['score'].min()\n",
    "    df_res['cnt'] = df1.groupby('scb')['score'].count()\n",
    "    print('Binning by score')\n",
    "    print(df_res)\n",
    "    print('-'*40 + '\\n')\n",
    "    \n",
    "print('all segments')\n",
    "measure_dataset(df)\n",
    "    \n",
    "print('cold segments')\n",
    "measure_dataset(df [df['utm_campaign'].map(lambda v: 'cold_' in v if v else False)])\n",
    "    \n",
    "print('cold_liru segments')\n",
    "measure_dataset(df [df['utm_campaign'].map(lambda v: 'cold_liru' in v if v else False)])\n",
    "\n",
    "print('cold_liru_test segment')\n",
    "measure_dataset(df [df['utm_campaign'].map(lambda v: 'cold_liru_test' in v if v else False)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка работоспособности кредитного скора, поставленного на регламент, на 20 днях, подтверждает работоспособность скоринга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
