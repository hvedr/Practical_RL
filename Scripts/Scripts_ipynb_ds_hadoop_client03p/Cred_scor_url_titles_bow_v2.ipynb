{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cred_scor_url_titles_bow\n",
    "## Анализ заголовков страниц в задаче кред скоринга\n",
    "DMP-3643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 16)\n",
    "        .set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "        .set('spark.driver.memory','16g')\n",
    "        .set(\"spark.executor.memory\", '16g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 1048)\n",
    "       )\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слова как множество: с коэф. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[525] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(numFeatures = 2 ** 17)\n",
    "train_data = (hc.sql('select phone_num, call_ymd, approve, bow from user_kposminin.cred_scor_title_bow1 where not approve is Null')\n",
    "                .filter('call_ymd < \"2016-11-01\"')\n",
    "                .rdd\n",
    "                .map(lambda row:LabeledPoint(row.approve,hashingTF.transform(row.bow)))\n",
    "                .map(lambda lp:LabeledPoint(lp.label,SparseVector(lp.features.size,lp.features.indices,[1] * len(lp.features.indices))))\n",
    "             )\n",
    "\n",
    "test_data = (hc.sql('select phone_num, call_ymd, approve, bow from user_kposminin.cred_scor_title_bow1 where not approve is Null')\n",
    "                .filter('call_ymd >= \"2016-11-01\"')\n",
    "                .rdd\n",
    "                .map(lambda row:LabeledPoint(row.approve,hashingTF.transform(row.bow)))\n",
    "                .map(lambda lp:LabeledPoint(lp.label,SparseVector(lp.features.size,lp.features.indices,[1] * len(lp.features.indices))))\n",
    "             )\n",
    "train_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = train_data.take(5)\n",
    "#lp = a[0]\n",
    "#SparseVector(lp.features.size,lp.features.indices,[1] * len(lp.features.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train NaiveBayes model\n",
    "\n",
    "modelNB = NaiveBayes.train(train_data)\n",
    "\n",
    "def predict_proba_NB(f,model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability. f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Function selects winning class with it probability.\n",
    "    Output: tuple with model selected class number as first element (type int) and it probability as second (type float).\n",
    "    '''\n",
    "    logp = [[i,f.dot(model.theta[i]) + model.pi[i]] for i in range(len(model.theta))] # classes with log probabilities\n",
    "    wi = sorted(logp, key = lambda e:  - e[1])[0][0] #winning index\n",
    "    prob = 1./sum([np.exp(e[1] - logp[wi][1]) for e in logp]) #winning class probability\n",
    "    return wi, prob\n",
    "\n",
    "def predict_proba_NB_2(f, model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability for 2-class classification.\n",
    "    f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Output: probability of class 1 (type float).\n",
    "    '''\n",
    "    if len(model.theta) != 2:\n",
    "        print('Model is NOT a 2-class classifier')\n",
    "        return None\n",
    "    logp = [f.dot(model.theta[i]) + model.pi[i] for i in range(2)]    \n",
    "    return 1./(1. + np.exp(logp[0] - logp[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LogisticRegression model\n",
    "modelLR = LogisticRegressionWithSGD.train(train_data)\n",
    "modelLR.clearThreshold()\n",
    "\n",
    "#LogisticRegression model\n",
    "#modelLR2 = LogisticRegressionWithSGD.train(train_data,regType = 'l1',regParam = 0.05)\n",
    "#modelLR2.clearThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nML approach\\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\\nhashingTF = HashingTF(inputCol=\"bow\", outputCol=\"Features\", numFeatures=2**17)\\ndf_train_tf = hashingTF.transform(df_train)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ML approach\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "hashingTF = HashingTF(inputCol=\"bow\", outputCol=\"Features\", numFeatures=2**17)\n",
    "df_train_tf = hashingTF.transform(df_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72719, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = test_data.map( lambda lp: pyspark.sql.Row(\n",
    "        Label = lp.label,\n",
    "        NaiveBayes = float(predict_proba_NB_2(lp.features, modelNB)),\n",
    "        LogisticRegression = float(modelLR.predict(lp.features))\n",
    "    )).toDF().toPandas()\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods AUCROC performance on test sample (218157 samples with 28991 positives):\n",
      "LogisticRegression            0.58303\n",
      "NaiveBayes                    0.62817\n"
     ]
    }
   ],
   "source": [
    "#Build AUCROC metric and print results\n",
    "import sklearn,sklearn.metrics\n",
    "AUCROC = {}\n",
    "for c in df_test.columns:\n",
    "    if c!= 'Label':\n",
    "        AUCROC[c] = sklearn.metrics.roc_auc_score(df_test['Label'],df_test[c])\n",
    "        \n",
    "print('Methods AUCROC performance on test sample ({0:.0f} samples with {1:.0f} positives):\\n'.format(df_test.size,df_test['Label'].sum()) +\n",
    "     '\\n'.join(['{0:<30}{1:.5f}'.format(k,v) for (k,v) in AUCROC.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 лучше чем tf. NaiveBayes         AUC ROC           0.62817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestModel' object has no attribute 'clearThreshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-29c30940bd78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                      \u001b[0mnumTrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureSubsetStrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                      impurity='gini', maxDepth=4, maxBins=32)\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclfRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclearThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Evaluate model on test instances and compute test error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestModel' object has no attribute 'clearThreshold'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "\n",
    "\n",
    "# Load and parse the data file into an RDD of LabeledPoint.\n",
    "\n",
    "clfRF = RandomForest.trainClassifier(train_data, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=200, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=4, maxBins=32)\n",
    "#clfRF.clearThreshold()\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "#predictions = model.predict(testData.map(lambda x: x.features))\n",
    "pred_labels = test_data.map(lambda lp: lp.label, float(clfRF.predict(lp.features))).collect()\n",
    "print('Random Forest classifier AUC ROC {}'.format(\n",
    "    sklearn.metrics.roc_aur_score(\n",
    "        y_true  = [e[1] for e in pred_labels],\n",
    "        y_score = [e[0] for e in pred_labels]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "#testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "#print('Test Error = ' + str(testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Random Forest classifier AUC ROC {}'.format(\\n    sklearn.metrics.roc_auc_score(\\n        y_true  = [e[1] for e in pred_labels],\\n        y_score = [e[0] for e in pred_labels]\\n        )\\n    ))\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.mllib.tree\n",
    "def predict_proba(rf_model, data):\n",
    "    '''\n",
    "    This wrapper overcomes the \"binary\" nature of predictions in the native\n",
    "    RandomForestModel. \n",
    "    '''\n",
    "    \n",
    "    # Collect the individual decision tree models by calling the underlying\n",
    "    # Java model. These are returned as JavaArray defined by py4j.\n",
    "    trees = rf_model._java_model.trees()\n",
    "    ntrees = rf_model.numTrees()\n",
    "    scores = pyspark.mllib.tree.DecisionTreeModel(trees[0]).predict(data.map(lambda x: x.features))\n",
    "\n",
    "    # For each decision tree, apply its prediction to the entire dataset and\n",
    "    # accumulate the results using 'zip'.\n",
    "    for i in range(1,ntrees):\n",
    "        dtm = pyspark.mllib.tree.DecisionTreeModel(trees[i])\n",
    "        scores = scores.zip(dtm.predict(data.map(lambda x: x.features)))\n",
    "        scores = scores.map(lambda x: x[0] + x[1])\n",
    "\n",
    "    # Divide the accumulated scores over the number of trees\n",
    "    return scores.map(lambda x: x/ntrees)\n",
    "\n",
    "def testError(lap):\n",
    "    testErr = lap.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "    print('Test Error = ' + str(testErr))\n",
    "\n",
    "pred_labels = predict_proba(clfRF,test_data).collect()\n",
    "\n",
    "'''\n",
    "print('Random Forest classifier AUC ROC {}'.format(\n",
    "    sklearn.metrics.roc_auc_score(\n",
    "        y_true  = [e[1] for e in pred_labels],\n",
    "        y_score = [e[0] for e in pred_labels]\n",
    "        )\n",
    "    ))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'PipelinedRDD' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-b567d3a10372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'PipelinedRDD' has no len()"
     ]
    }
   ],
   "source": [
    "len(pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[phone_num: string, call_ymd: string, approve: int, bow: array<string>, TF: vector, TFIDF: vector]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "#hashingTF = HashingTF(numFeatures = 2 ** 17)\n",
    "train_data = (hc.sql('''select phone_num, call_ymd, approve, bow \n",
    "                        from user_kposminin.cred_scor_title_bow1 \n",
    "                        where (not approve is Null)\n",
    "                        and call_ymd < \"2016-10-01\"\n",
    "                        ''')                \n",
    "             )\n",
    "\n",
    "test_data =  (hc.sql('''select phone_num, call_ymd, approve, bow \n",
    "                        from user_kposminin.cred_scor_title_bow1 \n",
    "                        where (not approve is Null)\n",
    "                        and call_ymd >= \"2016-10-01\"\n",
    "                        ''')                \n",
    "             )\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"bow\", outputCol=\"TF\", numFeatures=2 ** 16)\n",
    "train_featurizedData = hashingTF.transform(train_data)\n",
    "test_featurizedData = hashingTF.transform(test_data)\n",
    "\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"TFIDF\")\n",
    "idfModel = idf.fit(train_featurizedData)\n",
    "train_rescaledData = idfModel.transform(train_featurizedData)\n",
    "test_rescaledData = idfModel.transform(test_featurizedData)\n",
    "\n",
    "train_rescaledData.cache()\n",
    "test_rescaledData.cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#train_rescaledData.show()\n",
    "#a = train_rescaledData.toPandas()\n",
    "#sv = a.iloc[0,4]\n",
    "#type(sv)\n",
    "#train_rescaledData[\"TF\"].getItem('indices')\n",
    "#train_rescaledData.schema\n",
    "#pyspark.ml.linalg.SparseVector(sv.size,sv.indices,[1]*len(sv.indices))\n",
    "#train_rescaledData.select(\"TF\").rdd.map(lambda r: pyspark.sql.Row(ones=pyspark.ml.linalg.SparseVector(r[0].size,r[0].indices,[1]*len(r[0].indices)))).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions\n",
    "import pyspark.sql.types\n",
    "import pyspark.sql\n",
    "#pyspark.sql.types\n",
    "#pyspark.sql.types.VectorUDT()\n",
    "#train_rescaledData.show()\n",
    "#toDoublefunc = UserDefinedFunction(lambda x: x,DoubleType())\n",
    "#changedTypedf = joindf.withColumn(\"label\",toDoublefunc(joindf['show']))\n",
    "\n",
    "#to_ones_func = pyspark.sql.functions.udf(lambda sv: pyspark.ml.linalg.SparseVector(sv.size,sv.indices,[1]*sv.size),pyspark.ml.linalg.SparseVector)\n",
    "\n",
    "train_rescaledData.withColumn(\n",
    "    \"Ones\", \n",
    "    train_rescaledData.select(\"TF\").rdd.map(lambda r: pyspark.sql.Row(ones=pyspark.ml.linalg.SparseVector(r[0].size,r[0].indices,[1]*len(r[0].indices)))).toDF()['ones']\n",
    "   ).show()\n",
    "\n",
    "#train_data.withColumn(\"Ones\", train_data[\"approve\"]+1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "TFIDF\n",
      "\n",
      "Naive Bayes metrics on test\n",
      "        areaUnderROC\t0.490816983125\n",
      "         areaUnderPR\t0.402173464803\n",
      "\n",
      "Random Forest metrics on test\n",
      "        areaUnderROC\t0.636960561114\n",
      "         areaUnderPR\t0.525347154553\n",
      "\n",
      "Logistic Regression metrics on test\n",
      "        areaUnderROC\t0.631053664803\n",
      "         areaUnderPR\t0.516976789034\n",
      "----------------------------------------------------------------------\n",
      "TF\n",
      "\n",
      "Naive Bayes metrics on test\n",
      "        areaUnderROC\t0.49830793005\n",
      "         areaUnderPR\t0.406598254595\n",
      "\n",
      "Random Forest metrics on test\n",
      "        areaUnderROC\t0.636960561114\n",
      "         areaUnderPR\t0.525347154553\n",
      "\n",
      "Logistic Regression metrics on test\n",
      "        areaUnderROC\t0.631053664803\n",
      "         areaUnderPR\t0.516976789034\n"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.classification \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "fout = open('results_20170706.txt','w')\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': pyspark.ml.classification.LogisticRegression(maxIter=50, regParam=0.3),\n",
    "    'Naive Bayes': pyspark.ml.classification.NaiveBayes(smoothing=1.0, modelType=\"multinomial\"),\n",
    "    'Random Forest': pyspark.ml.classification.RandomForestClassifier(numTrees=100, maxDepth=5, labelCol=\"label\", seed=42)    \n",
    "}\n",
    "\n",
    "features_list = ['TFIDF','TF']\n",
    "\n",
    "for feats in features_list:\n",
    "    print('-'*70 + '\\n' + feats)\n",
    "    for clfname,clf in classifiers.items():\n",
    "        model = clf.fit(train_rescaledData.selectExpr('approve as label',feats + ' as features'))\n",
    "        test_predict = model.transform(test_rescaledData.selectExpr('approve as label',feats + ' as features'))\n",
    "        evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "        string = '\\n' + clfname + ' metrics on test'\n",
    "        print(string)\n",
    "        fout.write(string)\n",
    "        for metric in (\"areaUnderROC\",\"areaUnderPR\"):\n",
    "            string = '{:>20}\\t{:<10}'.format(metric, evaluator.evaluate(test_predict.selectExpr('label','rawPrediction'), {evaluator.metricName: metric}))\n",
    "            print(string)\n",
    "            fout.write(string)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        areaUnderROC\t0.619979838736\n",
      "         areaUnderPR\t0.50721843726\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# Prepare training and test data.\n",
    "#train, cv = train_rescaledData.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "lr = LinearRegression(maxIter=100)\n",
    "feats = 'TFIDF'\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.5,0.1, 0.01,0.001]) \\\n",
    "    .build()\n",
    "\n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(train_rescaledData.selectExpr('approve as label',feats + ' as features'))\n",
    "\n",
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "#model.transform(test_rescaledData)\\\n",
    "#    .select(\"features\", \"label\", \"prediction\")\\\n",
    "#    .show()\n",
    "    \n",
    "test_predict = model.transform(test_rescaledData.selectExpr('approve as label',feats + ' as features'))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "#string = '\\n' + clfname + ' metrics on test'\n",
    "#print(string)\n",
    "#        fout.write(string)\n",
    "\n",
    "for metric in (\"areaUnderROC\",\"areaUnderPR\"):\n",
    "    string = '{:>20}\\t{:<10}'.format(metric, evaluator.evaluate(test_predict.selectExpr('label','prediction'), {evaluator.metricName: metric}))\n",
    "    print(string)\n",
    "    #fout.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Подбор параметра по кросс-валидации как-то не помог\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем факторы из боевой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "create_query = '''\n",
    "set hive.support.quoted.identifiers=none;\n",
    "create table user_kposminin.cred_score_oldfeats_and_bow as\n",
    "select a.*,\n",
    "       b.`(phone_num|call_ymd|approve)?+.+`\n",
    "  from user_kposminin.cred_scor_title_bow1 a\n",
    "  full join user_kposminin.id_feat_ccall b on substr(a.phone_num,3,20) = substr(b.phone_mobile,2,20) and b.call_ymd = a.call_ymd\n",
    ";\n",
    "set hive.support.quoted.identifiers=column;\n",
    "'''\n",
    "\n",
    "#hc.sql(create_query)\n",
    "#double_feats = hc.sql('select * from user_kposminin.cred_score_oldfeats_and_bow where (not phone_num is Null) and (not phone_mobile is Null)')\n",
    "\n",
    "#hashingTF = HashingTF(numFeatures = 2 ** 17)\n",
    "train_ddata = (hc.sql('''select * \n",
    "                        from user_kposminin.cred_score_oldfeats_and_bow \n",
    "                        where (not phone_num is Null) \n",
    "                        and (not phone_mobile is Null) \n",
    "                        and (not approve is Null)\n",
    "                        and call_ymd < \"2016-10-01\"\n",
    "                        ''')                \n",
    "             )\n",
    "\n",
    "test_ddata =  (hc.sql('''select * \n",
    "                        from user_kposminin.cred_score_oldfeats_and_bow \n",
    "                        where (not phone_num is Null) \n",
    "                        and (not phone_mobile is Null) \n",
    "                        and (not approve is Null)\n",
    "                        and call_ymd < \"2016-10-01\"\n",
    "                        ''')                \n",
    "              )\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"bow\", outputCol=\"TF\", numFeatures = 2 ** 16)\n",
    "train_featurizedData = hashingTF.transform(train_ddata)\n",
    "test_featurizedData = hashingTF.transform(test_ddata)\n",
    "\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"TFIDF\")\n",
    "idfModel = idf.fit(train_featurizedData)\n",
    "train_ddata = idfModel.transform(train_featurizedData)\n",
    "test_ddata = idfModel.transform(test_featurizedData)\n",
    "\n",
    "#train_ddata.cache()\n",
    "#test_ddata.cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.ml.linalg as pmlla\n",
    "\n",
    "train_w_feat = (\n",
    "    train_ddata\n",
    "          .rdd\n",
    "          .map(lambda r:pyspark.sql.Row(label=r.approve,features = pmlla.SparseVector(\n",
    "                 len(r.TFIDF) + len(r) - 9,\n",
    "                 range(len(r) - 9) + [i + len(r) - 9 for i in r.TFIDF.indices],\n",
    "                 r[4:5] + r[6:41] + r[42:-5] + r[-4:-2] +  tuple(r.TFIDF.values)\n",
    "              )))\n",
    "              )\n",
    "\n",
    "test_w_feat = (\n",
    "    test_ddata\n",
    "          .rdd\n",
    "          .map(lambda r:pyspark.sql.Row(label=r.approve,features = pmlla.SparseVector(\n",
    "                 len(r.TFIDF) + len(r) - 9,\n",
    "                 range(len(r) - 9) + [i + len(r) - 9 for i in r.TFIDF.indices],\n",
    "                 r[4:5] + r[6:41] + r[42:-5] + r[-4:-2] +  tuple(r.TFIDF.values)\n",
    "              )))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest metrics on test\n",
      "        areaUnderROC\t0.651822654377\n",
      "         areaUnderPR\t0.488557043134\n",
      "\n",
      "Logistic Regression metrics on test\n",
      "        areaUnderROC\t0.5       \n",
      "         areaUnderPR\t0.677756963519\n"
     ]
    }
   ],
   "source": [
    "import pyspark.ml.classification \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "fout = open('results_20170810.txt','w')\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': pyspark.ml.classification.LogisticRegression(maxIter=50, regParam=0.3),\n",
    "    'Random Forest': pyspark.ml.classification.RandomForestClassifier(numTrees=100, maxDepth=5, labelCol=\"label\", seed=42)    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for clfname,clf in classifiers.items():\n",
    "    model = clf.fit(train_w_feat.toDF())\n",
    "    test_predict = model.transform(test_w_feat.toDF())\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "    string = '\\n' + clfname + ' metrics on test'\n",
    "    print(string)\n",
    "    fout.write(string)\n",
    "    for metric in (\"areaUnderROC\",\"areaUnderPR\"):\n",
    "        string = '{:>20}\\t{:<10}'.format(metric, evaluator.evaluate(test_predict.selectExpr('label','rawPrediction'), {evaluator.metricName: metric}))\n",
    "        print(string)\n",
    "        fout.write(string)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Явно недообучается, т.к. боевая модель имеет AUC ROC ~0.69."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1371.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:258)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:254)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.foreach(SparkPlan.scala:254)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:276)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:275)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply$mcI$sp(Dataset.scala:2768)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:2765)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:2765)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-f630bb8d6516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_w_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/train_w_feat.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_w_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/test_w_feat.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/k.p.osminin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mtoPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1583\u001b[0m         \"\"\"\n\u001b[0;32m   1584\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1585\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[1;31m##########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/k.p.osminin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/k.p.osminin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/k.p.osminin/spark-2.1.1-bin-hadoop2.6/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/k.p.osminin/spark-2.1.1-bin-hadoop2.6/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1371.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:258)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:254)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.foreach(SparkPlan.scala:254)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:276)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:275)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply$mcI$sp(Dataset.scala:2768)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:2765)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:2765)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "train_w_feat.toDF().toPandas().to_csv('./data/train_w_feat.csv')\n",
    "test_w_feat.toDF().toPandas().to_csv('./data/test_w_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
