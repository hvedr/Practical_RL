{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Холодные звонки\n",
    "\n",
    "Эффективность замены доменов на кластеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "read_ccalls_visits_clusters_query = '''\n",
    "select \n",
    "    c.ymd, \n",
    "    c.full_app as label, \n",
    "    c.features\n",
    "from user_kposminin.ccalls_visits_clusters c\n",
    "left semi join user_kposminin.cold_calls_matched_5 m on m.phone_num = c.phone_num and m.ymd = c.ymd and m.havent_started = 0\n",
    "'''\n",
    "from scipy.sparse import coo_matrix, vstack,hstack\n",
    "\n",
    "#tf = HashingTF(numFeatures = 10 ** 5)\n",
    "\n",
    "data = hc.sql(read_ccalls_visits_clusters_query).rdd\n",
    "train_data = data \\\n",
    "    .filter(lambda row: row['ymd'] < '2016-04-25') \\\n",
    "    .map(lambda r: (r.label,r.features)) \\\n",
    "    .collect()\n",
    "test_data  = data \\\n",
    "    .filter(lambda row: row['ymd'] >= '2016-04-25') \\\n",
    "    .map(lambda r: (r.label,r.features)) \\\n",
    "    .collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50\n",
      "1/50\n",
      "2/50\n",
      "3/50\n",
      "4/50\n",
      "5/50\n",
      "6/50\n",
      "7/50\n",
      "8/50\n",
      "9/50\n",
      "10/50\n",
      "11/50\n",
      "12/50\n",
      "13/50\n",
      "14/50\n",
      "15/50\n",
      "16/50\n",
      "17/50\n",
      "18/50\n",
      "19/50\n",
      "20/50\n",
      "21/50\n",
      "22/50\n",
      "23/50\n",
      "24/50\n",
      "25/50\n",
      "26/50\n",
      "27/50\n",
      "28/50\n",
      "29/50\n",
      "30/50\n",
      "31/50\n",
      "32/50\n",
      "33/50\n",
      "34/50\n",
      "35/50\n",
      "36/50\n",
      "37/50\n",
      "38/50\n",
      "39/50\n",
      "40/50\n",
      "41/50\n",
      "42/50\n",
      "43/50\n",
      "44/50\n",
      "45/50\n",
      "46/50\n",
      "47/50\n",
      "48/50\n",
      "49/50\n",
      "50/50\n"
     ]
    }
   ],
   "source": [
    "#Transform into sparse matrix\n",
    "from scipy.sparse import csr_matrix, vstack,hstack\n",
    "train_labels, train_features = [0], csr_matrix((1,50000))\n",
    "i = 0\n",
    "batch_size = 3000\n",
    "for i in range(len(train_data)/batch_size + 1):\n",
    "    batch = csr_matrix((1,50000))\n",
    "    for r in train_data[batch_size*i:batch_size*(i+1)]:\n",
    "        rr = [e for e in r[1] if 0 <= e < 50000]\n",
    "        train_labels.append(r[0])\n",
    "        batch = vstack([batch,csr_matrix(([1]*len(rr), ([0]*len(rr),rr)), shape=(1,50000), dtype = type(1))])\n",
    "    train_features = vstack([train_features, batch[1:]])\n",
    "    print(str(i)+'/'+str(len(train_data)/batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "6/6\n"
     ]
    }
   ],
   "source": [
    "test_labels, test_features = [0], csr_matrix((1,50000))\n",
    "i = 0\n",
    "batch_size = 3000\n",
    "for i in range(len(test_data)/batch_size + 1):\n",
    "    batch = csr_matrix((1,50000))\n",
    "    for r in test_data[batch_size*i:batch_size*(i+1)]:\n",
    "        rr = [e for e in r[1] if 0 <= e < 50000]\n",
    "        test_labels.append(r[0])\n",
    "        batch = vstack([batch,csr_matrix(([1]*len(rr), ([0]*len(rr),rr)), shape=(1,50000), dtype = type(1))])\n",
    "    test_features = vstack([test_features, batch[1:]])\n",
    "    print(str(i)+'/'+str(len(test_data)/batch_size))\n",
    "\n",
    "test_labels, test_features = test_labels[1:],test_features[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.565483924152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([train_features,train_labels,test_features,test_labels],open('train_test_data.pck','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.581656579846\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "mLR = sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 0.01,class_weight = 'auto')\n",
    "mLR.fit(X = train_features,y = train_labels)\n",
    "\n",
    "print('{0} AUCROC: {1}'.format('LogRegr',sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels , \n",
    "                y_score = [e[1] for e in mLR.predict_proba(test_features)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.590723865775\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "mLR = sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 0.1,class_weight = 'auto')\n",
    "mLR.fit(X = train_features,y = train_labels)\n",
    "\n",
    "print('{0} AUCROC: {1}'.format('LogRegr',sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels , \n",
    "                y_score = [e[1] for e in mLR.predict_proba(test_features)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.515503763166\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "mLR = sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 0.5,class_weight = 'auto',solver = 'lbfgs')\n",
    "mLR.fit(X = train_features,y = train_labels)\n",
    "\n",
    "print('{0} AUCROC: {1}'.format('LogRegr',sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels , \n",
    "                y_score = [e[1] for e in mLR.predict_proba(test_features)]\n",
    "    )))\n",
    "\n",
    "#solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’}, default: ‘liblinear’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_index = [i for i in range(len(train_labels)) if train_labels[i] == 1 or np.random.randint(0,6) == 0]\n",
    "train_sampled_labels = [train_labels[e] for e in sample_index]\n",
    "train_sampled_features = train_features[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.548705625481\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "mLR = sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 0.1,class_weight = 'auto')\n",
    "mLR.fit(X = train_sampled_features,y = train_sampled_labels)\n",
    "\n",
    "print('{0} AUCROC: {1}'.format('LogRegr',sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels , \n",
    "                y_score = [e[1] for e in mLR.predict_proba(test_features)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-86e5c0d3e917>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlin_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlin_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     print('{0} AUCROC:    {1}'.format(m,sk.metrics.roc_auc_score(\n\u001b[0;32m     13\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtest_labels\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/scipy/sparse/coo.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lin_models = {\n",
    "    'Ridge': linear_model.Ridge (alpha = .5),\n",
    "    'Lasso': linear_model.Lasso(),\n",
    "    'ElasticNet': linear_model.ElasticNet(),\n",
    "    'Lars': linear_model.Lars(),\n",
    "    'LinRegr': linear_model.LinearRegression(),\n",
    "    'BayesianRidge':  linear_model.BayesianRidge()\n",
    "}\n",
    "for m in lin_models:\n",
    "    lin_models[m].fit(X = train_features.toarray(),y = train_labels)\n",
    "    print('{0} AUCROC:    {1}'.format(m,sk.metrics.roc_auc_score(\n",
    "                y_true =  test_labels , \n",
    "                y_score = lin_models[m].predict(test_features.toarray()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest AUCROC: 0.576655089019\n",
      "SVC AUCROC: 0.500231089623\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "#from sklearn import svm\n",
    "clf = {\n",
    "   # 'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "   # 'LogRegr': sklearn.linear_model.LogisticRegression(),\n",
    "    'RandomForest': sklearn.ensemble.RandomForestClassifier(max_depth = 4,n_estimators = 400),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(X = train_sampled_features,y = train_sampled_labels)\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels, \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(test_features)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest1 AUCROC: 0.587306055059\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "#from sklearn import svm\n",
    "clf = {\n",
    "   # 'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "   # 'LogRegr': sklearn.linear_model.LogisticRegression(),\n",
    "    'RandomForest1': sklearn.ensemble.RandomForestClassifier(max_depth = 10,n_estimators = 100),\n",
    " #   'RandomForest2': sklearn.ensemble.RandomForestClassifier(max_depth = 2,n_estimators = 700),\n",
    " #   'RandomForest3': sklearn.ensemble.RandomForestClassifier(max_depth = 7,n_estimators = 700),\n",
    " #   'RandomForest4': sklearn.ensemble.RandomForestClassifier(max_depth = 20,n_estimators = 100),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(X = train_sampled_features,y = train_sampled_labels)\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels, \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(test_features)]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.012651928797431005, 40),\n",
       " (0.011327019096785729, 14),\n",
       " (0.010872332009940987, 29),\n",
       " (0.0099285464806288647, 1),\n",
       " (0.0062661276174051823, 48),\n",
       " (0.0062557930313100162, 1396),\n",
       " (0.0061582740670053093, 27),\n",
       " (0.0045285330640225168, 107),\n",
       " (0.0044189365272707557, 39),\n",
       " (0.0042574017667150041, 117)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clusters = [e[1] for e in sorted(zip(clf['RandomForest1'].feature_importances_,range(50000)), reverse  = True)[:50]]\n",
    "sorted(zip(clf['RandomForest1'].feature_importances_,range(50000)), reverse  = True)[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr AUCROC: 0.584287358597\n",
      "RandomForest1 AUCROC: 0.578164289191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data1 = [[r[0],len(r[1])] + [1 * (top_clusters[i] in r[1]) for i in range(len(top_clusters))] for r in train_data]\n",
    "test_data1 = [[r[0],len(r[1])] + [1 * (top_clusters[i] in r[1]) for i in range(len(top_clusters))] for r in test_data]\n",
    "\n",
    "clf = {\n",
    "   # 'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "    'LogRegr': sklearn.linear_model.LogisticRegression(penalty = 'l1',C = 0.1,class_weight = 'auto'),\n",
    "    'RandomForest': sklearn.ensemble.RandomForestClassifier(max_depth = 10,n_estimators = 100),\n",
    " #   'RandomForest2': sklearn.ensemble.RandomForestClassifier(max_depth = 2,n_estimators = 700),\n",
    " #   'RandomForest3': sklearn.ensemble.RandomForestClassifier(max_depth = 7,n_estimators = 700),\n",
    " #   'RandomForest4': sklearn.ensemble.RandomForestClassifier(max_depth = 20,n_estimators = 100),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(X = [r[1:] for r in train_data1],y = [r[0] for r in train_data1])\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = [r[0] for r in test_data1] , \n",
    "                y_score = [e[1] for e in clf[m].predict_proba([r[1:] for r in test_data1])]\n",
    "    )))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC AUCROC: 0.500023639715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import sklearn.neighbors\n",
    "clf = {\n",
    "   # 'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "   # 'LogRegr': sklearn.linear_model.LogisticRegression(),\n",
    "    'SGD': sklearn.linear_model.SGDClassifier(penalty = 'elasticnet',loss = 'log',class_weight = 'auto'),\n",
    "    'Nearest centriod': sklearn.neighbors.NearestCentroid(),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(X = train_features,y = train_labels)\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels, \n",
    "                y_score = clf[m].predict(test_features)\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes Multinpomial AUCROC: 0.557305500156\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1282f84c05f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sampled_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sampled_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n\u001b[0;32m     15\u001b[0m                 \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    495\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    496\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinarize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinarize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mbinarize\u001b[1;34m(X, threshold, copy)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meliminate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mcond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[0mnot_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python2.7/SocketServer.py\", line 295, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/anaconda/lib/python2.7/SocketServer.py\", line 321, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/anaconda/lib/python2.7/SocketServer.py\", line 334, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/anaconda/lib/python2.7/SocketServer.py\", line 655, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/serializers.py\", line 545, in read_int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 53693)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes\n",
    "\n",
    "clf = {\n",
    "   # 'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "   # 'LogRegr': sklearn.linear_model.LogisticRegression(),\n",
    "    'NaiveBayes Multinpomial': sklearn.naive_bayes.MultinomialNB(alpha = 0.001),\n",
    "    'NaiveBayes Bernoulli': sklearn.naive_bayes.BernoulliNB(alpha = 0.01),\n",
    "    'NaiveBayes Gaussian': sklearn.naive_bayes.GaussianNB(),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)    \n",
    "}\n",
    "\n",
    "for m in clf:\n",
    "    clf[m].fit(X = train_sampled_features.toarray(),y = train_sampled_labels)\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = test_labels, \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(test_features.toarray())]\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
