# General Parameters, see comment for each definition
# can be gbtree or gblinear
booster = gbtree
# choose logistic regression loss function for binary classification
objective = binary:logistic

# Tree Booster Parameters
# step size shrinkage
eta = 0.1
# minimum loss reduction required to make a further partition
gamma = 1.0
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 1
# maximum depth of a tree
max_depth = 6

eval_metric = "auc"

# Task Parameters
# the number of round to do boosting
num_round = 100
# 0 means do not save any model except the final round model
save_period = 2
# The path of training data
data = "/home/m.v.surovikov/.ipython/data/cc_features_classes4_libSVM_train.txt"
# The path of validation data, used to monitor training process, here [test] sets name of the validation set
eval[test] = "/home/m.v.surovikov/.ipython/data/cc_features_classes4_libSVM_test.txt"
# The path of test data
test:data = "/home/bigdatasys/projects/la_segments_builder/data/XGBoost_features.txt"