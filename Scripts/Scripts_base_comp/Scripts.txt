perl

вывести сумму и количество записей в файле (файл меток(
perl -nle '$sum1 += $_, $sum2 += 1 for split(//, $_)  } END { print  $sum1," ", $sum2' labels_sampled2__20160930_2.txt

выбирать отдельные столбцы в tab-delimited файле
cat file | perl -ne '@a = split("\t", $_) ; print join("\t",@a[0..4,8..29,34,36]) . "\n" '



beeline
подключиться и выполнить запрос
export HADOOP_CLIENT_OPTS="-Djline.terminal=jline.UnsupportedTerminal"
beeline -u "jdbc:hive2://ds-hadoop-cs01p:10000/" -n kposminin -e "select count(*) as a from user_kposminin.calcs"
beeline -u "jdbc:hive2://ds-hadoop-cs01p:10000/" -n kposminin --incremental=true --showheader=false --outputformat=tsv2 --maxwidth=5000 --silent=true --showWarnings=false --showNestedErrs=false --verbose=false --nullemptystring=true -f /home/k.osminin/scripts/la_many_feat_20161213.hql > /data1/share/kosm/data/la_many_feat_20161103.txt

bash
для использования g++
source /opt/rh/devtoolset-2/enable

ps aux | grep ipython
netstat -lntp | grep 161734 (пид процесса)

выбрать строки файла, которых нет в другом файле
comm -23 <(sort file1) <(sort file2) > result_file

-- модификация
comm -23 <(sort wget/task_22.txt ) <(cat wget/result/data.csv  | perl -ne '@a = split(",", $_) ; print $a[2] . "\n"' | sort) > wget/not_downloaded_task_22.txt

связь SAS и Hadoop 

LIBNAME kosm HADOOP  DBMAX_TEXT=250 PORT=10000 TRANSCODE_FAIL= SILENT  
SERVER="ds-hadoop-cs01p"  SCHEMA=user_kposminin ;

proc sql;
create table kosm.FRANK_BD_CC_SUROV as
select * from matemp.FRANK_BD_CC_SUROV;
quit;


HADOOP 

-- файл скопировать с теста на прод либо обратно
hadoop distcp -Dmapreduce.job.maps=10 -Dmapreduce.map.memory.mb=3000 -Dmapreduce.reduce.memory.mb=6000 -pb -bandwidth 3000 -m 10 hdfs://m1-hadoop-wk01t:8020/path/to/my/file_src hdfs://ds-hadoop-cs01p:8020/path/to/my/file_dst

-- переписать таблицу без временных подпапок
hadoop fs -ls /user/hive/warehouse/user_kposminin.db/cred_app_visits | grep ymd= | perl -ne '@a = split(" ", $_); print $a[7] ."\n"' | xargs -I {} hadoop distcp -Dmapreduce.job.maps=10 -Dmapreduce.map.memory.mb=3000 -Dmapreduce.reduce.memory.mb=6000 -pb -bandwidth 3000 -m 10  hdfs://ds-hadoop-cs01p:8020{} hdfs://m1-hadoop-wk01t:8020{}

Переписать файл с локали в HDFS
hadoop fs -rm -skipTrash /user/kposminin/la_20160824.txt
hadoop fs -put /data2/tmp/la_20160824.txt /user/kposminin/la_20160824.txt

переписать используя scp
scp /data2/tmp/la_20160824.txt k.p.osminin@m1-hadoop-client01t:~/



команда на убийство процесса:  yarn application -kill application_name
команда top выводит список активных процессов


Clickhouse: 
Сервер: m1-gp-tst-sdw17	    kosminin
вход: clickhouse-client --multiline.   выход Ctrl+C
исполнение из командной строки: clickhouse-client --query="select 1+1"
вывод в файл: clickhouse-client --query="select * from table_name FORMAT TabSeparated" > result_file_name.txt
Manual: https://clickhouse.yandex/reference_ru.html 

bigdatasys@mail.ru (pwd = standard_pwd + '123')

https://jira.tcsbank.ru/

--убить application
yarn application -kill application_1482401547244_25551

-- Перезапуск ipython notebook
убить старый интанс ipyhton на 3ьем клиенте можно так, на примере:

[k.p.osminin@ds-hadoop-client03p ~]$ ps ajxf | grep ipython | grep 708 | grep -v grep

16675 16814 16814 14980 pts/5    17776 D      708   0:01 \_ /opt/anaconda/bin/python /opt/anaconda/bin/ipython notebook --profile=spark

Если видишь несколько процессов, то выбираешь родительский, т.е. тот процесс, у которого pid во второй колонке самый маленький

В нашем случае это "16814". Далее выполняешь kill 16814. Проверяешь, остался ли процесс, повторяя команду kill 16814, 
пока не появится надпись "process not found". Если процесс никак не хочет умирать, то можно его убить так: kill -9 16814.


запустить ipython можно так:

k.p.osminin@ds-hadoop-client03p ~]$ nohup /opt/anaconda/bin/ipython notebook --profile=spark &

тут 708 - id твоей УЗ на 3ьем клиенте. Узнать его можно командой id:

[k.p.osminin@ds-hadoop-client03p ~]$ id k.p.osminin

uid=708(k.p.osminin) gid=708(k.p.osminin) groups=708(k.p.osminin)

Нас интересует uid=708.


Использовать новую версию g++. Выполнять пееред установкой пакетов.
source /opt/rh/devtoolset-2/enable

-- файл скопировать с теста на прод либо обратно
hadoop distcp -Dmapreduce.job.maps=10 -Dmapreduce.map.memory.mb=3000 -Dmapreduce.reduce.memory.mb=6000 -pb -bandwidth 3000 -m 10 hdfs://m1-hadoop-wk01t:8020/path/to/my/file_src hdfs://ds-hadoop-cs01p:8020/path/to/my/file_dst


-- починить таблицу
msck repair table user_kposminin.url_text_test

-- запустить юпитер ноутбук с поддержкой графики
nohup xvfb-run -s "-screen 0 1400x900x24" /home/k.osminin/anaconda2/bin/ipython notebook --profile=spark 2>&1 > /dev/null &
