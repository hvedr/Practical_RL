{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Построение Look-alike модели для целевой аудитории раздела веб-сайта\n",
    "\n",
    "Используются различные подходы:\n",
    "- Логистическая регрессия\n",
    "- Naive Bayes\n",
    "- текущий подход, рассмотренный в Wiki[https://wiki.tcsbank.ru/pages/viewpage.action?pageId=176096365].\n",
    "Сравнение методов производится по метрике AUC ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Description TODO\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"8g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hc = HiveContext(sc)\n",
    "table_name = 'user_kposminin.urls_w_levels1'\n",
    "query2 = '''\n",
    "select * from {0}\n",
    "\n",
    "'''.format(table_name)\n",
    "\n",
    "#hc.sql(query2[0])\n",
    "#hc.sql(query2[1])\n",
    "\n",
    "rdd = hc.sql(query2).rdd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Group by cookie and form url list the cookie visited\n",
    "def test(id):\n",
    "    ''' Is id (== cookie + '-'+date) from test sample or not ( and is from train sample)? Output is True or False\n",
    "        In this case test sample == sample from 4th of July.    \n",
    "    '''    \n",
    "    return re.findall('[0-9]{4}-([0-9]{2}-[0-9]{2})',id)[0] == '07-04'\n",
    "\n",
    "    \n",
    "rdd2 = rdd.flatMap(lambda row: [(row['cookie'] + str(1*test(row['object_id'])) , row['domain']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[0]'+row['lev0']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[1]'+row['lev1']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[2]'+row['lev2']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[r]'+row['ref_domain']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[r0]'+row['ref_lev0']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[r1]'+row['ref_lev1']),\n",
    "                                (row['cookie'] + str(1*test(row['object_id'])), row['domain']+'[r2]'+row['ref_lev2'])\n",
    "]).reduceByKey(lambda a,b: a + ';;' + b)\n",
    "#rdd2 = rdd.map(lambda row: (row['cookie'] , row['domain'])).reduceByKey(lambda a, b: a + ';;' + b)\n",
    "\n",
    "# Label target cookies (=cookies visited target url) and exclude some urls\n",
    "\n",
    "#target_urls =['mkb.ru/facility/private_person/cards/credit_card','mkb.ru']\n",
    "target_urls =['avito.ru']\n",
    "exclude_urls = target_urls + []\n",
    "\n",
    "def handle_row(row,targ_urls, exclud_urls):\n",
    "    proc_urls = row[1]\n",
    "    for u in exclud_urls:\n",
    "        proc_urls = re.sub('[^;;]*'+ u +'[^;;]*','',proc_urls)\n",
    "    return (\n",
    "        bool(int(row[0][-1])),\n",
    "        any(tu in row[1] for tu in targ_urls), \n",
    "        re.sub('[;]{3,}',';;',proc_urls)\n",
    "    )\n",
    "\n",
    "rdd3 = rdd2.map(lambda row: handle_row(row,target_urls, exclude_urls))\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "\n",
    "tf = HashingTF(numFeatures = 10 ** 5)\n",
    "\n",
    "#transform urls (as Bag of Words) into features and form features with labels\n",
    "train_data = rdd3.filter(lambda row: not row[0]).map(lambda row: LabeledPoint(row[1], tf.transform(row[2].split(';;'))))\n",
    "test_data  = rdd3.filter(lambda row:     row[0]).map(lambda row: LabeledPoint(row[1], tf.transform(row[2].split(';;'))))\n",
    "# TODO count visits or not\n",
    "# split into train and test samples\n",
    "#train_data, test_data = all_data.randomSplit([6, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "train_data.cache()\n",
    "modelNB = NaiveBayes.train(train_data)\n",
    "\n",
    "def predict_proba_NB(f,model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability. f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Function selects winning class with it probability.\n",
    "    Output: tuple with model selected class number as first element (type int) and it probability as second (type float).\n",
    "    '''\n",
    "    logp = [[i,f.dot(model.theta[i]) + model.pi[i]] for i in range(len(model.theta))] # classes with log probabilities\n",
    "    wi = sorted(logp, key = lambda e:  - e[1])[0][0] #winning index\n",
    "    prob = 1./sum([np.exp(e[1] - logp[wi][1]) for e in logp]) #winning class probability\n",
    "    return wi, prob\n",
    "\n",
    "def predict_proba_NB_2(f, model):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Naive Bayes model prediction with probability for 2-class classification.\n",
    "    f is features [Sparse] vector. model is mllib.NaiveBayesModel.\n",
    "    Output: probability of class 1 (type float).\n",
    "    '''\n",
    "    if len(model.theta) != 2:\n",
    "        print('Model is NOT a 2-class classifier')\n",
    "        return None\n",
    "    logp = [f.dot(model.theta[i]) + model.pi[i] for i in range(2)]    \n",
    "    return 1./(1. + np.exp(logp[0] - logp[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LogisticRegression model\n",
    "modelLR = LogisticRegressionWithSGD.train(train_data)\n",
    "modelLR.clearThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing result\n",
    "df_test = test_data.map( lambda lp: pyspark.sql.Row(\n",
    "        Label = lp.label,\n",
    "        NaiveBayes = float(predict_proba_NB_2(lp.features, modelNB)),\n",
    "        LogisticRegression = float(modelLR.predict(lp.features))\n",
    "    )).toDF().toPandas()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods AUCROC performance on test sample(19206 samples with 202 positives):\n",
      "LogisticRegression            58.344%\n",
      "NaiveBayes                    75.606%\n"
     ]
    }
   ],
   "source": [
    "#Build AUCROC metric and print results\n",
    "import sklearn\n",
    "AUCROC = {}\n",
    "for c in df_test.columns:\n",
    "    if c!= 'Label':\n",
    "        AUCROC[c] = sklearn.metrics.roc_auc_score(df_test['Label'],df_test[c])\n",
    "        \n",
    "print('Methods AUCROC performance on test sample ({0:.0f} samples with {1:.0f} positives):\\n'.format(df_test.size,df_test['Label'].sum()) +\n",
    "     '\\n'.join(['{0:<30}{1:.3%}'.format(k,v) for (k,v) in AUCROC.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
