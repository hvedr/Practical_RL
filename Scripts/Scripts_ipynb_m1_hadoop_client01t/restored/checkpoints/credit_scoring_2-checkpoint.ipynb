{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кредитный скоринг заявок на основе веб-лога\n",
    "#### На основании дефолта\n",
    "2017-03-07\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 10).set(\"spark.driver.maxResultSize\", \"24g\").set('spark.driver.memory','16g')\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_shot_queries = '''\n",
    "create table user_kposminin.cred_app_id_phone as\n",
    "select \n",
    "  financial_application_rk, \n",
    "  retro_date, \n",
    "  mobile_telephone_no as phone_num,\n",
    "  id,\n",
    "  financial_product_type_cd, \n",
    "  default_flg\n",
    "from\n",
    "  user_kposminin.credit_app_default_2014_2016 c \n",
    "  inner join (\n",
    "     select \n",
    "       uid_str as id,\n",
    "       property_value as phone_num\n",
    "     from\n",
    "       prod_dds.md_uid_property \n",
    "     where\n",
    "       property_cd = 'PHONE' \n",
    "      ) m on c.mobile_telephone_no = m.phone_num\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "CREATE TABLE `user_kposminin.cred_app_visits`(\n",
    "\t  `phone_mobile` varchar(35), \n",
    "\t  `default_flg` int, \n",
    "\t  `call_ymd` string, \n",
    "      `id_cnt` int, \n",
    "      `load_src_cnt` int, \n",
    "\t  `urlfr` string, \n",
    "\t  `cnt` int, \n",
    "      `first_visit` bigint,\n",
    "\t  `duration` int, \n",
    "\t  `avg_hour` int,\n",
    "      `load_dttm` timestamp\n",
    "      )\n",
    "\tPARTITIONED BY ( \n",
    "\t  `ymd` string,\n",
    "      `financial_product_type_cd` string)\n",
    "\tSTORED AS RCFile\n",
    ";\n",
    "'''\n",
    "\n",
    "query_pattern = '''\n",
    "\n",
    "insert overwrite \n",
    " table user_kposminin.cred_app_visits partition(ymd,financial_product_type_cd)\n",
    "select\n",
    "  phone_mobile\n",
    " ,max(default_flg) as default_flg\n",
    " ,date_add(retro_date, 1) as call_ymd\n",
    " ,count(distinct id) as id_cnt\n",
    " ,count(distinct load_src) as load_src_cnt\n",
    " ,urlfr\n",
    " ,cast(count(*) as int) cnt\n",
    " ,MIN(time) as first_visit\n",
    " ,cast(MAX(time) - MIN(time) as int) as duration\n",
    " ,cast(from_unixtime(cast(AVG(time) as Bigint), 'HH') AS int) as avg_hour\n",
    " ,max(current_timestamp()) as load_dttm\n",
    " ,max(ymd) ymd\n",
    " ,max(financial_product_type_cd) as financial_product_type_cd\n",
    " \n",
    "from\n",
    " (\n",
    "   select\n",
    "     phone_num as phone_mobile\n",
    "    ,id\n",
    "    ,financial_product_type_cd\n",
    "    ,retro_date\n",
    "    ,load_src\n",
    "    ,default_flg    \n",
    "    ,cast(event_dttm as Bigint) as time\n",
    "    ,concat(url_domain, '#', path_fr) as urlfr\n",
    "    ,ymd\n",
    "   from\n",
    "    (\n",
    "     select\n",
    "       a.phone_num, \n",
    "       a.id,\n",
    "       a.financial_product_type_cd, \n",
    "       a.retro_date, \n",
    "       a.default_flg,\n",
    "       a.load_src,\n",
    "       w.event_dttm,\n",
    "       w.url,\n",
    "       w.url_domain,\n",
    "       w.ymd\n",
    "     from\n",
    "       user_kposminin.cred_app_id_phone a \n",
    "       inner join prod_odd.weblog w on w.uid = a.id and w.load_src = a.load_src\n",
    "     where\n",
    "       w.ymd = '#visit_ymd'\n",
    "       and a.retro_date between date_add(w.ymd, 1) and date_add(w.ymd, 365)\n",
    "       \n",
    "    ) tmp\n",
    "    \n",
    "    LATERAL VIEW explode(split(parse_url(url, \"PATH\"), '/')) tt AS path_fr\n",
    "\n",
    "   ) t\n",
    "group by\n",
    "  phone_mobile\n",
    " ,date_add(retro_date, 1)\n",
    " ,urlfr\n",
    " ,phone_mobile\n",
    " \n",
    "'''   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calced_dates = [e[0] for e in hc.sql('select distinct ymd from user_kposminin.cred_app_visits').collect()]\n",
    "#calced_dates = [e[0] for e in calced_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_date = datetime.date(2015,12,31)\n",
    "\n",
    "#Uncomment 2 rows below to generate queries for visits filling\n",
    "for i in range(1,365*1):\n",
    "    date = str(start_date - datetime.timedelta(days = i))\n",
    "    if (not date in calced_dates):\n",
    "        print(query_pattern.replace('#visit_ymd', str(start_date - datetime.timedelta(days = i))) + ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#l = ['-'.join(e.split('-')[::-1]) for e in l]\n",
    "#l = [e for e in l if e not in ('2015-12-31','2015-11-08')][::-1]\n",
    "l = ['2015-12-30', '2015-12-29', '2015-12-28','2015-12-27', '2015-12-26', '2015-12-25', '2015-12-24', '2015-12-23', '2015-12-22',\n",
    " '2015-12-21', '2015-12-20', '2015-12-19', '2015-12-18', '2015-12-17', '2015-12-16', '2015-12-15', '2015-12-14', '2015-12-13',\n",
    " '2015-12-12', '2015-12-11', '2015-12-10', '2015-12-09', '2015-12-08', '2015-12-07', '2015-12-06', '2015-12-05', '2015-12-04',\n",
    " '2015-12-03', '2015-12-02', '2015-12-01', '2015-11-30', '2015-11-07', '2015-11-06', '2015-11-05', '2015-11-04', '2015-11-03',\n",
    " '2015-11-02', '2015-11-01', '2015-10-31', '2015-10-30', '2015-10-29', '2015-10-28', '2015-10-27', '2015-10-26', '2015-10-25',\n",
    " '2015-10-24', '2015-10-23', '2015-10-22', '2015-10-21', '2015-10-15', '2015-10-10', '2015-10-09', '2015-10-08', '2015-10-07',\n",
    " '2015-10-06', '2015-10-05', '2015-10-04', '2015-10-03', '2015-10-02', '2015-10-01', '2015-09-30', '2015-09-29', '2015-09-28',\n",
    " '2015-09-27', '2015-09-26', '2015-09-25', '2015-09-24', '2015-09-23', '2015-09-22', '2015-09-21', '2015-09-20', '2015-09-19',\n",
    " '2015-09-18', '2015-09-17', '2015-09-16', '2015-09-15', '2015-09-14', '2015-09-13', '2015-09-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in l:\n",
    "    print(query_pattern.replace('#visit_ymd', d) + ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_visits_pattern = '''\n",
    "\n",
    "\n",
    "insert overwrite \n",
    " table user_kposminin.cred_app_visits partition(ymd,financial_product_type_cd)\n",
    "select\n",
    "  a.phone_num as phone_mobile \n",
    " ,max(a.default_flg) as default_flg\n",
    " ,date_add(a.retro_date, 1) as call_ymd\n",
    " ,count(distinct a.id) as id_cnt\n",
    " ,count(distinct a.load_src) as load_src_cnt\n",
    " ,v.url_fragment as urlfr\n",
    " ,sum(v.visit_count) as cnt\n",
    " ,min(v.first_visit) as first_visit\n",
    " ,sum(v.duration_sec) as duration\n",
    " ,avg(v.average_visit_hour) as avg_hour\n",
    " ,current_timestamp() as load_dttm\n",
    " ,max(v.ymd) as ymd\n",
    " ,max(a.financial_product_type_cd) as financial_product_type_cd\n",
    " \n",
    "from\n",
    "  user_kposminin.cred_app_id_phone a \n",
    "  inner join prod_odd.visit_feature v on v.id = a.id and v.load_src = a.load_src\n",
    "where\n",
    "  a.retro_date between date_add(v.ymd, 1) and date_add(v.ymd, 365)\n",
    "  and v.ymd = '#visit_ymd'\n",
    "group by\n",
    "  phone_num\n",
    " ,date_add(a.retro_date, 1)\n",
    " ,v.url_fragment\n",
    ";\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2016,12,31)\n",
    "\n",
    "for d in dates_to_calc_2016:\n",
    "    #date = str(start_date - datetime.timedelta(days = i))\n",
    "    #if (not date in calced_dates):\n",
    "    print(feature_visits_pattern.replace('#visit_ymd', d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация факторов\n",
    "##### Я.Каталог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yaca_query = '''\n",
    "\n",
    "create table user_kposminin.yaca_tf_1 as \n",
    "select\n",
    "  y.section_ind,\n",
    "  sum(s.visitors) as cnt\n",
    "from\n",
    "  user_kposminin.yaca_urlfr y\n",
    "  left join prod_features_liveinternet.urlfr_stat s on y.urlfr = s.urlfr\n",
    "where\n",
    "  s.ymd = '2017-03-09'\n",
    "group by \n",
    "  y.section_ind\n",
    ";\n",
    "\n",
    "\n",
    "create table user_kposminin.yaca_tf as\n",
    "with f as (\n",
    "select\n",
    "  substr(section_ind,1,2) as section_ind,\n",
    "  1 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,2)\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  substr(section_ind,1,4) as section_ind,\n",
    "  2 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,4)\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  substr(section_ind,1,6) as section_ind,\n",
    "  3 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,6)\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  substr(section_ind,1,8) as section_ind,\n",
    "  4 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,8)\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  substr(section_ind,1,10) as section_ind,\n",
    "  5 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,10)\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  substr(section_ind,1,12) as section_ind,\n",
    "  6 as level,\n",
    "  sum(cnt) as cnt\n",
    "from user_kposminin.yaca_tf_1\n",
    "group by substr(section_ind,1,12)\n",
    ")\n",
    "\n",
    "select\n",
    "  section_ind,\n",
    "  level,\n",
    "  cnt/(sum(cnt) over (partition by level)) as tf\n",
    "from f;\n",
    "\n",
    "\n",
    "create table user_kposminin.cred_app_yaca_1 as \n",
    "select\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd, \n",
    "  substr(y.section_ind,1,6) as yaca3, \n",
    "  count(*) as cnt,\n",
    "  count(distinct ymd) as ymd_cnt,\n",
    "  count(distinct v.urlfr) as urlfr_cnt,\n",
    "  - count(*) * avg(log(tf.tf)) as tf_idf\n",
    "from\n",
    "  user_kposminin.cred_app_visits v\n",
    "  inner join user_kposminin.yaca_urlfr y on y.urlfr = v.urlfr\n",
    "  inner join user_kposminin.yaca_tf tf   on tf.section_ind = substr(y.section_ind,1,6) and tf.level = 3\n",
    "group by\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd, \n",
    "  substr(y.section_ind,1,6)\n",
    ";\n",
    "\n",
    "create table user_kposminin.cred_app_yaca_2 as \n",
    "select\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd, \n",
    "  max(v.default_flg) as default_flg,\n",
    "  avg(v.id_cnt) as id_cnt,\n",
    "  avg(v.load_src_cnt) as load_src_cnt,\n",
    "  \n",
    "  count(*) as cnt,\n",
    "  count(distinct ymd) as ymd_cnt,\n",
    "  count(distinct urlfr) as urlfr_cnt\n",
    "  \n",
    "from\n",
    "  user_kposminin.cred_app_visits v\n",
    "  left semi join user_kposminin.yaca_urlfr y on y.urlfr = v.urlfr\n",
    "group by\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd\n",
    ";\n",
    "\n",
    "create table user_kposminin.cred_app_yaca_3 as \n",
    "select\n",
    "  a.phone_mobile, \n",
    "  a.call_ymd, \n",
    "  b.default_flg as default_flg, \n",
    "  a.yaca3, \n",
    "  a.tf_idf / b.cnt as tf_idf, \n",
    "  a.cnt / b.cnt as tf, \n",
    "  b.cnt, \n",
    "  a.urlfr_cnt / b.urlfr_cnt as urlfr_share, \n",
    "  b.urlfr_cnt, \n",
    "  a.ymd_cnt / b.ymd_cnt as ymd_share,\n",
    "  b.ymd_cnt,\n",
    "  b.id_cnt,\n",
    "  b.load_src_cnt\n",
    "from\n",
    "  user_kposminin.cred_app_yaca_1 a\n",
    "  inner join user_kposminin.cred_app_yaca_2 b on a.phone_mobile = b.phone_mobile and a.call_ymd = b.call_ymd\n",
    ";\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_query = '''\n",
    "select \n",
    "  a.phone_mobile,\n",
    "  a.call_ymd,\n",
    "  a.default_flg,\n",
    "  yd.row_num as yaca,\n",
    "  a.tf,\n",
    "  a.tf_idf,\n",
    "  a.urlfr_share,\n",
    "  a.ymd_share,\n",
    "  a.cnt,\n",
    "  a.urlfr_cnt,\n",
    "  a.ymd_cnt,\n",
    "  a.id_cnt,\n",
    "  a.load_src_cnt\n",
    "\n",
    "from user_kposminin.cred_app_yaca_3 a \n",
    "inner join (select yaca3,ROW_NUMBER() OVER () AS row_num from\n",
    " (select distinct yaca3\n",
    "  from user_kposminin.cred_app_yaca_3\n",
    "  order by yaca3) a) yd on yd.yaca3 = a.yaca3\n",
    "where (not a.default_flg is Null)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = train_data1.take(100)\n",
    "#l = a[0][1]\n",
    "#[e[0] for e in l]\n",
    "#zip([list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)],range(500))\n",
    "a= (hc.sql(select_query)\n",
    "                .filter(\"call_ymd < '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .take(10)\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = a[7][1]\n",
    "b = (\n",
    "    [list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][2] if i in [e[0] for e in l] else 0 for i in range(420)] +\n",
    "                                     [list(l)[[e[0] for e in l].index(i)][3] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][4] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     list(list(l)[0][5:])\n",
    ")\n",
    "\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = (hc.sql(select_query)\n",
    "                .filter(\"call_ymd < '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .map(lambda (k,l):(k,[list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][2] if i in [e[0] for e in l] else 0 for i in range(420)] +\n",
    "                                     [list(l)[[e[0] for e in l].index(i)][3] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][4] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     list(list(l)[0][5:])))\n",
    "                .collect() \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = (hc.sql(select_query)\n",
    "                .filter(\"call_ymd >= '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .map(lambda (k,l):(k,[list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][2] if i in [e[0] for e in l] else 0 for i in range(420)] +\n",
    "                                     [list(l)[[e[0] for e in l].index(i)][3] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][4] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     list(list(l)[0][5:])))\n",
    "                .collect() \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix( [e[1] for e in train_data], label = [e[0][2] for e in train_data])\n",
    "dtest  = xgb.DMatrix( [e[1] for e in test_data],  label = [e[0][2] for e in test_data] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data[12] '+79678813486', u'2016-01-25'\n",
    "#dtest.get_label().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyLightGBM is looking for 'LIGHTGBM_EXEC' environment variable, cannot be found.\n",
      "exec_path will be deprecated in favor of environment variable\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 299.156293 seconds\n",
      "[LightGBM] [Info] Number of positive: 7938, number of negative: 130185\n",
      "[LightGBM] [Info] Total Bins 292442\n",
      "[LightGBM] [Info] Number of data: 138123, number of used features: 1681\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=16\n",
      "[LightGBM] [Info] Iteration:1, valid_1 auc : 0.513809\n",
      "[LightGBM] [Info] 1.871560 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=28\n",
      "[LightGBM] [Info] Iteration:2, valid_1 auc : 0.513327\n",
      "[LightGBM] [Info] 3.316948 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=17\n",
      "[LightGBM] [Info] Iteration:3, valid_1 auc : 0.507793\n",
      "[LightGBM] [Info] 4.678198 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=22\n",
      "[LightGBM] [Info] Iteration:4, valid_1 auc : 0.507774\n",
      "[LightGBM] [Info] 6.072644 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=21\n",
      "[LightGBM] [Info] Iteration:5, valid_1 auc : 0.50847\n",
      "[LightGBM] [Info] 7.540050 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=19\n",
      "[LightGBM] [Info] Iteration:6, valid_1 auc : 0.512309\n",
      "[LightGBM] [Info] 9.418751 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=26\n",
      "[LightGBM] [Info] Iteration:7, valid_1 auc : 0.513721\n",
      "[LightGBM] [Info] 10.825590 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=21\n",
      "[LightGBM] [Info] Iteration:8, valid_1 auc : 0.517425\n",
      "[LightGBM] [Info] 12.230772 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:9, valid_1 auc : 0.51724\n",
      "[LightGBM] [Info] 13.767759 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=18\n",
      "[LightGBM] [Info] Iteration:10, valid_1 auc : 0.518262\n",
      "[LightGBM] [Info] 15.328719 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:11, valid_1 auc : 0.521642\n",
      "[LightGBM] [Info] 17.325995 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=24\n",
      "[LightGBM] [Info] Iteration:12, valid_1 auc : 0.523954\n",
      "[LightGBM] [Info] 18.707779 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=31\n",
      "[LightGBM] [Info] Iteration:13, valid_1 auc : 0.526459\n",
      "[LightGBM] [Info] 20.110255 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=30\n",
      "[LightGBM] [Info] Iteration:14, valid_1 auc : 0.526446\n",
      "[LightGBM] [Info] 21.516466 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=28\n",
      "[LightGBM] [Info] Iteration:15, valid_1 auc : 0.52609\n",
      "[LightGBM] [Info] 23.051598 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=19\n",
      "[LightGBM] [Info] Iteration:16, valid_1 auc : 0.523625\n",
      "[LightGBM] [Info] 25.082329 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=25\n",
      "[LightGBM] [Info] Iteration:17, valid_1 auc : 0.524687\n",
      "[LightGBM] [Info] 26.513907 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=21\n",
      "[LightGBM] [Info] Iteration:18, valid_1 auc : 0.525792\n",
      "[LightGBM] [Info] 27.927662 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=33\n",
      "[LightGBM] [Info] Iteration:19, valid_1 auc : 0.523695\n",
      "[LightGBM] [Info] 29.329961 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=32\n",
      "[LightGBM] [Info] Iteration:20, valid_1 auc : 0.523551\n",
      "[LightGBM] [Info] 30.772368 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=36\n",
      "[LightGBM] [Info] Iteration:21, valid_1 auc : 0.525815\n",
      "[LightGBM] [Info] 33.108757 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=38\n",
      "[LightGBM] [Info] Iteration:22, valid_1 auc : 0.525929\n",
      "[LightGBM] [Info] 34.699876 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=39\n",
      "[LightGBM] [Info] Iteration:23, valid_1 auc : 0.527743\n",
      "[LightGBM] [Info] 36.236231 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=40\n",
      "[LightGBM] [Info] Iteration:24, valid_1 auc : 0.526293\n",
      "[LightGBM] [Info] 37.687975 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:25, valid_1 auc : 0.526198\n",
      "[LightGBM] [Info] 39.265881 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=37\n",
      "[LightGBM] [Info] Iteration:26, valid_1 auc : 0.525063\n",
      "[LightGBM] [Info] 41.207840 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:27, valid_1 auc : 0.527158\n",
      "[LightGBM] [Info] 42.746626 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=34\n",
      "[LightGBM] [Info] Iteration:28, valid_1 auc : 0.527838\n",
      "[LightGBM] [Info] 44.094552 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=43\n",
      "[LightGBM] [Info] Iteration:29, valid_1 auc : 0.529536\n",
      "[LightGBM] [Info] 45.603341 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=37\n",
      "[LightGBM] [Info] Iteration:30, valid_1 auc : 0.52676\n",
      "[LightGBM] [Info] 47.279682 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=31\n",
      "[LightGBM] [Info] Iteration:31, valid_1 auc : 0.527435\n",
      "[LightGBM] [Info] 49.311700 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=37\n",
      "[LightGBM] [Info] Iteration:32, valid_1 auc : 0.524256\n",
      "[LightGBM] [Info] 50.767364 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=39\n",
      "[LightGBM] [Info] Iteration:33, valid_1 auc : 0.524405\n",
      "[LightGBM] [Info] 52.203903 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=38\n",
      "[LightGBM] [Info] Iteration:34, valid_1 auc : 0.525421\n",
      "[LightGBM] [Info] 53.768956 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=33\n",
      "[LightGBM] [Info] Iteration:35, valid_1 auc : 0.525049\n",
      "[LightGBM] [Info] 55.162900 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=49\n",
      "[LightGBM] [Info] Iteration:36, valid_1 auc : 0.526668\n",
      "[LightGBM] [Info] 57.287796 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=56\n",
      "[LightGBM] [Info] Iteration:37, valid_1 auc : 0.527373\n",
      "[LightGBM] [Info] 59.217147 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=43\n",
      "[LightGBM] [Info] Iteration:38, valid_1 auc : 0.529826\n",
      "[LightGBM] [Info] 60.848355 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=51\n",
      "[LightGBM] [Info] Iteration:39, valid_1 auc : 0.531799\n",
      "[LightGBM] [Info] 62.570784 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=38\n",
      "[LightGBM] [Info] Iteration:40, valid_1 auc : 0.531083\n",
      "[LightGBM] [Info] 64.089138 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=27\n",
      "[LightGBM] [Info] Iteration:41, valid_1 auc : 0.531584\n",
      "[LightGBM] [Info] 66.014744 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=38\n",
      "[LightGBM] [Info] Iteration:42, valid_1 auc : 0.535195\n",
      "[LightGBM] [Info] 67.504018 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=32\n",
      "[LightGBM] [Info] Iteration:43, valid_1 auc : 0.537924\n",
      "[LightGBM] [Info] 68.901746 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=40\n",
      "[LightGBM] [Info] Iteration:44, valid_1 auc : 0.538117\n",
      "[LightGBM] [Info] 70.332999 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=24\n",
      "[LightGBM] [Info] Iteration:45, valid_1 auc : 0.538587\n",
      "[LightGBM] [Info] 71.587887 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=42\n",
      "[LightGBM] [Info] Iteration:46, valid_1 auc : 0.537229\n",
      "[LightGBM] [Info] 73.598408 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=48\n",
      "[LightGBM] [Info] Iteration:47, valid_1 auc : 0.534447\n",
      "[LightGBM] [Info] 75.388013 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=53\n",
      "[LightGBM] [Info] Iteration:48, valid_1 auc : 0.534711\n",
      "[LightGBM] [Info] 77.148020 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:49, valid_1 auc : 0.533281\n",
      "[LightGBM] [Info] 78.514636 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=36\n",
      "[LightGBM] [Info] Iteration:50, valid_1 auc : 0.530337\n",
      "[LightGBM] [Info] 79.755684 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=56\n",
      "[LightGBM] [Info] Iteration:51, valid_1 auc : 0.530639\n",
      "[LightGBM] [Info] 82.015230 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=35\n",
      "[LightGBM] [Info] Iteration:52, valid_1 auc : 0.530191\n",
      "[LightGBM] [Info] 83.402339 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=34\n",
      "[LightGBM] [Info] Iteration:53, valid_1 auc : 0.529885\n",
      "[LightGBM] [Info] 84.877564 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=56\n",
      "[LightGBM] [Info] Iteration:54, valid_1 auc : 0.529178\n",
      "[LightGBM] [Info] 86.785543 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=127 and max_depth=52\n",
      "[LightGBM] [Info] Iteration:55, valid_1 auc : 0.528305\n",
      "[LightGBM] [Info] Early stopping at iteration 55, the best iteration round is 45\n",
      "[LightGBM] [Info] Output of best iteration round:\n",
      "Iteration:45, valid_1 auc : 0.538587\n",
      "\n",
      "[LightGBM] [Info] 88.324281 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 46 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "('Accuracy: ', 0.050988524031360075)\n",
      "('AUC ROC:  ', 0.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from pylightgbm.models import GBMClassifier\n",
    "\n",
    "# full path to lightgbm executable (on Windows include .exe)\n",
    "exec_path = \"lightgbm\"\n",
    "\n",
    "#X, Y = datasets.make_classification(n_samples=200, n_features=10)\n",
    "#x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf=5,\n",
    "        is_unbalance = True,\n",
    "        num_iterations = 500,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 5,\n",
    "        metric = 'auc',\n",
    "        early_stopping_round=10\n",
    ")\n",
    "\n",
    "x_train, y_train, x_test, y_test = [e[1] for e in train_data],[e[0][2] for e in train_data], [e[1] for e in test_data],[e[0][2] for e in test_data]\n",
    "\n",
    "clf.fit( x_train, y_train, test_data=[(x_test, y_test)])\n",
    "y_test_pred = clf.predict(np.array(x_test))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('AUC ROC:  ',metrics.roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 46 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "('Accuracy: ', 0.8287410521531644)\n",
      "('AUC ROC:  ', 0.51281005210095087)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(np.array(x_test))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('AUC ROC:  ',metrics.roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На всех фичах AUC 0.538, что плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogReg AUC ROC:  ', 0.53186714903686738)\n"
     ]
    }
   ],
   "source": [
    "import sklearn,sklearn.linear_model\n",
    "clfLR = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "clfLR.fit(x_train, y_train)\n",
    "y_test_predLR= clfLR.predict_proba(x_test)[:,1]\n",
    "#print(\"LogReg Accuracy: \", metrics.accuracy_score(y_test, y_test_predLR))\n",
    "print('LogReg AUC ROC:  ', metrics.roc_auc_score(y_test, y_test_predLR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Вывод: факторы на основе Я.каталога себя не показали, предсказательная сила весьма слаба."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скорим урлфрагменты на основе default_flg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "-- скор урла - логарифм регуляризованного отношения кол-ва уникальных положительных посетителей к отрицательным посетителям.\n",
    "-- таких несколько партиций с интервалом в 3 месяца\n",
    "insert overwrite table user_kposminin.urlfr_tgt_cnt partition (ymd, target)\n",
    "select \n",
    "  urlfr,\n",
    "  cnt_positive,\n",
    "  cnt_total,\n",
    "  log((cnt_positive + 0.1) / (cnt_total - cnt_positive + 0.1)) as score,\n",
    "  ymd,\n",
    "  target\n",
    "from(\n",
    " select\n",
    "   urlfr,\n",
    "   count(distinct if(default_flg = 1, concat(phone_mobile, call_ymd), Null)) as  cnt_positive,\n",
    "   count(distinct concat(phone_mobile, call_ymd)) as cnt_total,\n",
    "   '2016-06-01' as ymd,\n",
    "   'tinkoff_LON_CCR_default' as target\n",
    " from \n",
    "   user_kposminin.cred_app_visits\n",
    " where\n",
    "   (not default_flg is Null)\n",
    "   and call_ymd < '2016-06-01'\n",
    " group by urlfr\n",
    " ) a\n",
    ";\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 1/2.\n",
    "\n",
    "create table user_kposminin.cred_app_sc_1_1 as\n",
    "select \n",
    "  phone_mobile\n",
    "  ,call_ymd\n",
    "  ,max(default_flg) as default_flg\n",
    "  ,v.urlfr\n",
    "  ,v.ymd\n",
    "  ,max(\n",
    "    named_struct(\n",
    "      'ymd', v.ymd,\n",
    "      'score', if(t.ymd < v.ymd,t.score, -10)\n",
    "    )\n",
    "   ).score as score\n",
    "  ,max(id_cnt) as id_cnt\n",
    "  ,max(  load_src_cnt ) as   load_src_cnt \n",
    "  ,max(  cnt ) as   cnt \n",
    "  ,max(  first_visit ) as   first_visit \n",
    "  ,max(  duration ) as   duration \n",
    "  ,max(  avg_hour ) as   avg_hour \n",
    "  ,max(  load_dttm ) as   load_dttm \n",
    "  ,max(  financial_product_type_cd) as   financial_product_type_cd\n",
    "  ,(unix_timestamp(max(v.call_ymd), 'yyyy-MM-dd') - unix_timestamp(min(v.ymd), 'yyyy-MM-dd'))/60/60/24 as lag\n",
    "from \n",
    "  user_kposminin.cred_app_visits v\n",
    "  left join user_kposminin.urlfr_tgt_cnt t on t.urlfr = v.urlfr\n",
    "group by\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd,\n",
    "  v.ymd,\n",
    "  v.urlfr\n",
    ";\n",
    "\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 2/2.\n",
    "create table user_kposminin.cred_app_sc_2 as\n",
    "select \n",
    "  phone_mobile, \n",
    "  call_ymd, \n",
    "  max(default_flg) as default_flg,\n",
    "  (unix_timestamp(max(ymd), 'yyyy-MM-dd') - unix_timestamp(min(ymd), 'yyyy-MM-dd'))/60/60/24 as ymd_range,\n",
    "  stddev(unix_timestamp(ymd, 'yyyy-MM-dd')/60/60 + avg_hour) as time_std,\n",
    "  count(distinct ymd) as ymd_cnt,\n",
    "  max(id_cnt) as id_cnt,\n",
    "  max(load_src_cnt) as load_src_cnt,\n",
    "  avg(avg_hour) as avg_hour,\n",
    "  percentile_approx(avg_hour,0.1) as avg_hour_q10,\n",
    "  percentile_approx(avg_hour,0.9) as avg_hour_q90,\n",
    "  percentile_approx(avg_hour,0.5) as avg_hour_q50,\n",
    "  count(*) as cnt,\n",
    "  sum(cnt) as hits,\n",
    "  avg(cnt) as avg_hits,\n",
    "  avg(duration) as avg_duration,\n",
    "  percentile_approx(duration,0.1) as duration_q10,\n",
    "  percentile_approx(duration,0.9) as duration_q90,\n",
    "  min(first_visit) as min_first_visit,\n",
    "  avg(first_visit) as avg_first_visit,\n",
    "  max(if(financial_product_type_cd = 'CCR',1,0)) as CCR,\n",
    "  max(score) as max_score,\n",
    "  avg(score) as avg_score,\n",
    "  percentile_approx(score, array(0.1,0.3,0.5,0.7,0.8,0.9,0.98)) as score_q_arr,\n",
    "  max(score * ( - log(lag + 1))) as max_w_score,\n",
    "  percentile_approx(score * ( - log(lag + 1)), array(0.1,0.3,0.5,0.7,0.8,0.9,0.98)) as w_score_q_arr,\n",
    "  avg(if(score > -2.5, avg_hour,Null)) as avg_good_hour,\n",
    "  sum(if(regexp_extract(urlfr, '\\.([^.#]*)#', 1) in ('ru','com','org'),1,0))/sum(1) as ru_com_share,\n",
    "  sum(if(urlfr like 'e.mail.ru%',1,0))/sum(1) as emailru_share,\n",
    "  sum(if(urlfr like 'm.%',1,0))/sum(1) as mobile_share,\n",
    "  sum(if(urlfr rlike '^(m\\\\.)?vk.com%', 1, 0))/sum(1) as vk_share,\n",
    "  sum(if(urlfr like 'vk.com%' or urlfr rlike '^(m\\\\.)?ok\\\\.ru' or urlfr like 'm.odnoklassniki.ru%' or urlfr rlike '^(m\\\\.)?my.mail.ru',1,0))/sum(1) as social_share,\n",
    "  count(distinct urlfr) as urlfr_cnt    \n",
    "\n",
    "from \n",
    "  user_kposminin.cred_app_sc_1_1\n",
    "group by\n",
    "  phone_mobile, \n",
    "  call_ymd\n",
    ";\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Результат см в ноутбуке  credit_scoring_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylightgbm.models import GBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тематическое моделирование BigARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "-- Статистика урлфрагментов на обучающей выборке\n",
    "create table user_kposminin.cred_app_urlfr_stat as \n",
    "select\n",
    "  urlfr,\n",
    "  count(distinct phone_mobile,call_ymd) as visitors_cnt\n",
    "from\n",
    "  user_kposminin.cred_app_visits\n",
    "  where call_ymd < '2017-06-01'\n",
    "group by urlfr\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "-- Формирование данных для BigARTM в задача cred_scoring\n",
    "create table user_kposminin.cred_app_features_4_thematic_modelling as\n",
    "select\n",
    "  phone_mobile, \n",
    "  call_ymd, \n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',hits))) as feat_hits,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',cnt))) as feat_cnt,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',1))) as feat_1,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',ymd_cnt))) as feat_ymd,\n",
    "  sum(hits) as hits,\n",
    "  sum(cnt) as cnt,\n",
    "  max(ymd_cnt) as max_ymd_cnt\n",
    "  \n",
    "from\n",
    "  (select \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    max(default_flg) as default_flg,\n",
    "    v.urlfr,\n",
    "    count(*) as cnt,\n",
    "    count(distinct ymd) as ymd_cnt,\n",
    "    sum(cnt) as hits\n",
    "  from user_kposminin.cred_app_visits v\n",
    "  left join user_kposminin.cred_app_urlfr_stat st on st.urlfr = v.urlfr\n",
    "  where coalesce(st.visitors_cnt,1000) > 300\n",
    "  group by \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    v.urlfr\n",
    "  order by \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    v.urlfr\n",
    "  ) a  \n",
    "group by \n",
    "  phone_mobile, \n",
    "  call_ymd\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
