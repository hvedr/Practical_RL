{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "#sc.setCheckpointDir('/user/kposminin/checkpointdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def repart(filename):\n",
    "    starttime = datetime.datetime.now()\n",
    "    sc.textFile(filename).repartition(32*8).saveAsTextFile('.'.join(filename.split('.')[:-1]))\n",
    "    print('End. Time of work {0}.'.format(datetime.datetime.now() - starttime))\n",
    "#repart(\"/user/kposminin/la_app_20160817_1.txt\")\n",
    "#repart(\"/user/kposminin/la_app_20160818_1.txt\")\n",
    "#repart(\"/user/kposminin/la_app_20160824_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(table):\n",
    "    si = 15 #score start index\n",
    "    def top_avg_score(slist): \n",
    "        return [sum(slist[:i])/i for i in [2,3,4,5,7,10]]\n",
    "    return [r + top_avg_score(r[si:si+11]) for r in table] \n",
    "\n",
    "def add_feature_rdd(row):\n",
    "    si = 15 #score start index\n",
    "    def top_avg_score(slist): \n",
    "        return [sum(slist[:i])/i for i in [2,3,4,5,7,10]]\n",
    "    r = row\n",
    "    return r + top_avg_score(r[si:si+11])\n",
    "    \n",
    "    \n",
    "# Load and parse the data file.\n",
    "# Load and parse the data file.\n",
    "train = sc.textFile(\"/user/kposminin/la_20160817_3.txt\") \\\n",
    "  .filter(lambda s: (s[0] == '1') or (hash(s) % 1000 == 0)) \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \\\n",
    "  .collect()\n",
    "\n",
    "test = sc.textFile(\"/user/kposminin/la_20160824_3.txt\") \\\n",
    "  .filter(lambda s: (s[0] == '1') or (hash(s) % 1000 == 17)) \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \\\n",
    "  .collect()\n",
    "\n",
    "test_rdd = sc.textFile(\"/user/kposminin/la_20160824_3.txt\") \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \n",
    "\n",
    "test_rdd2 = sc.textFile(\"/user/kposminin/la_20160818_3.txt\") \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2 = sc.textFile(\"/user/kposminin/la_20160818_3.txt\") \\\n",
    "  .filter(lambda s: (s[0] == '1') or (hash(s) % 300 == 87)) \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = '''smax ,savg ,ssum ,smedian ,sstd ,cntrepeat ,cntuniq \n",
    ",duration , has_scores, mobile ,emailru ,vkru ,okru ,social_other , s1 ,s2 ,s3 ,s4 ,s5 ,s6 ,s7 ,s8 ,s9 ,s10 , \n",
    "sm1 ,sm2 ,sm3 ,sm4 ,sm5, avg2, avg3,avg4,avg5,avg7,avg10'''.replace(' ','').replace('\\n','').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score  AUCROC on sampled test data 0.818371529014\n"
     ]
    }
   ],
   "source": [
    "aucroc_smax = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    "    )\n",
    "print('Max score  AUCROC on sampled test data {0}'.format(aucroc_smax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test AUC ROC 0.843090200848\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(test_rdd.map(lambda r: (float(r[1]),float(r[0]))))\n",
    "print('Full test AUC ROC {0}'.format(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full test 20160818 AUC ROC 0.843819806579\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(test_rdd2.map(lambda r: (float(r[1]),float(r[0]))))\n",
    "print('Full test 20160818 AUC ROC {0}'.format(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Варьируем размер семплирования  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5023 ['test on 5023-model', 0.87585529174876009]\n",
      "8845 ['test on 8845-model', 0.87230379889219778]\n",
      "16264 ['test on 16264-model', 0.8698999084238872]\n",
      "31226 ['test on 31226-model', 0.86535683842561495]\n",
      "76957 ['test on 76957-model', 0.87027077578850187]\n",
      "152483 ['test on 152483-model', 0.86609921153177005]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelGBT = {}\n",
    "AUCROC=[]\n",
    "\n",
    "for f in [40,20,10,5,2,1]:\n",
    "    train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    s = len(train1)\n",
    "    modelGBT[s] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2000, learning_rate=0.04,\n",
    "       max_depth=3, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append(['GBT test on {0}-model'.format(s),sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    #AUCROC.append(['train '+ str(s), sklearn.metrics.roc_auc_score(\n",
    "    #    y_true = [e[0] for e in train1], \n",
    "    #    y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in train1])]\n",
    "    #)])    \n",
    "    print('{0} {1}'.format(s,AUCROC[-1]))\n",
    "\n",
    "AUCROC.append(['smax '+ str(s), sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    ")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше объем выборки, тем лучше обучение. Достигается улучшение по сравнению с текущим подходом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5048 ['test on 5048-model', 0.87488486723995595]\n",
      "8853 ['test on 8853-model', 0.87578267300647705]\n",
      "16479 ['test on 16479-model', 0.85510116496516331]\n"
     ]
    }
   ],
   "source": [
    "modelRF = {}\n",
    "\n",
    "\n",
    "for f in [40,20,10,2]:\n",
    "    train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    s = len(train1)\n",
    "    modelRF[s] = sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, \n",
    "                min_samples_split=20, min_samples_leaf=10, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, \n",
    "                warm_start=False, class_weight='auto') \\\n",
    "    .fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    \n",
    "    AUCROC.append(['RF test on {0}-model'.format(s),sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelRF[s].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    #AUCROC.append(['train '+ str(s), sklearn.metrics.roc_auc_score(\n",
    "    #    y_true = [e[0] for e in train1], \n",
    "    #    y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in train1])]\n",
    "    #)])    \n",
    "    print('{0} {1}'.format(s,AUCROC[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество сравнимо с градиентным бустингом. Достигается улучшение по сравнению с текущим подходом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5125 ['LR test on 5125-model', 0.83345360139130609]\n",
      "8780 ['LR test on 8780-model', 0.82907160978351158]\n",
      "16295 ['LR test on 16295-model', 0.83297771967560108]\n",
      "152483 ['LR test on 152483-model', 0.83209338177671432]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "modelLR = {}\n",
    "AUCROC = []\n",
    "for f in [40,20,10,1]:\n",
    "    train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    s = len(train1)\n",
    "    \n",
    "    modelRF[s] = sklearn.linear_model.LogisticRegression(penalty='l1', class_weight = 'auto') \\\n",
    "        .fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append(['LR test on {0}-model'.format(s),sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelRF[s].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    print('{0} {1}'.format(s,AUCROC[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия хуже текущего подхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*20) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_table_to_file(table, filename):\n",
    "    f = open(filename,'w+')\n",
    "    #f.write('label,' + ','.join(columns)+'\\n')\n",
    "    f.write('\\n'.join([','.join([str(e) for e in r]) for r in table]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Варьируем параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT 30 trees ['GBT 30 trees', 0.84589361214189684]\n",
      "GBT 50 trees ['GBT 50 trees', 0.84528972103790279]\n",
      "GBT 100 trees ['GBT 100 trees', 0.85903091365852413]\n",
      "GBT 200 trees ['GBT 200 trees', 0.86655869477184377]\n",
      "GBT 500 trees ['GBT 500 trees', 0.87359304284435757]\n",
      "GBT 1000 trees ['GBT 1000 trees', 0.87196810959784354]\n",
      "GBT 2000 trees ['GBT 2000 trees', 0.86931065419843812]\n"
     ]
    }
   ],
   "source": [
    "# Train a GradientBoostedTrees model.\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "modelGBT = {}\n",
    "AUCROC1={}\n",
    "\n",
    "for n in [30,50,100,200,500,1000,2000]:\n",
    "    key = 'GBT {0} trees'.format(n)\n",
    "    modelGBT[key] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=n, learning_rate=0.06,\n",
    "       max_depth=3, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append([key,sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[key].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    print('{0} {1}'.format(key,AUCROC[-1]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT 1 depth ['GBT 1 depth', 0.8879349885558141]\n",
      "GBT 2 depth ['GBT 2 depth', 0.87755841674118451]\n",
      "GBT 3 depth ['GBT 3 depth', 0.86931065419843812]\n",
      "GBT 5 depth ['GBT 5 depth', 0.86385182037894159]\n",
      "GBT 7 depth ['GBT 7 depth', 0.83871529256437416]\n",
      "GBT 9 depth ['GBT 9 depth', 0.85280441138388219]\n",
      "GBT 13 depth ['GBT 13 depth', 0.84844868481154767]\n"
     ]
    }
   ],
   "source": [
    "# Вариация глубины\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "\n",
    "\n",
    "for d in [1,2,3,5,7,9,13]:\n",
    "    key = 'GBT {0} depth'.format(d)\n",
    "    modelGBT[key] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2000, learning_rate=0.06,\n",
    "       max_depth = d, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append([key,sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[key].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    print('{0} {1}'.format(key,AUCROC[-1]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT 200-trees 1-depth 0.03-learn rate ['GBT 200-trees 1-depth 0.03-learn rate', 0.84971364889193668]\n",
      "GBT 200-trees 1-depth 0.05-learn rate ['GBT 200-trees 1-depth 0.05-learn rate', 0.86601748312381921]\n",
      "GBT 200-trees 1-depth 0.07-learn rate ['GBT 200-trees 1-depth 0.07-learn rate', 0.87431954272171908]\n",
      "GBT 200-trees 1-depth 0.1-learn rate ['GBT 200-trees 1-depth 0.1-learn rate', 0.8805847381800741]\n",
      "GBT 200-trees 3-depth 0.03-learn rate ['GBT 200-trees 3-depth 0.03-learn rate', 0.85819464527279732]\n",
      "GBT 200-trees 3-depth 0.05-learn rate ['GBT 200-trees 3-depth 0.05-learn rate', 0.86671247896521098]\n",
      "GBT 200-trees 3-depth 0.07-learn rate ['GBT 200-trees 3-depth 0.07-learn rate', 0.86651242187222643]\n",
      "GBT 200-trees 3-depth 0.1-learn rate ['GBT 200-trees 3-depth 0.1-learn rate', 0.86498075630265225]\n",
      "GBT 200-trees 5-depth 0.03-learn rate ['GBT 200-trees 5-depth 0.03-learn rate', 0.85553795215469985]\n",
      "GBT 200-trees 5-depth 0.05-learn rate ['GBT 200-trees 5-depth 0.05-learn rate', 0.86698257435703985]\n",
      "GBT 200-trees 5-depth 0.07-learn rate ['GBT 200-trees 5-depth 0.07-learn rate', 0.86887557742809096]\n",
      "GBT 200-trees 5-depth 0.1-learn rate ['GBT 200-trees 5-depth 0.1-learn rate', 0.86897149019423403]\n",
      "GBT 200-trees 7-depth 0.03-learn rate ['GBT 200-trees 7-depth 0.03-learn rate', 0.85015613568305604]\n",
      "GBT 200-trees 7-depth 0.05-learn rate ['GBT 200-trees 7-depth 0.05-learn rate', 0.86172814505820028]\n",
      "GBT 200-trees 7-depth 0.07-learn rate ['GBT 200-trees 7-depth 0.07-learn rate', 0.86827678256520968]\n",
      "GBT 200-trees 7-depth 0.1-learn rate ['GBT 200-trees 7-depth 0.1-learn rate', 0.8702950772088609]\n",
      "GBT 500-trees 1-depth 0.03-learn rate ['GBT 500-trees 1-depth 0.03-learn rate', 0.8768722315787989]\n",
      "GBT 500-trees 1-depth 0.05-learn rate ['GBT 500-trees 1-depth 0.05-learn rate', 0.88408045251604284]\n",
      "GBT 500-trees 1-depth 0.07-learn rate ['GBT 500-trees 1-depth 0.07-learn rate', 0.88822259217556754]\n",
      "GBT 500-trees 1-depth 0.1-learn rate ['GBT 500-trees 1-depth 0.1-learn rate', 0.88948290445447564]\n",
      "GBT 500-trees 3-depth 0.03-learn rate ['GBT 500-trees 3-depth 0.03-learn rate', 0.86924134047087209]\n",
      "GBT 500-trees 3-depth 0.05-learn rate ['GBT 500-trees 3-depth 0.05-learn rate', 0.87256546878603491]\n",
      "GBT 500-trees 3-depth 0.07-learn rate ['GBT 500-trees 3-depth 0.07-learn rate', 0.87190616548744704]\n",
      "GBT 500-trees 3-depth 0.1-learn rate ['GBT 500-trees 3-depth 0.1-learn rate', 0.86977532256755108]\n",
      "GBT 500-trees 5-depth 0.03-learn rate ['GBT 500-trees 5-depth 0.03-learn rate', 0.87139475014977619]\n",
      "GBT 500-trees 5-depth 0.05-learn rate ['GBT 500-trees 5-depth 0.05-learn rate', 0.86899637612004854]\n",
      "GBT 500-trees 5-depth 0.07-learn rate ['GBT 500-trees 5-depth 0.07-learn rate', 0.86958848014628898]\n",
      "GBT 500-trees 5-depth 0.1-learn rate ['GBT 500-trees 5-depth 0.1-learn rate', 0.87272255799411957]\n",
      "GBT 500-trees 7-depth 0.03-learn rate ['GBT 500-trees 7-depth 0.03-learn rate', 0.87025225208335788]\n",
      "GBT 500-trees 7-depth 0.05-learn rate ['GBT 500-trees 7-depth 0.05-learn rate', 0.87053494262499842]\n",
      "GBT 500-trees 7-depth 0.07-learn rate ['GBT 500-trees 7-depth 0.07-learn rate', 0.87212787083086685]\n",
      "GBT 500-trees 7-depth 0.1-learn rate ['GBT 500-trees 7-depth 0.1-learn rate', 0.86937650129687483]\n",
      "GBT 2000-trees 1-depth 0.03-learn rate ['GBT 2000-trees 1-depth 0.03-learn rate', 0.88986008555543727]\n",
      "GBT 2000-trees 1-depth 0.05-learn rate ['GBT 2000-trees 1-depth 0.05-learn rate', 0.88869697626439181]\n",
      "GBT 2000-trees 1-depth 0.07-learn rate ['GBT 2000-trees 1-depth 0.07-learn rate', 0.8880931471125888]\n",
      "GBT 2000-trees 1-depth 0.1-learn rate ['GBT 2000-trees 1-depth 0.1-learn rate', 0.8874717343128028]\n",
      "GBT 2000-trees 3-depth 0.03-learn rate ['GBT 2000-trees 3-depth 0.03-learn rate', 0.87246653652396833]\n",
      "GBT 2000-trees 3-depth 0.05-learn rate ['GBT 2000-trees 3-depth 0.05-learn rate', 0.86890544646492973]\n",
      "GBT 2000-trees 3-depth 0.07-learn rate ['GBT 2000-trees 3-depth 0.07-learn rate', 0.87100048371193406]\n",
      "GBT 2000-trees 3-depth 0.1-learn rate ['GBT 2000-trees 3-depth 0.1-learn rate', 0.86714911800820371]\n",
      "GBT 2000-trees 5-depth 0.03-learn rate ['GBT 2000-trees 5-depth 0.03-learn rate', 0.86648360063548946]\n",
      "GBT 2000-trees 5-depth 0.05-learn rate ['GBT 2000-trees 5-depth 0.05-learn rate', 0.86598457573604171]\n",
      "GBT 2000-trees 5-depth 0.07-learn rate ['GBT 2000-trees 5-depth 0.07-learn rate', 0.86139301602713947]\n",
      "GBT 2000-trees 5-depth 0.1-learn rate ['GBT 2000-trees 5-depth 0.1-learn rate', 0.84257344876696549]\n",
      "GBT 2000-trees 7-depth 0.03-learn rate ['GBT 2000-trees 7-depth 0.03-learn rate', 0.86390569993019883]\n",
      "GBT 2000-trees 7-depth 0.05-learn rate ['GBT 2000-trees 7-depth 0.05-learn rate', 0.84543328581330934]\n",
      "GBT 2000-trees 7-depth 0.07-learn rate ['GBT 2000-trees 7-depth 0.07-learn rate', 0.84140361092924998]\n",
      "GBT 2000-trees 7-depth 0.1-learn rate ['GBT 2000-trees 7-depth 0.1-learn rate', 0.84704606296249663]\n",
      "GBT 4000-trees 1-depth 0.03-learn rate ['GBT 4000-trees 1-depth 0.03-learn rate', 0.88872701768993634]\n",
      "GBT 4000-trees 1-depth 0.05-learn rate ['GBT 4000-trees 1-depth 0.05-learn rate', 0.88728879487958123]\n",
      "GBT 4000-trees 1-depth 0.07-learn rate ['GBT 4000-trees 1-depth 0.07-learn rate', 0.88661720888571127]\n",
      "GBT 4000-trees 1-depth 0.1-learn rate ['GBT 4000-trees 1-depth 0.1-learn rate', 0.8859020193235887]\n",
      "GBT 4000-trees 3-depth 0.03-learn rate ['GBT 4000-trees 3-depth 0.03-learn rate', 0.86880634181415739]\n",
      "GBT 4000-trees 3-depth 0.05-learn rate ['GBT 4000-trees 3-depth 0.05-learn rate', 0.86902663572504879]\n",
      "GBT 4000-trees 3-depth 0.07-learn rate ['GBT 4000-trees 3-depth 0.07-learn rate', 0.868610667165301]\n",
      "GBT 4000-trees 3-depth 0.1-learn rate ['GBT 4000-trees 3-depth 0.1-learn rate', 0.85926579057648977]\n",
      "GBT 4000-trees 5-depth 0.03-learn rate ['GBT 4000-trees 5-depth 0.03-learn rate', 0.86076368142761128]\n",
      "GBT 4000-trees 5-depth 0.05-learn rate ['GBT 4000-trees 5-depth 0.05-learn rate', 0.84714024645443564]\n",
      "GBT 4000-trees 5-depth 0.07-learn rate ['GBT 4000-trees 5-depth 0.07-learn rate', 0.83595683085128614]\n",
      "GBT 4000-trees 5-depth 0.1-learn rate ['GBT 4000-trees 5-depth 0.1-learn rate', 0.83935397655761412]\n",
      "GBT 4000-trees 7-depth 0.03-learn rate ['GBT 4000-trees 7-depth 0.03-learn rate', 0.84389401628566874]\n",
      "GBT 4000-trees 7-depth 0.05-learn rate ['GBT 4000-trees 7-depth 0.05-learn rate', 0.84538437051806192]\n",
      "GBT 4000-trees 7-depth 0.07-learn rate ['GBT 4000-trees 7-depth 0.07-learn rate', 0.84140361092924998]\n",
      "GBT 4000-trees 7-depth 0.1-learn rate ['GBT 4000-trees 7-depth 0.1-learn rate', 0.84704606296249663]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for n,d,lr in itertools.product([200,500,2000,4000],[1,3,5,7],[0.03,0.05,0.07,0.1]):\n",
    "    key = 'GBT {0}-trees {1}-depth {2}-learn rate'.format(n,d,lr)\n",
    "    modelGBT[key] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=n, learning_rate=lr,\n",
    "       max_depth = d, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append([key,sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[key].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    print('{0} {1}'.format(key,AUCROC[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 500-trees 15-depth 10-min leaf ['RF 500-trees 15-depth 10-min leaf', 0.88782539243615455]\n",
      "RF 500-trees 15-depth 20-min leaf ['RF 500-trees 15-depth 20-min leaf', 0.88768306670457076]\n",
      "RF 500-trees 15-depth 40-min leaf ['RF 500-trees 15-depth 40-min leaf', 0.88563079801802558]\n",
      "RF 500-trees 18-depth 10-min leaf ['RF 500-trees 18-depth 10-min leaf', 0.88731923764758158]\n",
      "RF 500-trees 18-depth 20-min leaf ['RF 500-trees 18-depth 20-min leaf', 0.88838619713801348]\n",
      "RF 500-trees 18-depth 40-min leaf ['RF 500-trees 18-depth 40-min leaf', 0.88465178370324449]\n",
      "RF 1000-trees 15-depth 10-min leaf ['RF 1000-trees 15-depth 10-min leaf', 0.88869619782164255]\n",
      "RF 1000-trees 15-depth 20-min leaf ['RF 1000-trees 15-depth 20-min leaf', 0.88775841134326294]\n",
      "RF 1000-trees 15-depth 40-min leaf ['RF 1000-trees 15-depth 40-min leaf', 0.88593394086345512]\n",
      "RF 1000-trees 18-depth 10-min leaf ['RF 1000-trees 18-depth 10-min leaf', 0.88859274843677116]\n",
      "RF 1000-trees 18-depth 20-min leaf ['RF 1000-trees 18-depth 20-min leaf', 0.88827000176321325]\n",
      "RF 1000-trees 18-depth 40-min leaf ['RF 1000-trees 18-depth 40-min leaf', 0.88510650201174923]\n",
      "RF 2000-trees 15-depth 10-min leaf ['RF 2000-trees 15-depth 10-min leaf', 0.88762299462777527]\n",
      "RF 2000-trees 15-depth 20-min leaf ['RF 2000-trees 15-depth 20-min leaf', 0.88808596873914003]\n",
      "RF 2000-trees 15-depth 40-min leaf ['RF 2000-trees 15-depth 40-min leaf', 0.88479691075129629]\n",
      "RF 2000-trees 18-depth 10-min leaf ['RF 2000-trees 18-depth 10-min leaf', 0.88813313321159459]\n",
      "RF 2000-trees 18-depth 20-min leaf ['RF 2000-trees 18-depth 20-min leaf', 0.88829314494695577]\n",
      "RF 2000-trees 18-depth 40-min leaf ['RF 2000-trees 18-depth 40-min leaf', 0.88566723398712277]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "model = {}\n",
    "for n,d,ls in itertools.product([500,1000,2000],[15,18],[10,20,40]):\n",
    "    key = 'RF {0}-trees {1}-depth {2}-min leaf'.format(n,d,ls)\n",
    "    model[key] = sklearn.ensemble.RandomForestClassifier(n_estimators = n, criterion='gini', max_depth = d, \n",
    "                min_samples_split=20, min_samples_leaf = ls, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                max_leaf_nodes=None, bootstrap=True, oob_score=False, random_state=None, verbose=0, \n",
    "                warm_start=False, class_weight='auto') \\\n",
    "    .fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append([key,sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in model[key].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    print('{0} {1}'.format(key,AUCROC[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0060000000000000001, 'social_other'),\n",
       " (0.0001619221317144149, 0.021999999999999999, 'emailru'),\n",
       " (0.00066509547187676009, 0.0, 'okru'),\n",
       " (0.0017624640643627231, 0.0, 'vkru'),\n",
       " (0.0023055360894703157, 0.040000000000000001, 'mobile'),\n",
       " (0.0028449690172619615, 0.016, 's10'),\n",
       " (0.0040044522704579307, 0.0060000000000000001, 's9'),\n",
       " (0.0046076953433872242, 0.0, 's8'),\n",
       " (0.0047726843288324536, 0.0, 's7'),\n",
       " (0.0069552274972296962, 0.040000000000000001, 'duration'),\n",
       " (0.0074199581358142504, 0.0, 's6'),\n",
       " (0.0085602519137338504, 0.032000000000000001, 's5'),\n",
       " (0.0085941953517960357, 0.051999999999999998, 'cntrepeat'),\n",
       " (0.009044052066678996, 0.0040000000000000001, 'sstd'),\n",
       " (0.0094969168531821527, 0.106, 'sm5'),\n",
       " (0.015386514597758038, 0.01, 's4'),\n",
       " (0.015813316296610598, 0.056000000000000001, 'smedian'),\n",
       " (0.018193779567013152, 0.002, 's3'),\n",
       " (0.021363422025643501, 0.002, 'has_scores'),\n",
       " (0.021843157622157251, 0.050000000000000003, 'cntuniq'),\n",
       " (0.021952372918380401, 0.043999999999999997, 'sm4'),\n",
       " (0.023047902082895255, 0.017999999999999999, 'sm3'),\n",
       " (0.025712399539846546, 0.01, 'avg10'),\n",
       " (0.02783317186689702, 0.01, 'sm2'),\n",
       " (0.030677678918302701, 0.071999999999999995, 'ssum'),\n",
       " (0.036676705562510042, 0.012, 'avg7'),\n",
       " (0.037224377732379188, 0.01, 's2'),\n",
       " (0.045326891083536887, 0.002, 'avg5'),\n",
       " (0.057534995037898481, 0.021999999999999999, 'avg4'),\n",
       " (0.061563676634920184, 0.056000000000000001, 's1'),\n",
       " (0.074434157051601182, 0.01, 'avg3'),\n",
       " (0.077231492574275265, 0.032000000000000001, 'smax'),\n",
       " (0.079123472540086989, 0.035999999999999997, 'avg2'),\n",
       " (0.10660263037847878, 0.10199999999999999, 'sm1'),\n",
       " (0.13126246543300982, 0.12, 'savg')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(zip(modelGBT['GBT 500-trees 1-depth 0.1-learn rate'].feature_importances_,columns))\n",
    "sorted(zip(model['RF 1000-trees 18-depth 20-min leaf'].feature_importances_,\n",
    "           modelGBT['GBT 500-trees 1-depth 0.1-learn rate'].feature_importances_,columns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUCROC on 20160818 sampled test data:\\nsmax {0},\\nGBT  {1},\\nRF   {2}.'.format(\n",
    "    sklearn.metrics.roc_auc_score(\n",
    "           y_true = [e[0] for e in test2], \n",
    "           y_score = [e[columns.index('s1')+1] for e in test2]\n",
    "    ),\n",
    "    sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test2], \n",
    "        y_score = [r[1] for r in modelGBT['GBT 500-trees 1-depth 0.1-learn rate'].predict_proba([e[1:] for e in test2])]\n",
    "    ),\n",
    "    sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test2], \n",
    "        y_score = [r[1] for r in model['RF 1000-trees 18-depth 20-min leaf'].predict_proba([e[1:] for e in test2])]\n",
    "    )\n",
    "))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобранные модели градиентного бустинга и случайного леса показывают лучшую результативность на тестовой семплированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2000, learning_rate=0.03,\n",
    "       max_depth = 1, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "\n",
    "m2 = sklearn.ensemble.RandomForestClassifier(n_estimators = 1000, criterion='gini', max_depth = 18, \n",
    "                min_samples_split=20, min_samples_leaf = 20, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                max_leaf_nodes=None, bootstrap=True, oob_score=False, random_state=None, verbose=0, \n",
    "                warm_start=False, class_weight='auto') \\\n",
    "    .fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "print('AUC ROC on full test data 20160818. smax: {0}.'.format(\n",
    "        BinaryClassificationMetrics(test_rdd2.map(lambda r: (\n",
    "        float(r[1]),\n",
    "        float(r[0])\n",
    "       ))).areaUnderROC\n",
    "))\n",
    "print('AUC ROC on full test data 20160818.  GBT: {0}.'.format(\n",
    "        BinaryClassificationMetrics(test_rdd2.map(lambda r: (\n",
    "        float(m1.predict_proba(r[1:])[0][1]),\n",
    "        float(r[0])\n",
    "       ))).areaUnderROC\n",
    "))\n",
    "\n",
    "print('AUC ROC on full test data 20160818.   RF: {0}.'.format(\n",
    "        BinaryClassificationMetrics(test_rdd2.map(lambda r: (\n",
    "        float(m2.predict_proba(r[1:])[0][1]),\n",
    "        float(r[0])\n",
    "       ))).areaUnderROC\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
