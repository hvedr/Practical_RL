{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кредитный скоринг заявок на основе веб-лога\n",
    "#### На основании дефолта. Ещё один подход\n",
    "2017-04-21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "hive_config_query = '''\n",
    "set hive.vectorized.execution.enabled=true;\n",
    "set hive.vectorized.execution.reduce.enabled = true;\n",
    "set mapreduce.map.memory.mb=4096;\n",
    "set mapreduce.map.child.java.opts=-Xmx4g;\n",
    "set mapreduce.task.io.sort.mb=1024;\n",
    "set mapreduce.reduce.child.java.opts=-Xmx4g;\n",
    "set mapreduce.reduce.memory.mb=7000;\n",
    "set mapreduce.reduce.shuffle.input.buffer.percent=0.5;\n",
    "set mapreduce.input.fileinputformat.split.minsize=536870912;\n",
    "set mapreduce.input.fileinputformat.split.maxsize=1073741824;\n",
    "set hive.optimize.ppd=true;\n",
    "set hive.merge.smallfiles.avgsize=536870912;\n",
    "set hive.merge.mapredfiles=true;\n",
    "set hive.merge.mapfiles=true;\n",
    "set hive.hadoop.supports.splittable.combineinputformat=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=536870912;\n",
    "set hive.exec.parallel=true;\n",
    "set hive.exec.max.created.files=10000000;\n",
    "set hive.exec.compress.output=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=1000000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "set io.seqfile.compression.type=BLOCK;\n",
    "set mapreduce.map.failures.maxpercent=5;\n",
    "'''\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.executor.instances\", 4)\n",
    "        .set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "        .set(\"spark.executor.memory\", '16g')\n",
    "        .set(\"spark.yarn.executor.memoryOverhead\", 4048)      \n",
    "        .set('spark.akka.frameSize',2040)\n",
    "       )\n",
    "sc = SparkContext(conf=conf)    \n",
    "hc = HiveContext(sc)\n",
    "\n",
    "for q in hive_config_query.split(';'):\n",
    "    try:\n",
    "        hc.sql(q)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case sparkcontext doesn't work, use following (remove --driver-memory 4g string):\n",
    "#import os\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '''\n",
    "#--master yarn --deploy-mode client --num-executors 2 --executor-memory 8g --executor-cores 1 --conf spark.yarn.queue=kposminin\n",
    "#  pyspark-shell\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "from pylightgbm.models import GBMClassifier\n",
    "\n",
    "# full path to lightgbm executable (on Windows include .exe)\n",
    "exec_path = \"lightgbm\"\n",
    "\n",
    "import sklearn.model_selection\n",
    "import os\n",
    "\n",
    "os.environ[\"LIGHTGBM_EXEC\"] = exec_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.date(2016,12,31)\n",
    "\n",
    "for d in dates_to_calc_2016:\n",
    "    #date = str(start_date - datetime.timedelta(days = i))\n",
    "    #if (not date in calced_dates):\n",
    "    print(feature_visits_pattern.replace('#visit_ymd', d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация факторов\n",
    "##### Я.Каталог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = train_data1.take(100)\n",
    "#l = a[0][1]\n",
    "#[e[0] for e in l]\n",
    "#zip([list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)],range(500))\n",
    "a= (hc.sql(select_query)\n",
    "                .filter(\"call_ymd < '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .take(10)\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = (hc.sql(select_query)\n",
    "                .filter(\"call_ymd < '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .map(lambda (k,l):(k,[list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][2] if i in [e[0] for e in l] else 0 for i in range(420)] +\n",
    "                                     [list(l)[[e[0] for e in l].index(i)][3] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][4] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     list(list(l)[0][5:])))\n",
    "                .collect() \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = (hc.sql(select_query)\n",
    "                .filter(\"call_ymd >= '2016-06-15'\")\n",
    "                .rdd\n",
    "                .map(lambda r: ((r.phone_mobile,r.call_ymd,r.default_flg),r[3:]))\n",
    "                .groupByKey()\n",
    "                .map(lambda (k,l):(k,[list(l)[[e[0] for e in l].index(i)][1] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][2] if i in [e[0] for e in l] else 0 for i in range(420)] +\n",
    "                                     [list(l)[[e[0] for e in l].index(i)][3] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     [list(l)[[e[0] for e in l].index(i)][4] if i in [e[0] for e in l] else 0 for i in range(420)] + \n",
    "                                     list(list(l)[0][5:])))\n",
    "                .collect() \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix( [e[1] for e in train_data], label = [e[0][2] for e in train_data])\n",
    "dtest  = xgb.DMatrix( [e[1] for e in test_data],  label = [e[0][2] for e in test_data] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data[12] '+79678813486', u'2016-01-25'\n",
    "#dtest.get_label().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X, Y = datasets.make_classification(n_samples=200, n_features=10)\n",
    "#x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf=5,\n",
    "        is_unbalance = True,\n",
    "        num_iterations = 500,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 5,\n",
    "        metric = 'auc',\n",
    "        early_stopping_round=10\n",
    ")\n",
    "\n",
    "x_train, y_train, x_test, y_test = [e[1] for e in train_data],[e[0][2] for e in train_data], [e[1] for e in test_data],[e[0][2] for e in test_data]\n",
    "\n",
    "clf.fit( x_train, y_train, test_data=[(x_test, y_test)])\n",
    "y_test_pred = clf.predict(np.array(x_test))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('AUC ROC:  ',metrics.roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(np.array(x_test))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('AUC ROC:  ',metrics.roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На всех фичах AUC 0.538, что плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скорим урлфрагменты на основе default_flg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "-- скор урла - логарифм регуляризованного отношения кол-ва уникальных положительных посетителей к отрицательным посетителям.\n",
    "-- таких несколько партиций с интервалом в 3 месяца\n",
    "insert overwrite table user_kposminin.urlfr_tgt_cnt partition (ymd, target)\n",
    "select \n",
    "  urlfr,\n",
    "  cnt_positive,\n",
    "  cnt_total,\n",
    "  log((cnt_positive + 0.1) / (cnt_total - cnt_positive + 0.1)) as score,\n",
    "  ymd,\n",
    "  target\n",
    "from(\n",
    " select\n",
    "   urlfr,\n",
    "   count(distinct if(default_flg = 1, concat(phone_mobile, call_ymd), Null)) as  cnt_positive,\n",
    "   count(distinct concat(phone_mobile, call_ymd)) as cnt_total,\n",
    "   '2016-06-01' as ymd,\n",
    "   'tinkoff_LON_CCR_default' as target\n",
    " from \n",
    "   user_kposminin.cred_app_visits\n",
    " where\n",
    "   (not default_flg is Null)\n",
    "   and call_ymd < '2016-06-01'\n",
    " group by urlfr\n",
    " ) a\n",
    ";\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 1/4.\n",
    "create table user_kposminin.cred_app_sc_1_1 as\n",
    "select \n",
    "  phone_mobile\n",
    "  ,call_ymd\n",
    "  ,max(default_flg) as default_flg\n",
    "  ,v.urlfr\n",
    "  ,v.ymd\n",
    "  ,max(\n",
    "    named_struct(\n",
    "      'ymd', v.ymd,\n",
    "      'score', if(t.ymd < v.ymd,t.score, -10)\n",
    "    )\n",
    "   ).score as score\n",
    "  ,max(  id_cnt ) as id_cnt\n",
    "  ,max(  load_src_cnt ) as   load_src_cnt \n",
    "  ,max(  cnt ) as   cnt \n",
    "  ,max(  first_visit ) as   first_visit \n",
    "  ,max(  duration ) as   duration \n",
    "  ,max(  avg_hour ) as   avg_hour \n",
    "  ,max(  load_dttm ) as   load_dttm \n",
    "  ,max(  financial_product_type_cd ) as   financial_product_type_cd\n",
    "  ,(unix_timestamp(max(v.call_ymd), 'yyyy-MM-dd') - unix_timestamp(min(v.ymd), 'yyyy-MM-dd'))/60/60/24 as lag\n",
    "from \n",
    "  user_kposminin.cred_app_visits v\n",
    "  left join user_kposminin.urlfr_tgt_cnt t on t.urlfr = v.urlfr\n",
    "group by\n",
    "  v.phone_mobile, \n",
    "  v.call_ymd,\n",
    "  v.ymd,\n",
    "  v.urlfr\n",
    ";\n",
    "\n",
    "\n",
    "set hive.tez.auto.reducer.parallelism=true;\n",
    "\n",
    "set hive.tez.min.partition.factor=0.25;\n",
    "set hive.tez.max.partition.factor=2.0;\n",
    "set tez.runtime.pipelined.sorter.lazy-allocate.memory=true;\n",
    "set hive.exec.reducers.bytes.per.reducer=67108864;\n",
    "\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 2/4.\n",
    "create table user_kposminin.cred_app_sc_2 as\n",
    "select \n",
    "  phone_mobile, \n",
    "  call_ymd, \n",
    "  max(default_flg) as default_flg,\n",
    "  (unix_timestamp(max(ymd), 'yyyy-MM-dd') - unix_timestamp(min(ymd), 'yyyy-MM-dd'))/60/60/24 as ymd_range,\n",
    "  stddev(unix_timestamp(ymd, 'yyyy-MM-dd')/60/60 + avg_hour) as time_std,\n",
    "  count(distinct ymd) as ymd_cnt,\n",
    "  max(id_cnt) as id_cnt,\n",
    "  max(load_src_cnt) as load_src_cnt,\n",
    "  avg(avg_hour) as avg_hour,\n",
    "  percentile_approx(avg_hour,array(0.1,0.5,0.9)) as avg_hour_q_arr,\n",
    "  count(*) as cnt,\n",
    "  sum(cnt) as hits,\n",
    "  avg(cnt) as avg_hits,\n",
    "  avg(duration) as avg_duration,\n",
    "  percentile_approx(duration,0.1) as duration_q10,\n",
    "  percentile_approx(duration,0.9) as duration_q90,\n",
    "  min(first_visit) as min_first_visit,\n",
    "  avg(first_visit) as avg_first_visit,\n",
    "  max(if(financial_product_type_cd = 'CCR',1,0)) as CCR,\n",
    "  max(score) as max_score,\n",
    "  avg(score) as avg_score,\n",
    "  max(score * ( - log(lag + 1))) as max_w_score,\n",
    "  avg(if(score > -2.5, avg_hour,Null)) as avg_good_hour,\n",
    "  sum(if(regexp_extract(urlfr, '\\.([^.#]*)#', 1) in ('ru','com','org'),1,0))/sum(1) as ru_com_share,\n",
    "  sum(if(urlfr like 'e.mail.ru%',1,0))/sum(1) as emailru_share,\n",
    "  sum(if(urlfr like 'm.%',1,0))/sum(1) as mobile_share,\n",
    "  sum(if(urlfr rlike '^(m\\\\.)?vk.com%', 1, 0))/sum(1) as vk_share,\n",
    "  sum(if(urlfr like 'vk.com%' or urlfr rlike '^(m\\\\.)?ok\\\\.ru' or urlfr like 'm.odnoklassniki.ru%' or urlfr rlike '^(m\\\\.)?my.mail.ru',1,0))/sum(1) as social_share,\n",
    "  count(distinct urlfr) as urlfr_cnt    \n",
    "from \n",
    "  user_kposminin.cred_app_sc_1_1\n",
    "group by\n",
    "  phone_mobile, \n",
    "  call_ymd\n",
    ";\n",
    "\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 3/4.\n",
    "create table user_kposminin.cred_app_sc_3 as\n",
    "select \n",
    "  phone_mobile, \n",
    "  call_ymd,\n",
    "  percentile_approx(score * ( - log(lag + 1)), array(0.1,0.3,0.5,0.7,0.8,0.9,0.98)) as w_score_q_arr,\n",
    "  percentile_approx(score, array(0.1,0.3,0.5,0.7,0.8,0.9,0.98)) as score_q_arr\n",
    "from \n",
    "  user_kposminin.cred_app_sc_1_1\n",
    "group by\n",
    "  phone_mobile, \n",
    "  call_ymd\n",
    ";\n",
    "\n",
    "-- Генерация фичей на основе этого скоринга. Шаг 4/4.\n",
    "create table user_kposminin.cred_app_sc_4 as\n",
    "select \n",
    "  a.*,\n",
    "  b.w_score_q_arr,\n",
    "  b.score_q_arr\n",
    "from \n",
    "  user_kposminin.cred_app_sc_2 a\n",
    "  left join user_kposminin.cred_app_sc_3 b on a.phone_mobile = b.phone_mobile and  a.call_ymd = b.call_ymd\n",
    ";\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['phone_mobile','call_ymd','default_flg','ymd_range','time_std','ymd_cnt','id_cnt','load_src_cnt',\n",
    "        'avg_hour','avg_hour_q10','avg_hour_q50','avg_hour_q90','cnt','hits','avg_hits','avg_duration',\n",
    "        'duration_q10','duration_q90',\n",
    "        'min_first_visit','avg_first_visit','ccr','max_score','avg_score','max_w_score','avg_good_hour',\n",
    "        'ru_com_share','emailru_share','mobile_share','vk_share','social_share','urlfr_cnt',\n",
    "        'wscore_q10','wscore_q30','wscore_q50','wscore_q70','wscore_q80','wscore_q90','wscore_q98',\n",
    "        'score_q10','score_q30','score_q50','score_q70','score_q80','score_q90','score_q98']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train = (\n",
    "      hc.sql('select * from user_kposminin.cred_app_sc_4')\n",
    "        .filter('call_ymd <= \"2016-06-01\"')\n",
    "        .filter('not default_flg is Null')\n",
    "        .map(lambda r: \n",
    "                list(r[:9]) + (r[9] if r[9] else []) + list(r[10:-2])  + (r[-2] if r[-2] else []) + (r[-1] if r[-1] else [])\n",
    "            )\n",
    "        .toDF()\n",
    "        .toPandas()\n",
    "    )\n",
    "df_train.columns = cols\n",
    "feat_cols = [c for c in df_train.columns if not c in (u'phone_mobile', u'call_ymd', u'default_flg',\n",
    "                                                      u'min_first_visit',u'avg_first_visit')]\n",
    "    \n",
    "df_test = (\n",
    "      hc.sql('select * from user_kposminin.cred_app_sc_4')\n",
    "        .filter('call_ymd > \"2016-06-01\"')\n",
    "        .filter('not default_flg is Null')\n",
    "        .map(lambda r: \n",
    "                list(r[:9]) + (r[9] if r[9] else []) + list(r[10:-2])  + (r[-2] if r[-2] else []) + (r[-1] if r[-1] else [])\n",
    "            )\n",
    "        .toDF()\n",
    "        .toPandas()\n",
    "    )\n",
    "df_test.columns = cols\n",
    "label = 'default_flg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, model_selection\n",
    "from pylightgbm.models import GBMClassifier\n",
    "\n",
    "# full path to lightgbm executable (on Windows include .exe)\n",
    "exec_path = \"/usr/bin/lightgbm\"\n",
    "\n",
    "#X, Y = datasets.make_classification(n_samples=200, n_features=10)\n",
    "#x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf=10,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 200,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 127,\n",
    "        metric = 'auc',\n",
    "        early_stopping_round=10\n",
    ")\n",
    "\n",
    "#clf.fit(df_train[feat_cols], df_train[label], test_data = [(df_test[feat_cols], df_test[label])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[LightGBM] [Info] Iteration:47, valid_1 auc : 0.621389 - на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf=10,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 200,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 127,\n",
    "        metric = 'auc',\n",
    "        early_stopping_round=10,\n",
    "        verbose = False\n",
    ")\n",
    "\n",
    "r = cv(clf, df_train[feat_cols].values, df_train[label].values, folds = 5)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(r['roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Базовый классификатор дает 0.621389 - на тесте и 0.571297 на кросс-валидации. Тот же диспартитет будем наблюдать и дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Важность факторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "feat_imp = pd.DataFrame([(feat_cols[k],v) for k,v in clf.feature_importance().items()]) #.sort_values(ascending=False)\n",
    "feat_imp.index = feat_imp[0]\n",
    "feat_imp = feat_imp.sort(1, ascending = False)[1]\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "#print(\"Features as classifiers: AUC ROC on test. \")\n",
    "features_performance = [(\n",
    "        f,\n",
    "        sklearn.metrics.roc_auc_score(y_true = df_train[label],y_score = df_train[f].fillna(-1000)),\n",
    "        sklearn.metrics.average_precision_score(y_true = df_train[label],y_score = df_train[f].fillna(-1000)),\n",
    "    ) for f in feat_cols]\n",
    "print('Feature standalone performace\\n{:<30}  {:<15}  {:<15}\\n'.format('Feature','Train AUC ROC','Train AUC PR') + \n",
    "    '\\n'.join('{:<30}  {:<15.4f}  {:<15.4f}'.format(*e) for e in sorted(features_performance, key = lambda e: -e[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Param selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(clf, X, y, folds = 5, metrics = 'roc_auc,pr_auc', predict = False):\n",
    "    '''calc cross-validation metrics for clf classfier (actually LightGBM classifier) on X,y data.\n",
    "       In case predict == True, additionally returns cv proba predictions.'''\n",
    "    assert X.shape[0] == len(y), 'X and y lengths doesnt match'\n",
    "    idx = range(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    fold_idx = []\n",
    "    if predict:\n",
    "        y_pred = np.zeros(len(idx))\n",
    "    \n",
    "    for i in range(folds):\n",
    "        fold_idx.append(idx[i*len(idx)/folds:(i+1)*len(idx)/folds])\n",
    "    res = {k:[] for k in metrics.split(',')}\n",
    "    \n",
    "    for i in range(folds):\n",
    "        train_idx = reduce(lambda x,y: x + y, (fold_idx[:i] + fold_idx[(i+1):]))\n",
    "        valid_idx = fold_idx[i]\n",
    "        \n",
    "        clf.fit(X[train_idx],y[train_idx])\n",
    "        valid_pred = clf.predict_proba(X[valid_idx])[:,1]\n",
    "        if predict:\n",
    "            for j in range(len(valid_idx)):\n",
    "                y_pred[valid_idx[j]] = valid_pred[j]\n",
    "        \n",
    "        if('roc_auc' in metrics):\n",
    "            res['roc_auc'].append(\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = y[valid_idx],\n",
    "                  y_score = valid_pred\n",
    "                )\n",
    "            )\n",
    "        if('pr_auc' in metrics):\n",
    "            res['pr_auc'].append(\n",
    "                sklearn.metrics.average_precision_score(\n",
    "                  y_true = y[valid_idx],\n",
    "                  y_score = valid_pred\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    if predict:\n",
    "        return res, y_pred\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set high learning rate. Find optimum trees num\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 50,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 200,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 63,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    \n",
    "param_grid = {\n",
    "    'num_iterations': [30,70,100,150,200,300,500]\n",
    "\n",
    "}\n",
    "\n",
    "ngrid = 7\n",
    "grid_search = sklearn.model_selection.RandomizedSearchCV(clf, param_distributions=param_grid,\n",
    "                                   n_iter=ngrid,cv=5,scoring='roc_auc')\n",
    "\n",
    "grid_search.fit(df_train[feat_cols], df_train[label])\n",
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected learning_rate = 0.1,num_iterations = 70;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set high learning rate. Find optimum trees num\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 50,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 63,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    \n",
    "param_grid = {\n",
    "    'min_data_in_leaf': [10,50,100,200,500],\n",
    "    'num_leaves': [15,31,63,127,255],\n",
    "    'bagging_fraction': [0.5,0.8, 1],\n",
    "    'bagging_freq': [5,10,30],\n",
    "    'feature_fraction': [0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "   \n",
    "n_iter = 60\n",
    "\n",
    "grid_search = sklearn.model_selection.RandomizedSearchCV(clf, param_distributions=param_grid,\n",
    "                                   n_iter = n_iter, cv = 5,scoring='roc_auc')\n",
    "\n",
    "grid_search.fit(df_train[feat_cols], df_train[label])\n",
    "grid_search.grid_scores_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selected params:\n",
    "mean\t0.61121\t std\t0.01024\t params\t {'num_leaves'\t15\t 'bagging_fraction'\t1\t 'bagging_freq'\t5\t 'min_data_in_leaf'\t100\t 'feature_fraction'\t 0.8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 15,\n",
    "        learning_rate = 0.1,\n",
    "        feature_fraction = 0.8,\n",
    "        metric = 'auc',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "param_set = (\n",
    "    {'learning_rate':0.1, 'num_iterations':50, 'num_leaves':15},\n",
    "    {'learning_rate':0.1, 'num_iterations':70, 'num_leaves':15},\n",
    "    {'learning_rate':0.08, 'num_iterations':100, 'num_leaves':15},\n",
    "    {'learning_rate':0.08, 'num_iterations':100, 'num_leaves':31},\n",
    "    {'learning_rate':0.06, 'num_iterations':150, 'num_leaves':31},\n",
    "    {'learning_rate':0.06, 'num_iterations':150, 'num_leaves':15},\n",
    "    {'learning_rate':0.05, 'num_iterations':200, 'num_leaves':31},\n",
    "    {'learning_rate':0.04, 'num_iterations':200, 'num_leaves':63},\n",
    "    {'learning_rate':0.04, 'num_iterations':300, 'num_leaves':63},\n",
    "    {'learning_rate':0.03, 'num_iterations':400, 'num_leaves':31},\n",
    "    {'learning_rate':0.05, 'num_iterations':300, 'num_leaves':31},\n",
    ")\n",
    "\n",
    "\n",
    "#n_iter = 60\n",
    "res= []\n",
    "for param in param_set:\n",
    "    clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = param['num_iterations'],\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = param['num_iterations'],\n",
    "        learning_rate = param['learning_rate'],\n",
    "        feature_fraction = 0.8,\n",
    "        metric = 'auc',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    res.append((param,cv(clf, df_train[feat_cols].values, df_train[label].values, folds = 5, metrics = 'roc_auc,pr_auc')))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame([(k,v['pr_auc'],v['roc_auc']) for (k,v) in res],\n",
    "                      columns = ['feats','cv_pr','cv_roc'])\n",
    "df_res['avg_roc'] = df_res['cv_roc'].map(lambda l: sum(l)/len(l))\n",
    "df_res['std_roc'] = df_res['cv_roc'].map(lambda l: np.std(l))\n",
    "df_res['min_roc'] = df_res['cv_roc'].map(lambda l: min(l))\n",
    "df_res['max_roc'] = df_res['cv_roc'].map(lambda l: max(l))\n",
    "df_res['avg_pr'] = df_res['cv_pr'].map(lambda l: sum(l)/len(l))\n",
    "df_res['std_pr'] = df_res['cv_pr'].map(lambda l: np.std(l))\n",
    "df_res['min_pr'] = df_res['cv_pr'].map(lambda l: min(l))\n",
    "df_res['max_pr'] = df_res['cv_pr'].map(lambda l: max(l))\n",
    "df_res['feats_len'] = df_res['feats'].map(lambda l: len(l))\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res.loc[0]['feats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 15,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        feature_fraction = 0.8,\n",
    "    )\n",
    "\n",
    "#mean 0.61121 std 0.01024 params {'num_leaves' 15 'bagging_fraction' 1 'bagging_freq' 5 'min_data_in_leaf' 100 'feature_fraction' 0.8}\n",
    "r = cv(clf, df_train[feat_cols].values, df_train[label].values, folds = 5, metrics = 'roc_auc,pr_auc')\n",
    "print('CV AUC ROC {}; AUC PR {}'.format(np.mean(r['roc_auc']),np.mean(r['pr_auc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 2.851885 seconds\n",
      "[LightGBM] [Info] Number of positive: 7820, number of negative: 127078\n",
      "[LightGBM] [Info] Total Bins 8592\n",
      "[LightGBM] [Info] Number of data: 134898, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:1, valid_1 auc : 0.593282\n",
      "[LightGBM] [Info] 0.039797 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:2, valid_1 auc : 0.597723\n",
      "[LightGBM] [Info] 0.080450 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:3, valid_1 auc : 0.597559\n",
      "[LightGBM] [Info] 0.115997 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:4, valid_1 auc : 0.600037\n",
      "[LightGBM] [Info] 0.156155 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:5, valid_1 auc : 0.601017\n",
      "[LightGBM] [Info] 0.195139 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] Iteration:6, valid_1 auc : 0.603739\n",
      "[LightGBM] [Info] 0.427868 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:7, valid_1 auc : 0.605273\n",
      "[LightGBM] [Info] 0.467758 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:8, valid_1 auc : 0.606237\n",
      "[LightGBM] [Info] 0.510677 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:9, valid_1 auc : 0.607284\n",
      "[LightGBM] [Info] 0.547949 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:10, valid_1 auc : 0.607394\n",
      "[LightGBM] [Info] 0.588736 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:11, valid_1 auc : 0.60939\n",
      "[LightGBM] [Info] 0.633529 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:12, valid_1 auc : 0.609885\n",
      "[LightGBM] [Info] 0.674443 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:13, valid_1 auc : 0.610103\n",
      "[LightGBM] [Info] 0.714548 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] Iteration:14, valid_1 auc : 0.60938\n",
      "[LightGBM] [Info] 0.761194 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] Iteration:15, valid_1 auc : 0.608707\n",
      "[LightGBM] [Info] 0.800762 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:16, valid_1 auc : 0.610518\n",
      "[LightGBM] [Info] 0.843152 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:17, valid_1 auc : 0.610657\n",
      "[LightGBM] [Info] 0.883562 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:18, valid_1 auc : 0.609615\n",
      "[LightGBM] [Info] 0.923969 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:19, valid_1 auc : 0.610754\n",
      "[LightGBM] [Info] 0.963530 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:20, valid_1 auc : 0.610121\n",
      "[LightGBM] [Info] 1.005786 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:21, valid_1 auc : 0.611113\n",
      "[LightGBM] [Info] 1.047539 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:22, valid_1 auc : 0.61193\n",
      "[LightGBM] [Info] 1.093673 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:23, valid_1 auc : 0.614457\n",
      "[LightGBM] [Info] 1.132432 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:24, valid_1 auc : 0.61465\n",
      "[LightGBM] [Info] 1.175481 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:25, valid_1 auc : 0.615997\n",
      "[LightGBM] [Info] 1.218492 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:26, valid_1 auc : 0.617347\n",
      "[LightGBM] [Info] 1.258843 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:27, valid_1 auc : 0.617179\n",
      "[LightGBM] [Info] 1.298845 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:28, valid_1 auc : 0.617539\n",
      "[LightGBM] [Info] 1.340516 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:29, valid_1 auc : 0.619778\n",
      "[LightGBM] [Info] 1.379546 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:30, valid_1 auc : 0.622314\n",
      "[LightGBM] [Info] 1.417985 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:31, valid_1 auc : 0.622992\n",
      "[LightGBM] [Info] 1.458137 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:32, valid_1 auc : 0.623347\n",
      "[LightGBM] [Info] 1.495803 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:33, valid_1 auc : 0.623533\n",
      "[LightGBM] [Info] 1.535588 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:34, valid_1 auc : 0.625677\n",
      "[LightGBM] [Info] 1.574406 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:35, valid_1 auc : 0.625375\n",
      "[LightGBM] [Info] 1.612037 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:36, valid_1 auc : 0.625818\n",
      "[LightGBM] [Info] 1.650148 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:37, valid_1 auc : 0.626642\n",
      "[LightGBM] [Info] 1.688200 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:38, valid_1 auc : 0.626674\n",
      "[LightGBM] [Info] 1.724803 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:39, valid_1 auc : 0.628723\n",
      "[LightGBM] [Info] 1.761119 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:40, valid_1 auc : 0.631002\n",
      "[LightGBM] [Info] 1.794474 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:41, valid_1 auc : 0.631155\n",
      "[LightGBM] [Info] 1.833497 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:42, valid_1 auc : 0.630567\n",
      "[LightGBM] [Info] 1.866649 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:43, valid_1 auc : 0.630345\n",
      "[LightGBM] [Info] 1.904382 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] Iteration:44, valid_1 auc : 0.630741\n",
      "[LightGBM] [Info] 1.942770 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:45, valid_1 auc : 0.63053\n",
      "[LightGBM] [Info] 1.980390 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:46, valid_1 auc : 0.63269\n",
      "[LightGBM] [Info] 2.018770 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:47, valid_1 auc : 0.632721\n",
      "[LightGBM] [Info] 2.055906 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] Iteration:48, valid_1 auc : 0.632792\n",
      "[LightGBM] [Info] 2.093846 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:49, valid_1 auc : 0.634119\n",
      "[LightGBM] [Info] 2.131136 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:50, valid_1 auc : 0.633721\n",
      "[LightGBM] [Info] 2.167786 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:51, valid_1 auc : 0.633322\n",
      "[LightGBM] [Info] 2.197895 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] Iteration:52, valid_1 auc : 0.634756\n",
      "[LightGBM] [Info] 2.232423 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:53, valid_1 auc : 0.634887\n",
      "[LightGBM] [Info] 2.264908 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=12\n",
      "[LightGBM] [Info] Iteration:54, valid_1 auc : 0.635476\n",
      "[LightGBM] [Info] 2.295505 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] Iteration:55, valid_1 auc : 0.635692\n",
      "[LightGBM] [Info] 2.332198 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:56, valid_1 auc : 0.637175\n",
      "[LightGBM] [Info] 2.366209 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:57, valid_1 auc : 0.636506\n",
      "[LightGBM] [Info] 2.397307 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:58, valid_1 auc : 0.636702\n",
      "[LightGBM] [Info] 2.430911 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:59, valid_1 auc : 0.636852\n",
      "[LightGBM] [Info] 2.459982 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:60, valid_1 auc : 0.637172\n",
      "[LightGBM] [Info] 2.491340 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:61, valid_1 auc : 0.637412\n",
      "[LightGBM] [Info] 2.524141 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:62, valid_1 auc : 0.637025\n",
      "[LightGBM] [Info] 2.561131 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:63, valid_1 auc : 0.637554\n",
      "[LightGBM] [Info] 2.586952 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] Iteration:64, valid_1 auc : 0.637561\n",
      "[LightGBM] [Info] 2.621054 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=12\n",
      "[LightGBM] [Info] Iteration:65, valid_1 auc : 0.637323\n",
      "[LightGBM] [Info] 2.646216 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] Iteration:66, valid_1 auc : 0.637628\n",
      "[LightGBM] [Info] 2.674784 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:67, valid_1 auc : 0.637597\n",
      "[LightGBM] [Info] 2.705187 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:68, valid_1 auc : 0.638254\n",
      "[LightGBM] [Info] 2.735840 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] Iteration:69, valid_1 auc : 0.638454\n",
      "[LightGBM] [Info] 2.760557 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] Iteration:70, valid_1 auc : 0.638639\n",
      "[LightGBM] [Info] 2.791542 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n"
     ]
    }
   ],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 15,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        feature_fraction = 0.8,\n",
    "        early_stopping_round=100\n",
    "    )\n",
    "\n",
    "clf.fit(df_train[feat_cols], df_train[label], test_data = [(df_test[feat_cols], df_test[label])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[LightGBM] [Info] Iteration:72, valid_1 auc : 0.63864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, оптимальный классификатор имеет параметры:\n",
    "\n",
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 15,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        feature_fraction = 0.8        \n",
    "    )\n",
    "    \n",
    "На кросс-валидации дает AUCROC 0.6096, на тесте 0.63864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['pred'] = clf.predict_proba(df_test[feat_cols])[:,1]\n",
    "df_test['sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Feature importances')\n",
    "print(sorted(zip([e[1] for e in sorted(list(clf.feature_importance().items()))],feat_cols),reverse = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 1.950544 seconds\n",
      "[LightGBM] [Info] Number of positive: 6292, number of negative: 101627\n",
      "[LightGBM] [Info] Total Bins 8541\n",
      "[LightGBM] [Info] Number of data: 107919, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.035844 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.063501 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.094933 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.128848 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.159021 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.189137 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.219397 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.247530 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.278581 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 0.308245 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.338724 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.368797 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.402329 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.431860 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.459771 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.491388 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.522331 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.552790 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.587017 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.613932 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.643465 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.677782 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.709266 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.738997 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.773088 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 0.814692 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.848892 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.880661 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.911993 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.940185 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.971387 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 0.998854 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.027970 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 1.060817 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.090662 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.118476 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.145042 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.177222 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.204378 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.233635 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.262815 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.291735 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.319780 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.346870 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.377540 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.403381 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.428162 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.458858 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.487147 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.514389 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.538386 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.566790 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.592695 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.613315 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.639520 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.670531 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.694588 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.716107 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.740772 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.759977 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.785691 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.813176 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.837458 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.867525 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.886155 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.909933 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.936410 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.961635 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=12\n",
      "[LightGBM] [Info] 1.980227 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.001399 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 71 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 2.077279 seconds\n",
      "[LightGBM] [Info] Number of positive: 6217, number of negative: 101701\n",
      "[LightGBM] [Info] Total Bins 8548\n",
      "[LightGBM] [Info] Number of data: 107918, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.033185 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.068765 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.106882 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.143603 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.177948 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.216292 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.250204 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.291209 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.322627 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.357008 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.397418 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.430117 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.465131 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.505099 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.539540 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.578011 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.613992 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.652383 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.692282 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.724176 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.759557 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 0.799787 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.837054 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.879944 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.914442 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.951352 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.993377 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.030753 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.070093 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.110773 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.145290 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.182048 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.219037 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.253483 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.290575 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.321501 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.354954 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.387787 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.419708 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.451869 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.489101 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.522066 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.557599 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.591582 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.635153 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.676249 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.708036 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.742991 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.797793 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.842083 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.887237 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 1.929291 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.961691 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.995967 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.030271 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.066749 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 2.114989 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.151618 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.212554 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.250128 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 2.278489 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 2.312900 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.336049 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.355414 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.390656 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.408878 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.434463 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.454298 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.484520 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 2.512018 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 71 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 1.979068 seconds\n",
      "[LightGBM] [Info] Number of positive: 6275, number of negative: 101644\n",
      "[LightGBM] [Info] Total Bins 8548\n",
      "[LightGBM] [Info] Number of data: 107919, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.034454 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.066584 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.094481 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.129303 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.161374 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.196650 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.229132 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.260185 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.293280 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.327241 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.358082 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.396897 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.430510 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.465045 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.493795 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.527197 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.563561 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.593639 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.622571 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.661960 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.691579 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.719867 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.753710 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.784613 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.811645 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.848881 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.881360 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.914634 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.948617 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.978036 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.009444 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.042873 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.074538 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.106982 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.139862 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.170599 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.199831 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.231421 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.260552 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.295178 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.326460 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.357102 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.387623 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.417526 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.441998 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.485045 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.544354 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 1.579240 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.612646 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.637534 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.663896 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.691437 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.716553 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.745722 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.767971 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 1.792996 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.815393 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.836311 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.859222 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.883167 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.905261 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.932124 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.951451 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.975960 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.997071 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.017950 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.040065 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.063392 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 2.083833 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.100114 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 71 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 2.093074 seconds\n",
      "[LightGBM] [Info] Number of positive: 6265, number of negative: 101653\n",
      "[LightGBM] [Info] Total Bins 8549\n",
      "[LightGBM] [Info] Number of data: 107918, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.029612 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.059108 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.089906 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.127127 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.155577 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.185757 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.216653 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.253745 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.284091 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.315881 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.349754 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.387311 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.416371 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.445870 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.477468 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.514535 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.544949 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.575606 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.609629 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.646541 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.681361 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.718400 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.748475 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.780248 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.810318 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.844954 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.876895 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.917510 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.950001 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.981109 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.013684 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.051015 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.086168 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.118497 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.145815 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.178934 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.208473 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.240091 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.277551 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.315632 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.344749 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.375663 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.409531 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.433645 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.462963 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.495892 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.525713 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.552242 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.572227 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.603215 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.637250 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.667113 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.692516 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.719185 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.752882 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.785898 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.811073 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.834103 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.857051 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.887117 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.916066 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.943188 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.976325 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.003858 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 2.037938 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.070470 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.099093 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.134278 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 2.175819 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.216101 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 71 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading data in 1.991903 seconds\n",
      "[LightGBM] [Info] Number of positive: 6231, number of negative: 101687\n",
      "[LightGBM] [Info] Total Bins 8555\n",
      "[LightGBM] [Info] Number of data: 107918, number of used features: 39\n",
      "[LightGBM] [Info] Finished initializing training\n",
      "[LightGBM] [Info] Started training...\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.035943 seconds elapsed, finished iteration 1\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.068397 seconds elapsed, finished iteration 2\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.098438 seconds elapsed, finished iteration 3\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.126644 seconds elapsed, finished iteration 4\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.161324 seconds elapsed, finished iteration 5\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.194286 seconds elapsed, finished iteration 6\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.225879 seconds elapsed, finished iteration 7\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.255540 seconds elapsed, finished iteration 8\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.285977 seconds elapsed, finished iteration 9\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.321914 seconds elapsed, finished iteration 10\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.359960 seconds elapsed, finished iteration 11\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.388151 seconds elapsed, finished iteration 12\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 0.420280 seconds elapsed, finished iteration 13\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.453583 seconds elapsed, finished iteration 14\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.485831 seconds elapsed, finished iteration 15\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.518670 seconds elapsed, finished iteration 16\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.550831 seconds elapsed, finished iteration 17\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.580441 seconds elapsed, finished iteration 18\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.620166 seconds elapsed, finished iteration 19\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 0.653283 seconds elapsed, finished iteration 20\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.683378 seconds elapsed, finished iteration 21\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.720575 seconds elapsed, finished iteration 22\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.752361 seconds elapsed, finished iteration 23\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.786593 seconds elapsed, finished iteration 24\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.820518 seconds elapsed, finished iteration 25\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.852969 seconds elapsed, finished iteration 26\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 0.881294 seconds elapsed, finished iteration 27\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=5\n",
      "[LightGBM] [Info] 0.920624 seconds elapsed, finished iteration 28\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.953488 seconds elapsed, finished iteration 29\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 0.987279 seconds elapsed, finished iteration 30\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.018457 seconds elapsed, finished iteration 31\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.049971 seconds elapsed, finished iteration 32\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.080091 seconds elapsed, finished iteration 33\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.117365 seconds elapsed, finished iteration 34\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.147223 seconds elapsed, finished iteration 35\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.174983 seconds elapsed, finished iteration 36\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.207388 seconds elapsed, finished iteration 37\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.237138 seconds elapsed, finished iteration 38\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.268567 seconds elapsed, finished iteration 39\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.301127 seconds elapsed, finished iteration 40\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.329827 seconds elapsed, finished iteration 41\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.354768 seconds elapsed, finished iteration 42\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.385975 seconds elapsed, finished iteration 43\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.423971 seconds elapsed, finished iteration 44\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.451452 seconds elapsed, finished iteration 45\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.481506 seconds elapsed, finished iteration 46\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.508107 seconds elapsed, finished iteration 47\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.537386 seconds elapsed, finished iteration 48\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.569723 seconds elapsed, finished iteration 49\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.601177 seconds elapsed, finished iteration 50\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.626409 seconds elapsed, finished iteration 51\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.651066 seconds elapsed, finished iteration 52\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.676739 seconds elapsed, finished iteration 53\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 1.712133 seconds elapsed, finished iteration 54\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.738571 seconds elapsed, finished iteration 55\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.762809 seconds elapsed, finished iteration 56\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.794368 seconds elapsed, finished iteration 57\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.819027 seconds elapsed, finished iteration 58\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=11\n",
      "[LightGBM] [Info] 1.841216 seconds elapsed, finished iteration 59\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.863125 seconds elapsed, finished iteration 60\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 1.894466 seconds elapsed, finished iteration 61\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.913888 seconds elapsed, finished iteration 62\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 1.942780 seconds elapsed, finished iteration 63\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 1.963826 seconds elapsed, finished iteration 64\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=7\n",
      "[LightGBM] [Info] 1.989733 seconds elapsed, finished iteration 65\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=9\n",
      "[LightGBM] [Info] 2.016916 seconds elapsed, finished iteration 66\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 2.042313 seconds elapsed, finished iteration 67\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=10\n",
      "[LightGBM] [Info] 2.064218 seconds elapsed, finished iteration 68\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=8\n",
      "[LightGBM] [Info] 2.092192 seconds elapsed, finished iteration 69\n",
      "[LightGBM] [Info] Trained a tree with leaves=15 and max_depth=6\n",
      "[LightGBM] [Info] 2.114324 seconds elapsed, finished iteration 70\n",
      "[LightGBM] [Info] Finished training\n",
      "[LightGBM] [Info] Finished loading parameters\n",
      "[LightGBM] [Info] Finished loading 71 models\n",
      "[LightGBM] [Info] Finished initializing prediction\n",
      "[LightGBM] [Info] Finished prediction\n"
     ]
    }
   ],
   "source": [
    "clf = GBMClassifier(\n",
    "        exec_path=exec_path,\n",
    "        min_data_in_leaf = 100,\n",
    "       # is_unbalance = True,\n",
    "        num_iterations = 70,\n",
    "        bagging_fraction = 1,\n",
    "        bagging_freq = 10,\n",
    "        num_leaves = 15,\n",
    "        learning_rate = 0.1,\n",
    "        metric = 'auc',\n",
    "        feature_fraction = 0.8,\n",
    "    )\n",
    "\n",
    "r = cv(clf, df_train[feat_cols].values, df_train[label].values, folds = 5, metrics = 'roc_auc,pr_auc', predict = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60927360641101302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(y_score = r[1], y_true = df_train[label].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['pred'] = r[1]\n",
    "df_train['sample'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o252.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 4 times, most recent failure: Lost task 0.3 in stage 8.0 (TID 11, m1-hadoop-wk02t.tcsbank.ru): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 9.6 GB of 9.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply$mcI$sp(DataFrame.scala:1778)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply(DataFrame.scala:1778)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply(DataFrame.scala:1778)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:2125)\n\tat org.apache.spark.sql.DataFrame.collectToPython(DataFrame.scala:1777)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-431fd1692d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m       \u001b[0mhc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select * from user_kposminin.cred_app_sc_4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(call_ymd > \"2016-06-01\") or (default_flg is Null)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         .map(lambda r: \n\u001b[0m\u001b[0;32m      5\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             )\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mtoPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \"\"\"\n\u001b[0;32m   1377\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \u001b[1;31m##########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \"\"\"\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/apache/spark-1.6.0-bin-hadoop2.6/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o252.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 4 times, most recent failure: Lost task 0.3 in stage 8.0 (TID 11, m1-hadoop-wk02t.tcsbank.ru): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 9.6 GB of 9.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply$mcI$sp(DataFrame.scala:1778)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply(DataFrame.scala:1778)\n\tat org.apache.spark.sql.DataFrame$$anonfun$collectToPython$1.apply(DataFrame.scala:1778)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:2125)\n\tat org.apache.spark.sql.DataFrame.collectToPython(DataFrame.scala:1777)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "df_all = (\n",
    "      hc.sql('select * from user_kposminin.cred_app_sc_4')\n",
    "        .filter('(call_ymd > \"2016-06-01\") or (default_flg is Null)')\n",
    "        .map(lambda r: \n",
    "                list(r[:9]) + (r[9] if r[9] else []) + list(r[10:-2])  + (r[-2] if r[-2] else []) + (r[-1] if r[-1] else [])\n",
    "            )\n",
    "        .toDF()\n",
    "        .toPandas()\n",
    "    )\n",
    "df_all.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_all = df_train.append(df_test, ignore_index= True)\n",
    "df_all.shape,df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранить в Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hc.registerDataFrameAsTable(hc.createDataFrame(df_all), 'df_all')\n",
    "hc.sql('drop table if exists user_kposminin.default_predict_result')\n",
    "hc.sql('create table user_kposminin.default_predict_result as select * from df_all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Почему-то спарк неограниченно долго работает, но по факту таблица записывается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тематическое моделирование BigARTM (еще не доделано)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "-- Статистика урлфрагментов на обучающей выборке\n",
    "create table user_kposminin.cred_app_urlfr_stat as \n",
    "select\n",
    "  urlfr,\n",
    "  count(distinct phone_mobile,call_ymd) as visitors_cnt\n",
    "from\n",
    "  user_kposminin.cred_app_visits\n",
    "  where call_ymd < '2017-06-01'\n",
    "group by urlfr\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "-- Формирование данных для BigARTM в задача cred_scoring\n",
    "create table user_kposminin.cred_app_features_4_thematic_modelling as\n",
    "select\n",
    "  phone_mobile, \n",
    "  call_ymd, \n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',hits))) as feat_hits,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',cnt))) as feat_cnt,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',1))) as feat_1,\n",
    "  concat_ws(' ',collect_list(concat(urlfr,':',ymd_cnt))) as feat_ymd,\n",
    "  sum(hits) as hits,\n",
    "  sum(cnt) as cnt,\n",
    "  max(ymd_cnt) as max_ymd_cnt\n",
    "  \n",
    "from\n",
    "  (select \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    max(default_flg) as default_flg,\n",
    "    v.urlfr,\n",
    "    count(*) as cnt,\n",
    "    count(distinct ymd) as ymd_cnt,\n",
    "    sum(cnt) as hits\n",
    "  from user_kposminin.cred_app_visits v\n",
    "  left join user_kposminin.cred_app_urlfr_stat st on st.urlfr = v.urlfr\n",
    "  where coalesce(st.visitors_cnt,1000) > 300\n",
    "  group by \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    v.urlfr\n",
    "  order by \n",
    "    phone_mobile, \n",
    "    call_ymd, \n",
    "    v.urlfr\n",
    "  ) a  \n",
    "group by \n",
    "  phone_mobile, \n",
    "  call_ymd\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
