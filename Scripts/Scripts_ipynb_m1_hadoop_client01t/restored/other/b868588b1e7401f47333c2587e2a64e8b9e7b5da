{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "sc.stop()\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"32g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "#sc.setCheckpointDir('/user/kposminin/checkpointdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def repart(filename):\n",
    "    starttime = datetime.datetime.now()\n",
    "    sc.textFile(filename).repartition(32*8).saveAsTextFile('.'.join(filename.split('.')[:-1]))\n",
    "    print('End. Time of work {0}.'.format(datetime.datetime.now() - starttime))\n",
    "#repart(\"/user/kposminin/la_app_20160817_1.txt\")\n",
    "#repart(\"/user/kposminin/la_app_20160818_1.txt\")\n",
    "#repart(\"/user/kposminin/la_app_20160824_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(table):\n",
    "    si = 15 #score start index\n",
    "    def top_avg_score(slist): \n",
    "        return [sum(slist[:i])/i for i in [2,3,4,5,7,10]]\n",
    "    return [r + top_avg_score(r[si:si+11]) for r in table] \n",
    "\n",
    "def add_feature_rdd(row):\n",
    "    si = 15 #score start index\n",
    "    def top_avg_score(slist): \n",
    "        return [sum(slist[:i])/i for i in [2,3,4,5,7,10]]\n",
    "    r = row\n",
    "    return r + top_avg_score(r[si:si+11])\n",
    "    \n",
    "    \n",
    "# Load and parse the data file.\n",
    "# Load and parse the data file.\n",
    "train = sc.textFile(\"/user/kposminin/la_20160817_3.txt\") \\\n",
    "  .filter(lambda s: (s[0] == '1') or (hash(s) % 500 == 0)) \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \\\n",
    "  .collect()\n",
    "\n",
    "test = sc.textFile(\"/user/kposminin/la_20160824_3.txt\") \\\n",
    "  .filter(lambda s: (s[0] == '1') or (hash(s) % 500 == 11)) \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \\\n",
    "  .collect()\n",
    "\n",
    "test_rdd = sc.textFile(\"/user/kposminin/la_20160824_3.txt\") \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \n",
    "\n",
    "test_rdd2 = sc.textFile(\"/user/kposminin/la_20160818_3.txt\") \\\n",
    "  .map(lambda r:r.split('\\t')) \\\n",
    "  .map(lambda r:[int(e) for e in r]) \\\n",
    "  .filter(lambda r: len(r) == 30) \\\n",
    "  .map(add_feature_rdd) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = '''label, smax ,savg ,ssum ,smedian ,sstd ,cntrepeat ,cntuniq \n",
    ",duration ,has_scores ,mobile ,emailru ,vkru ,okru ,social_other , s1 ,s2 ,s3 ,s4 ,s5 ,s6 ,s7 ,s8 ,s9 ,s10 , \n",
    "sm1 ,sm2 ,sm3 ,sm4 ,sm5, avg2, avg3,avg4,avg5,avg7,avg10'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aucroc_smax = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    "    )\n",
    "print('Max score  AUCROC on sampled test data {0}'.format(aucroc_smax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(test_rdd.map(lambda r: (float(r[1]),float(r[0]))))\n",
    "print('Full test AUC ROC {0}'.format(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(test_rdd2.map(lambda r: (float(r[1]),float(r[0]))))\n",
    "print('Full test 20160818 AUC ROC {0}'.format(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def birth_coinc_prob(n,k):\n",
    "    return 1. - reduce(lambda x,y:x*y, [1-i*1./n for i in range(1,k)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9353043348654984"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birth_coinc_prob(250000000, 37000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4756953076625502"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Варьируем размер семплирования  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9721 ['test on 9721-model', 0.96776222371414]\n",
      "18259 ['test on 18259-model', 0.96886831765121251]\n",
      "34628 ['test on 34628-model', 0.96721683409948667]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-dc2aa319c368>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     modelGBT[s] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2000, learning_rate=0.04,\n\u001b[1;32m----> 9\u001b[1;33m        max_depth=3, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n\u001b[0m\u001b[0;32m     10\u001b[0m     AUCROC.append(['test on {0}-model'.format(s),sklearn.metrics.roc_auc_score(\n\u001b[0;32m     11\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m--> 980\u001b[1;33m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[0;32m    981\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1039\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                                      random_state)\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 766\u001b[1;33m                      check_input=False)\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    302\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "modelGBT = {}\n",
    "AUCROC=[]\n",
    "\n",
    "for f in [40,20,10,5]:\n",
    "    train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*f) == 0]\n",
    "    s = len(train1)\n",
    "    modelGBT[s] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=2000, learning_rate=0.04,\n",
    "       max_depth=3, random_state=0).fit(X = [e[1:] for e in train1], y = [e[0] for e in train1])\n",
    "    AUCROC.append(['test on {0}-model'.format(s),sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in test])]\n",
    "    )])\n",
    "    #AUCROC.append(['train '+ str(s), sklearn.metrics.roc_auc_score(\n",
    "    #    y_true = [e[0] for e in train1], \n",
    "    #    y_score = [r[1] for r in modelGBT[s].predict_proba([e[1:] for e in train1])]\n",
    "    #)])    \n",
    "    print('{0} {1}'.format(s,AUCROC[-1]))\n",
    "\n",
    "AUCROC.append(['smax '+ str(s), sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-d4901fdcc5b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.985\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m aucroc = sklearn.metrics.roc_auc_score(\n\u001b[0;32m      4\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m                 )\n\u001b[0;32m   1038\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         epsilon)\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "m = sklearn.linear_model.LogisticRegression(penalty='l1', class_weight = {0:0.015,1:0.985}) \\\n",
    "    .fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "aucroc = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in m.predict_proba([e[1:] for e in test])]\n",
    "    )\n",
    "print(aucroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('AUCROC score from sample number:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC.items())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelGBT[9721].features_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUCROC score from sample number:\\n' + '\\n'.join(['{0} {1:.5f}'.format(*e) for e in AUCROC])) #800 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1 = [r for r in train if (r[0] == 1) or int(np.random.rand()*5) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC_full_smax 0.851776495921\n"
     ]
    }
   ],
   "source": [
    "res_full = test_rdd2.map(lambda r:(r[0],int(10**4 * modelGBT[77856].predict_proba(r[1:])[0][1]),int(10**4 * modelGBT[5042].predict_proba(r[1:])[0][1]),r[1])).collect()\n",
    "AUCROC['full_smax2'] = sklearn.metrics.roc_auc_score(y_true = [e[0] for e in res_full], y_score = [e[3] for e in res_full])\n",
    "print('AUCROC_full_smax {0}'.format(AUCROC['full_smax2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC_full_GBT1 0.978765751101\n"
     ]
    }
   ],
   "source": [
    "AUCROC['full_GBT12'] = sklearn.metrics.roc_auc_score(y_true = [e[0] for e in res_full], y_score = [e[1] for e in res_full])\n",
    "print('AUCROC_full_GBT1 {0}'.format(AUCROC['full_GBT12']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC_full_GBT2 0.972477343875\n"
     ]
    }
   ],
   "source": [
    "AUCROC['full_GBT22'] = sklearn.metrics.roc_auc_score(y_true = [e[0] for e in res_full], y_score = [e[2] for e in res_full])\n",
    "print('AUCROC_full_GBT2 {0}'.format(AUCROC['full_GBT22']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC score:\n",
      "5042 0.99000\n",
      "8791 0.99193\n",
      "16592 0.98962\n",
      "39714 0.98899\n",
      "77856 0.98214\n",
      "full_GBT1 0.98154\n",
      "full_GBT12 0.97877\n",
      "full_GBT2 0.99185\n",
      "full_GBT22 0.97248\n",
      "full_smax 0.85926\n",
      "full_smax2 0.85178\n",
      "smax 16592 0.81586\n",
      "smax 39714 0.81594\n",
      "smax 5042 0.81850\n",
      "smax 77856 0.81560\n",
      "smax 8791 0.81510\n",
      "test_full on 16592-model 0.98962\n",
      "test_full on 39714-model 0.98893\n",
      "test_full on 5042-model 0.99012\n",
      "test_full on 77856-model 0.98214\n",
      "test_full on 8791-model 0.99186\n",
      "train 16592 1.00000\n",
      "train 39714 1.00000\n",
      "train 5042 1.00000\n",
      "train 77856 1.00000\n",
      "train 8791 1.00000\n",
      "train smax 16592 0.85259\n",
      "train smax 39714 0.85281\n",
      "train smax 5042 0.85198\n",
      "train smax 77856 0.85299\n",
      "train smax 8791 0.85165\n"
     ]
    }
   ],
   "source": [
    "#open('res_aucroc.txt','w').write(str(AUCROC))\n",
    "columns = '''smax ,savg ,ssum ,smedian ,sstd ,cntrepeat ,cntuniq \n",
    ",duration ,mobile ,emailru ,vkru ,okru ,social_other , s1 ,s2 ,s3 ,s4 ,s5 ,s6 ,s7 ,s8 ,s9 ,s10 , \n",
    "sm1 ,sm2 ,sm3 ,sm4 ,sm5'''.replace(' ','').replace('\\n','').split(',')\n",
    "#sorted(zip(modelGBT[5042].feature_importances_,columns))\n",
    "print('AUCROC score:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC.items())]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохраняем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(modelGBT[5042],open('la_modelGBT5042.pckl','w'))\n",
    "#pickle.dump(modelGBT[77856],open('la_modelGBT77856.pckl','w'))\n",
    "#m = pickle.load(open('la_modelGBT5042.pckl','r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_table_to_file(table, filename):\n",
    "    f = open(filename,'w+')\n",
    "    #f.write('label,' + ','.join(columns)+'\\n')\n",
    "    f.write('\\n'.join([','.join([str(e) for e in r]) for r in table]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = '''smax ,savg ,ssum ,smedian ,sstd ,cntrepeat ,cntuniq \n",
    ",duration , has_scores, mobile ,emailru ,vkru ,okru ,social_other , s1 ,s2 ,s3 ,s4 ,s5 ,s6 ,s7 ,s8 ,s9 ,s10 , \n",
    "sm1 ,sm2 ,sm3 ,sm4 ,sm5'''.replace(' ','').replace('\\n','').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346389, 73114)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = train\n",
    "train = [r for r in train if (r[0] == 1) or int(np.random.rand() * 5) == 0]\n",
    "test1 = [r for r in test if (r[0] == 1) or int(np.random.rand()*5) == 0]\n",
    "len(train1),len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = add_features(train)\n",
    "test1 = test\n",
    "test = add_features([r for r in test if (r[0] == 1) or int(np.random.rand()*5) == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Варьируем количество деревьев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0.765186460161\n",
      "50\n",
      "0.812268008099\n",
      "80\n",
      "0.821962476989\n",
      "100\n",
      "0.82124470712\n",
      "200\n",
      "0.814525853692\n",
      "500\n",
      "0.810490713885\n",
      "1000\n",
      "0.807774298353\n"
     ]
    }
   ],
   "source": [
    "# Train a GradientBoostedTrees model.\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "modelGBT = {}\n",
    "AUCROC1={}\n",
    "for n in [30,50,80,100,200,500,1000]:\n",
    "    print(n)\n",
    "    modelGBT[n] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=n, learning_rate=0.1,\n",
    "       max_depth=2, random_state=0).fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "    AUCROC1[n] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[n].predict_proba([e[1:] for e in test])]\n",
    "    )\n",
    "    AUCROC1['train '+str(n)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [r[1] for r in modelGBT[n].predict_proba([e[1:] for e in train])]\n",
    "    )\n",
    "    print(AUCROC1[n])\n",
    "AUCROC1['smax'] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [e[1] for e in test]\n",
    ")\n",
    "AUCROC1['train smax'] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [e[1] for e in train]\n",
    ")\n",
    "#print(AUCROC)\n",
    "# Evaluate model on test instances and compute test error\n",
    "##predictions = model.predict(test.map(lambda x: x.features))\n",
    "#predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC test sample score from GBT trees number:\n",
      "30 0.79558\n",
      "50 0.80590\n",
      "80 0.78700\n",
      "100 0.79087\n",
      "200 0.78997\n",
      "300 0.78981\n",
      "500 0.78737\n",
      "800 0.78817\n",
      "1200 0.77926\n",
      "smax 0.85145\n",
      "train 100 0.99360\n",
      "train 1200 1.00000\n",
      "train 200 0.99777\n",
      "train 30 0.98293\n",
      "train 300 0.99922\n",
      "train 50 0.98742\n",
      "train 500 0.99983\n",
      "train 80 0.99125\n",
      "train 800 1.00000\n",
      "train smax 0.93210\n"
     ]
    }
   ],
   "source": [
    "print('AUCROC test sample score from GBT trees number:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC1.items())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Если брать более 100 деревьев, то происходит переобучение на выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Вариация глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797715977001\n"
     ]
    }
   ],
   "source": [
    "modelGBT = sklearn.ensemble.GradientBoostingClassifier(n_estimators=50, learning_rate=0.1,\n",
    "       max_depth=6, random_state=0).fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "print(sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT.predict_proba([e[1:] for e in test])]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "modelGBT = {}\n",
    "AUCROC1 = {'smax':AUCROC1['smax'], 'train smax':AUCROC1['train smax']}\n",
    "for m in [1,2,3,4,6]:    \n",
    "    modelGBT[m] = sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "       max_depth=m, random_state=0).fit(X = [e[1:] for e in train], y = [e[0] for e in train])\n",
    "    AUCROC1[m] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in test], \n",
    "        y_score = [r[1] for r in modelGBT[m].predict_proba([e[1:] for e in test])]\n",
    "    )\n",
    "    AUCROC1['train '+str(m)] = sklearn.metrics.roc_auc_score(\n",
    "        y_true = [e[0] for e in train], \n",
    "        y_score = [r[1] for r in modelGBT[m].predict_proba([e[1:] for e in train])]\n",
    "    )\n",
    "    print('{0} {1}'.format(m,AUCROC1[m]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC test sample score from GBT tree depth:\n",
      "1 0.82124\n",
      "2 0.81431\n",
      "3 0.80892\n",
      "4 0.80037\n",
      "6 0.78834\n",
      "smax 0.85147\n",
      "train 1 0.97495\n",
      "train 2 0.97961\n",
      "train 3 0.98310\n",
      "train 4 0.98666\n",
      "train 6 0.99375\n",
      "train smax 0.93210\n"
     ]
    }
   ],
   "source": [
    "print('AUCROC test sample score from GBT tree depth:\\n' + '\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(AUCROC1.items())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### До глубины 7 разница несущественна, далее начинается переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUCROC 0.913370268124\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res1 = test_rdd.map(lambda r:(float(r[0]),modelGBT.predict_proba(r[1:])[0][1])).collect()\n",
    "ar = sklearn.metrics.roc_auc_score(y_true = [e[0] for e in res1], y_score = [e[1] for e in res1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open('test.txt','w').write(str(AUCROC)+','+str(ar)+'\\n'+str(sorted(zip(columns,modelGBT.feature_importances_), key = lambda r:-r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())\n",
    "print('AUCROC: {0}'.format(sklearn.metrics.roc_auc_score(\n",
    "            labelsAndPredictions.map(lambda r:r[0]).collect(),\n",
    "            labelsAndPredictions.map(lambda r:r[1]).collect()\n",
    ")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUCROC smax: {0}'.format(sklearn.metrics.roc_auc_score(\n",
    "            test.map(lambda lp: lp.label).collect(),\n",
    "            test.map(lambda lp: lp.features[0]).collect()\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax 0.13844\n",
      "s1 0.11298\n",
      "sm1 0.10010\n",
      "s2 0.09305\n",
      "ssum 0.07244\n",
      "savg 0.06488\n",
      "duration 0.06053\n",
      "sstd 0.04256\n",
      "s3 0.04210\n",
      "s4 0.03787\n",
      "s5 0.03752\n",
      "smedian 0.02722\n",
      "cntrepeat 0.02636\n",
      "s10 0.02193\n",
      "sm5 0.02015\n",
      "cntuniq 0.01583\n",
      "s6 0.01453\n",
      "s8 0.01242\n",
      "sm4 0.01025\n",
      "sm2 0.00985\n",
      "s7 0.00788\n",
      "vkru 0.00674\n",
      "sm3 0.00650\n",
      "s9 0.00633\n",
      "emailru 0.00529\n",
      "mobile 0.00464\n",
      "okru 0.00156\n",
      "social_other 0.00002\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(['{0} {1:.5f}'.format(k,v) for (k,v) in sorted(zip(columns,modelGBT[5].feature_importances_), key = lambda r:-r[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
