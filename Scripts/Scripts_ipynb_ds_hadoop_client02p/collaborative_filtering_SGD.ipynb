{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "#import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import datetime\n",
    "#from pyspark.mllib.regression import LabeledPoint\n",
    "#from pyspark.mllib.feature import HashingTF\n",
    "#from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "#import scipy.sparse as sps\n",
    "#from pyspark.mllib.linalg import Vectors\n",
    "#import sklearn\n",
    "import itertools\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "#from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 32).set(\"spark.driver.maxResultSize\", \"16g\")\n",
    "sc = SparkContext()\n",
    "hc = HiveContext(sc)\n",
    "sc.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD модель интернет-логов. Выделение тем. ##\n",
    "Есть таблица интернет-логов  $m_{ij}$, каждая строка отвечает одному интернет-пользователю, каждый столбец - фрагменту урла. $m_{ij}=1$, если посетитель $i$ посетил фрагмент урла $j$ в рамках рассматриваемой сессии, иначе $m_{ij}=0$.\n",
    "\n",
    "Выделим темы - группировки урлов и пользователей. Для этого воспользуемся модификацией SVD разложения. \n",
    "\n",
    "Зафиксируем количество тем $K$. Для каждого пользователя сформируем вектор длины $K$, отражающий степень близости темы к пользователю. Получаем матрицу $X_{ik}$. Индекс $i$ отвечает пользователю, $k$ отвечает теме. \n",
    "\n",
    "Аналогично сформируем вектор  длины $K$ для каждого фрагмента урла. Получаем матрицу $Y_{kj}$. $k$ отвечает теме, $j$ отвечает фрагменту урла.\n",
    "\n",
    "Далее для каждого пользователя $i$ введем число $a_i$, которое в целом характеризует его интернет-активность.\n",
    "\n",
    "Аналогично, элементы вектора $b_j$ отражают популярность урла $j$.\n",
    "\n",
    "Параметр $\\mu$ есть усредняющий скаляр по всей выборке.\n",
    "\n",
    "Далее интерес пользователя  $i$ к фрагменту урла $j$ будем моделировать величиной $s_{ij} = \\mu + a_i + b_j + \\sum_k X_{ik} \\cdot Y_{kj}$.\n",
    "\n",
    "Для перевода этой величины в вероятность, воспользуемся логистической функцией: \n",
    "$\\hat{m}_{ij} = 1/(1+e^{-s_{ij}})$. \n",
    "\n",
    "Таким образом, построенная величина $\\hat{m}_{ij}$ есть  модельная оценка вероятности посещения пользователем $i$ фрагмента урла $j$.\n",
    "\n",
    "Введем функцию ошибки $L = \\sum_{ij} L_{ij} $,\n",
    "$$L_{ij} = -m_{ij} \\cdot \\ln(\\hat{m}_{ij}) - (1 - m_{ij}) \\cdot \\ln(1 - \\hat{m}_{ij}) + \\lambda_{0} \\cdot \\mu + \\lambda_{1}\\cdot (a_i^2 + b_j^2) + \\lambda_{2} \\cdot \\sum_k(X_{ik}^2 + Y_{kj}^2)$$.\n",
    "\n",
    "Для обучения будем использовать стохастический градиентный спуск (его модификацию Adadelta http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#AdaDelta_8211_implementation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-23a8e9e4a8fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmake_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Param selection\n",
    "query = '''\n",
    "select id_num,urlfr_num from \n",
    "(select id_num,urlfr_num,count(*) over (partition by id_num) as uf_cnt,count(*) over (partition by urlfr_num) as id_cnt from user_kposminin.visits_enum_20160412 \n",
    "where id_num<40000 ) a\n",
    "where id_cnt > 10 and uf_cnt > 9\n",
    "'''\n",
    "\n",
    "# where uf_cnt > 9 and id_cnt > 500\n",
    "\n",
    "\n",
    "K = 20\n",
    "id_cnt = 10000\n",
    "urlfr_cnt = 3000000\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "#lmbd = np.array([0.01, 0.01, 0.01])\n",
    "\n",
    "#step = np.array([0.001, 0.005, 0.01])\n",
    "\n",
    "param_grid = []\n",
    "\n",
    " #   [[0.00001, 0.0001, 0.0001],[0.01, 0.05, 0.01]],\n",
    "for base_step in np.exp(np.arange(-4,0,2)):\n",
    "    for base_lmbd in np.exp(np.arange(-14,-8,2)):\n",
    "        for var_step in np.array([[0.1,1,0.1],[0.01,1,10]]):\n",
    "            for var_lmbd in np.array([[0.01,0.1,1],[1,0.1,0.01]]):\n",
    "                param_grid.append([var_step * base_step,var_lmbd * base_lmbd])\n",
    "\n",
    "lmbd_corr = np.exp(np.arange(-3,3,6./K))\n",
    "\n",
    "'''\n",
    "# Load and parse the data\n",
    "sampled_data = hc.sql(query) \\\n",
    "            .collect()\n",
    "print('Sampled data consists of {} rows, {} id and {} uf.'.format(len(sampled_data),len(set([e[0] for e in sampled_data])),len(set([e[1] for e in sampled_data]))))\n",
    "\n",
    "train,test = [], []\n",
    "for r in sampled_data:\n",
    "    if(np.random.rand() < 0.1):\n",
    "        test.append(r)\n",
    "    else:\n",
    "        train.append(r)\n",
    "'''  \n",
    "#  \n",
    "# prediction is m^hat_{ij} = 1/(1+exp(-s_{ij})) where s_{ij} = mu + a[i] + b[j] + sum_k (X[i,k] * Y[k,j])\n",
    "# error function is L_{ij} = -m_{ij}*ln(m^hat_{ij}) - (1 - m_{ij})*ln(1 - m^hat_{ij}) + \n",
    "#                            lmbd[0] * mu + lmbd[1]*(a_i^2 + b_j^2) + lmbd[2]*sum_k(X_{ik}^2 + Y_{kj}^2)\n",
    "f = open('data/collab_filter_SGD_param_tuning.csv','a+')\n",
    "f.write('\\n\\n New calc at {}'.format(datetime.datetime.now()))\n",
    "stat = []\n",
    "prev_id = -1\n",
    "uf_visited= []\n",
    "neg_sig_share = 2\n",
    "rho = 0.9\n",
    "eps = 1e-6\n",
    "errors = []\n",
    "err_thres = 0.005\n",
    "\n",
    "for step,lmbd in  [[[0.0135,0.1353,0.0135],[1e-04,1e-03,1e-02]]]:\n",
    "\n",
    "    #Init matrices\n",
    "    mu = np.random.rand(1) - 0.5 -6 # One-element array to be able to update inside a procedure\n",
    "    a = np.random.rand(id_cnt) - 0.5\n",
    "    b = np.random.rand(urlfr_cnt) - 0.5\n",
    "    X = np.random.rand(id_cnt, K) - 0.5\n",
    "    Y = np.random.rand(K,urlfr_cnt) - 0.5\n",
    "\n",
    "    def make_step(i, j, v):\n",
    "        s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "        pred = 1./(1+np.exp(-s))\n",
    "        err = v - pred # r[2] - pred\n",
    "        grad_mu = -err + lmbd[0] * mu\n",
    "        grad_ai = -err + lmbd[1] * a[i]\n",
    "        grad_bj = -err + lmbd[1] * b[j]\n",
    "        grad_xi = -err * Y[:,j] + lmbd[2] * X[i,:] * lmbd_corr\n",
    "        grad_yj = -err * X[i,:] + lmbd[2] * Y[:,j] * lmbd_corr\n",
    "        \n",
    "        # TODO Implement Adadelta SGD version. \n",
    "        #http://int8.io/comparison-of-optimization-techniques-stochastic-gradient-descent-momentum-adagrad-and-adadelta/#AdaDelta_8211_implementation\n",
    "        # \n",
    "     \n",
    "        mu[0] += - grad_mu[0] * step[0]\n",
    "        a[i]  += - grad_ai * step[1]\n",
    "        b[j]  += - grad_bj * step[1]\n",
    "        X[i,:] = X[i,:] - grad_xi * step[2]\n",
    "        Y[:,j] = Y[:,j] - grad_yj * step[2]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for r in train:\n",
    "            i,j = r[:2]\n",
    "            make_step(i, j, 1)\n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(train) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not train[(ni + k) % len(train)][1] in uf_visited):                        \n",
    "                        make_step(prev_id, train[(ni + k) % len(train)][1],0)\n",
    "                        neg += 1\n",
    "                    k +=1 \n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        \n",
    "        #calc err\n",
    "        err1_p ,err2_p, err1_n, err2_n = 0, 0, 0, 0\n",
    "        for r in test:\n",
    "            i,j = r[:2]\n",
    "            s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "            pred = 1/(1+np.exp(-s))\n",
    "            err1_p += - 1 * np.log(pred) # r[2] - pred\n",
    "            err2_p += - 1 * np.log(pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i] ** 2 + b[j] ** 2) + lmbd[2] * (X[i,:].dot(X[i,:]*lmbd_corr) + Y[:,j].dot(Y[:,j]*lmbd_corr))\n",
    "            \n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(test) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not test[(ni + k) % len(test)][1] in uf_visited): \n",
    "                        i1, j1 = prev_id, train[(ni + k) % len(train)][1]\n",
    "                        s = mu[0] + a[i1] + b[j1] + X[i1,:].dot(Y[:,j1])\n",
    "                        pred = 1/(1+np.exp(-s))\n",
    "                        err1_n += - 1 * np.log(1 - pred) # r[2] - pred\n",
    "                        err2_n += - 1 * np.log(1 - pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i1] ** 2 + b[j1] ** 2) + lmbd[2] * (X[i1,:].dot(X[i1,:]) + Y[:,j1].dot(Y[:,j1]))                        \n",
    "                        neg += 1\n",
    "                    k +=1 \n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        err1_t = (err1_p + err1_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err2_t = (err2_p + err2_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err1_p /= float(len(test))\n",
    "        err2_p /= float(len(test))\n",
    "        err1_n /= len(test) * neg_sig_share\n",
    "        err2_n /= len(test) * neg_sig_share        \n",
    "        errors.append(err1_t)\n",
    "        stat=('{} ' * 9).format(step,lmbd,epoch,err1_t, err1_p,err1_n,err2_t, err2_p,err2_n)\n",
    "        f.write(stat + '\\n')\n",
    "        print(stat)\n",
    "        if((len(errors)>6) & (sum(errors[-3:])/3 > sum(errors[-6:-3])/3 - err_thres)): # too fast.\n",
    "            step = [s * 0.7 for s in step]\n",
    "        if((len(errors)>13) & (abs(sum(errors[-3:])/3 - sum(errors[-13:-3])/10) < 1e-4)): # too slow.\n",
    "            step = [s / 0.6 for s in step]\n",
    "        \n",
    "        \n",
    "print('Finish. Work time {}.'.format(datetime.datetime.now()- start_time))\n",
    "f.write('\\nFinish at {}. Work time {}.\\n\\n\\n'.format(datetime.datetime.now(),datetime.datetime.now() - start_time))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d25550cccd46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;31m# One-element array to be able to update inside a procedure\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlfr_cnt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murlfr_cnt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlmbd_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "K = 500\n",
    "#id_cnt = 10000\n",
    "urlfr_cnt = 1701067 # hc.sql('select max(urlfr_num) from user_kposminin.visits_enum_20160412').collect()[0][0] + 1\n",
    "\n",
    "\n",
    "\n",
    "err = []\n",
    "err_thres = 0.005\n",
    "step, lmbd = [0.0135,0.1353,0.0135], [1e-04,1e-03,1e-02]\n",
    "f = open('data/collab_filter_SGD_calc.csv','a+')\n",
    "af = open('data/collab_filter_SGD_a_vec.csv','w')\n",
    "Xf = open('data/collab_filter_SGD_X_matr.csv','w')\n",
    "full_train_epochs = 2\n",
    "\n",
    "mu = np.random.rand(1) - 0.5 - 2 # One-element array to be able to update inside a procedure\n",
    "b = np.random.rand(urlfr_cnt) - 0.5\n",
    "Y = np.random.rand(K,urlfr_cnt) - 0.5\n",
    "\n",
    "lmbd_corr = np.exp(np.arange(-3,3,6./K))\n",
    "\n",
    "query1 = '''\n",
    "select id_num,urlfr_num from user_kposminin.visits_enum_20160412 \n",
    "where id_num between #low and #high\n",
    "'''\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "for btc in range(180*10**6/batch_size):\n",
    "\n",
    "    # Load and parse the data\n",
    "    sampled_data = hc.sql(query1.replace('#low',str(btc*batch_size)).replace('#high',str((btc + 1) * batch_size - 1))) \\\n",
    "            .collect()\n",
    "    if(len(sampled_data) == 0): break\n",
    "    str2write = '{}. Num {}. Sampled data consists of {} rows, {} id and {} uf.\\n'.format(datetime.datetime.now(),btc, \n",
    "                                len(sampled_data),len(set([e[0] for e in sampled_data])), len(set([e[1] for e in sampled_data])))\n",
    "    print(str2write)\n",
    "    f.write(str2write)\n",
    "    id_start = btc*batch_size\n",
    "    \n",
    "    train,test = [], []\n",
    "    for r in sampled_data:\n",
    "        if(np.random.rand() < 0.1):\n",
    "            test.append(r)\n",
    "        else:\n",
    "            train.append(r)\n",
    "    id_cnt = batch_size\n",
    "    stat = []\n",
    "    prev_id = -1\n",
    "    uf_visited= []\n",
    "    neg_sig_share = 2\n",
    "\n",
    "    #Init matrices\n",
    "    a = np.random.rand(id_cnt) - 0.5\n",
    "    X = np.random.rand(id_cnt, K) - 0.5\n",
    "\n",
    "    def make_step(i, j, v):\n",
    "        s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "        pred = 1./(1+np.exp(-s))\n",
    "        err = v - pred # r[2] - pred\n",
    "        grad_mu = -err + lmbd[0] * mu\n",
    "        grad_ai = -err + lmbd[1] * a[i]\n",
    "        grad_bj = -err + lmbd[1] * b[j]\n",
    "        grad_xi = -err * Y[:,j] + lmbd[2] * X[i,:] * lmbd_corr\n",
    "        grad_yj = -err * X[i,:] + lmbd[2] * Y[:,j] * lmbd_corr\n",
    "        mu[0] += - grad_mu[0] * step[0]\n",
    "        a[i]  += - grad_ai * step[1]\n",
    "        b[j]  += - grad_bj * step[1]\n",
    "        X[i,:] = X[i,:] - grad_xi * step[2]\n",
    "        Y[:,j] = Y[:,j] - grad_yj * step[2]\n",
    "    \n",
    "    for epoch in range(full_train_epochs):\n",
    "        for r in train:\n",
    "            i,j = r[0] - id_start, r[1]\n",
    "            make_step(i, j, 1)\n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(train) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not train[(ni + k) % len(train)][1] in uf_visited):                        \n",
    "                        make_step(prev_id, train[(ni + k) % len(train)][1],0)\n",
    "                        neg += 1\n",
    "                    k +=1\n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        \n",
    "        #calc err\n",
    "        err1_p ,err2_p, err1_n, err2_n = 0, 0, 0, 0\n",
    "        for r in test:\n",
    "            i,j = r[0] - id_start, r[1]\n",
    "            s = mu[0] + a[i] + b[j] + X[i,:].dot(Y[:,j])\n",
    "            pred = 1/(1+np.exp(-s))\n",
    "            err1_p += - 1 * np.log(pred) # r[2] - pred\n",
    "            err2_p += - 1 * np.log(pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i] ** 2 + b[j] ** 2) + lmbd[2] * (X[i,:].dot(X[i,:]*lmbd_corr) + Y[:,j].dot(Y[:,j]*lmbd_corr))\n",
    "            \n",
    "            if i == prev_id:\n",
    "                uf_visited.append(j)\n",
    "            else:\n",
    "                # Add negative examples\n",
    "                ni = np.random.randint(len(test) - len(uf_visited))\n",
    "                neg, k = 0, 0\n",
    "                while(neg < int(len(uf_visited) * neg_sig_share)):\n",
    "                    if(not test[(ni + k) % len(test)][1] in uf_visited): \n",
    "                        i1, j1 = prev_id, train[(ni + k) % len(train)][1]\n",
    "                        s = mu[0] + a[i1] + b[j1] + X[i1,:].dot(Y[:,j1])\n",
    "                        pred = 1/(1+np.exp(-s))\n",
    "                        err1_n += - 1 * np.log(1 - pred) # r[2] - pred\n",
    "                        err2_n += - 1 * np.log(1 - pred) + lmbd[0] * mu[0] + lmbd[1] * (a[i] ** 2 + b[j] ** 2) + lmbd[2] * (X[i,:].dot(X[i,:]*lmbd_corr) + Y[:,j].dot(Y[:,j]*lmbd_corr))\n",
    "                        neg += 1\n",
    "                    k +=1 \n",
    "                prev_id = i\n",
    "                uf_visited = [j]\n",
    "        err1_t = (err1_p + err1_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err2_t = (err2_p + err2_n) / (len(test) * (neg_sig_share + 1))\n",
    "        err1_p /= float(len(test))\n",
    "        err2_p /= float(len(test))\n",
    "        err1_n /= len(test) * neg_sig_share\n",
    "        err2_n /= len(test) * neg_sig_share        \n",
    "        err.append(err1_t)\n",
    "        stat=('{} ' * 9).format(step,lmbd,epoch,err1_t, err1_p,err1_n,err2_t, err2_p,err2_n)\n",
    "        f.write(stat + '\\n')\n",
    "        print(stat)\n",
    "        if((len(err)>6) & (sum(err[-3:])/3 > sum(err[-6:-3])/3 - err_thres)): # too fast.\n",
    "            step = [s * 0.7 for s in step]\n",
    "        if((len(err)>13) & (abs(sum(err[-3:])/3 - sum(err[-13:-3])/10) < 1e-5)): # too slow.\n",
    "            step = [s / 0.6 for s in step]\n",
    "                    \n",
    "        for r in test:\n",
    "            i,j = r[0] - id_start, r[1]\n",
    "            make_step(i, j, 1)\n",
    "        \n",
    "        l = 0\n",
    "        for e in a:\n",
    "            af.write('{},{}\\n'.format(id_start + l,a[l]))\n",
    "            l+=1\n",
    "        l = 0\n",
    "        for e in X:\n",
    "            Xf.write('{},{}\\n'.format(id_start + l,','.join(str(z) for z in X[l])))\n",
    "            l+=1\n",
    "l=0            \n",
    "Yf = open('data/collab_filter_SGD_Y_matr.csv','w')\n",
    "for e in Y:\n",
    "    Yf.write('{},{}\\n'.format(l,','.join(str(z) for z in Y[l])))\n",
    "    l+=1\n",
    "l=0            \n",
    "bf = open('data/collab_filter_SGD_b_vec.csv','w')\n",
    "for e in b:\n",
    "    bf.write('{},{}\\n'.format(l,b[l]))\n",
    "    l+=1\n",
    "\n",
    "f.write('mu is {}'.format(mu))\n",
    "\n",
    "print('Finish. Work time {}.'.format(datetime.datetime.now()- start_time))\n",
    "f.write('\\nFinish at {}. Work time {}.\\n\\n\\n'.format(datetime.datetime.now(),datetime.datetime.now() - start_time))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
