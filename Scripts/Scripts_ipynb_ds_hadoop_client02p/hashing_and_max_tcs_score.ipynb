{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## max_score + Hashing trick for look-alike portal application completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k.p.osminin/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Config\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "#import re\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import datetime\n",
    "#from pyspark.mllib.regression import LabeledPoint\n",
    "#from pyspark.mllib.feature import HashingTF\n",
    "#from pyspark.mllib.classification import LogisticRegressionWithSGD, NaiveBayes, NaiveBayesModel\n",
    "#import scipy.sparse as sps\n",
    "#from pyspark.mllib.linalg import Vectors\n",
    "#import sklearn\n",
    "try:\n",
    "    sc.stop()\n",
    "except NameError: pass\n",
    "\n",
    "\n",
    "conf = SparkConf().set(\"spark.executor.instances\", 8).set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "hc = HiveContext(sc)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import re\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7468151\n",
      "7468151\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for r in open('/home/k.p.osminin/external_hdfs/ha_raw_lah_20161012.txt','r'):\n",
    "    e = r.strip('\\n').split(' ')[:3]\n",
    "    train.append([int(e[0]),int(e[1]), float(e[2])])\n",
    "        \n",
    "print(len(train))\n",
    "train_hash_pred = [float(e) for e in open('/home/k.p.osminin/external_hdfs/pred_20161012.txt','r')]\n",
    "print(len(train_hash_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data = [e[0]+[e[1]] for e in zip(train,train_hash_pred)],columns = ['label','first_day','tcs_maxs','hash_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix( df_train[['tcs_maxs','hash_score']], label=df_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':10, 'eta':1, 'gamma' : 0.5, 'silent':1, 'objective':'binary:logistic','eval_metric' : \"auc\",\n",
    "         'scale_pos_weight' : 1, 'num_round' : 10 }\n",
    "\n",
    "bst = xgb.train(param, dtrain)\n",
    "\n",
    "# make prediction\n",
    "df_train['xgboost_pred'] = bst.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC train: tcs_max_score 0.855961. ha_score 0.837702. xgboost(tcs_max,ha_sc) 0.877686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('{0} AUCROC train: tcs_max_score {1:.6f}. ha_score {2:.6f}. xgboost(tcs_max,ha_sc) {3:.6f}'.format(\n",
    "               'XGBoost',\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train.label, \n",
    "                  y_score = df_train.tcs_maxs\n",
    "                ),\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train.label, \n",
    "                  y_score = df_train.hash_score\n",
    "                ),                                              \n",
    "               sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train.label, \n",
    "                  y_score = df_train.xgboost_pred\n",
    "                ),                                              \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7476264\n",
      "7476264\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for r in open('/home/k.p.osminin/external_hdfs/ha_raw_lah_20161019.txt','r'):\n",
    "    e = r.strip('\\n').split(' ')[:3]\n",
    "    test.append([int(e[0]),int(e[1]), float(e[2])])\n",
    "        \n",
    "print(len(test))\n",
    "test_hash_pred = [float(e) for e in open('/home/k.p.osminin/external_hdfs/pred_20161019.txt','r')]\n",
    "print(len(test_hash_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data = [e[0]+[e[1]] for e in zip(test,test_hash_pred)],columns = ['label','first_day','tcs_maxs','hash_score'])\n",
    "df_test['xgboost_pred'] = bst.predict(xgb.DMatrix( df_test[['tcs_maxs','hash_score']], label=df_test.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUCROC test: tcs_max_score 0.852580. ha_score 0.827884. xgboost(tcs_max,ha_sc) 0.850725\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC test: tcs_max_score {1:.6f}. ha_score {2:.6f}. xgboost(tcs_max,ha_sc) {3:.6f}'.format(\n",
    "               'XGBoost',\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test.label, \n",
    "                  y_score = df_test.tcs_maxs\n",
    "                ),\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test.label, \n",
    "                  y_score = df_test.hash_score\n",
    "                ),                                              \n",
    "               sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test.label, \n",
    "                  y_score = df_test.xgboost_pred\n",
    "                ),                                              \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.loc[:,'tcs_maxs_bin'] = pd.cut(\n",
    "    df_train['tcs_maxs'], \n",
    "    bins = np.unique(df_train['tcs_maxs'].quantile(np.arange(0,1.05,0.05)).values), \n",
    "    labels  = False).values\n",
    "\n",
    "df_train.loc[:,'hash_score_bin'] = pd.cut(\n",
    "    df_train['hash_score'], \n",
    "    bins = np.unique(df_train['hash_score'].quantile(np.arange(0,1.05,0.05)).values), \n",
    "    labels  = False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hash_score_bin</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcs_maxs_bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81400.0</td>\n",
       "      <td>18786.0</td>\n",
       "      <td>272571.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>226599.0</td>\n",
       "      <td>222511.0</td>\n",
       "      <td>153802.0</td>\n",
       "      <td>13598.0</td>\n",
       "      <td>16543.0</td>\n",
       "      <td>91069.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>18864.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>6528.0</td>\n",
       "      <td>4452.0</td>\n",
       "      <td>10568.0</td>\n",
       "      <td>28820.0</td>\n",
       "      <td>317948.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>151569.0</td>\n",
       "      <td>129892.0</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>5377.0</td>\n",
       "      <td>44952.0</td>\n",
       "      <td>169633.0</td>\n",
       "      <td>127831.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>5015.0</td>\n",
       "      <td>2637.0</td>\n",
       "      <td>271746.0</td>\n",
       "      <td>119089.0</td>\n",
       "      <td>125960.0</td>\n",
       "      <td>105225.0</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>286.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>10654.0</td>\n",
       "      <td>179559.0</td>\n",
       "      <td>11670.0</td>\n",
       "      <td>10123.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>112.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>4416.0</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>17853.0</td>\n",
       "      <td>231335.0</td>\n",
       "      <td>18299.0</td>\n",
       "      <td>46657.0</td>\n",
       "      <td>32451.0</td>\n",
       "      <td>16225.0</td>\n",
       "      <td>5185.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>4324.0</td>\n",
       "      <td>10749.0</td>\n",
       "      <td>260123.0</td>\n",
       "      <td>17839.0</td>\n",
       "      <td>23478.0</td>\n",
       "      <td>37244.0</td>\n",
       "      <td>9561.0</td>\n",
       "      <td>6206.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>138.0</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>3394.0</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>9297.0</td>\n",
       "      <td>209182.0</td>\n",
       "      <td>23335.0</td>\n",
       "      <td>58336.0</td>\n",
       "      <td>24956.0</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>4713.0</td>\n",
       "      <td>3217.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>173.0</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>3133.0</td>\n",
       "      <td>3834.0</td>\n",
       "      <td>8039.0</td>\n",
       "      <td>151444.0</td>\n",
       "      <td>13780.0</td>\n",
       "      <td>38691.0</td>\n",
       "      <td>72404.0</td>\n",
       "      <td>72578.0</td>\n",
       "      <td>16247.0</td>\n",
       "      <td>5957.0</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>167.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>3622.0</td>\n",
       "      <td>8302.0</td>\n",
       "      <td>167976.0</td>\n",
       "      <td>16670.0</td>\n",
       "      <td>39724.0</td>\n",
       "      <td>35475.0</td>\n",
       "      <td>42077.0</td>\n",
       "      <td>30403.0</td>\n",
       "      <td>9903.0</td>\n",
       "      <td>5688.0</td>\n",
       "      <td>1894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>161.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>19949.0</td>\n",
       "      <td>153156.0</td>\n",
       "      <td>14354.0</td>\n",
       "      <td>38237.0</td>\n",
       "      <td>35045.0</td>\n",
       "      <td>43557.0</td>\n",
       "      <td>59543.0</td>\n",
       "      <td>56945.0</td>\n",
       "      <td>21841.0</td>\n",
       "      <td>7344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>105.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>2557.0</td>\n",
       "      <td>6014.0</td>\n",
       "      <td>58717.0</td>\n",
       "      <td>8225.0</td>\n",
       "      <td>18801.0</td>\n",
       "      <td>21462.0</td>\n",
       "      <td>33501.0</td>\n",
       "      <td>39013.0</td>\n",
       "      <td>46840.0</td>\n",
       "      <td>32824.0</td>\n",
       "      <td>10809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>115.0</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>2408.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>7591.0</td>\n",
       "      <td>89206.0</td>\n",
       "      <td>12988.0</td>\n",
       "      <td>25422.0</td>\n",
       "      <td>26781.0</td>\n",
       "      <td>35052.0</td>\n",
       "      <td>41140.0</td>\n",
       "      <td>51478.0</td>\n",
       "      <td>41939.0</td>\n",
       "      <td>22484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>6545.0</td>\n",
       "      <td>61564.0</td>\n",
       "      <td>11127.0</td>\n",
       "      <td>20737.0</td>\n",
       "      <td>26170.0</td>\n",
       "      <td>32850.0</td>\n",
       "      <td>59644.0</td>\n",
       "      <td>55040.0</td>\n",
       "      <td>57614.0</td>\n",
       "      <td>36581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>49387.0</td>\n",
       "      <td>8292.0</td>\n",
       "      <td>19105.0</td>\n",
       "      <td>23176.0</td>\n",
       "      <td>34110.0</td>\n",
       "      <td>44332.0</td>\n",
       "      <td>53378.0</td>\n",
       "      <td>78655.0</td>\n",
       "      <td>55447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>4664.0</td>\n",
       "      <td>48747.0</td>\n",
       "      <td>7181.0</td>\n",
       "      <td>15999.0</td>\n",
       "      <td>19787.0</td>\n",
       "      <td>23861.0</td>\n",
       "      <td>37116.0</td>\n",
       "      <td>47733.0</td>\n",
       "      <td>66977.0</td>\n",
       "      <td>91174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>41220.0</td>\n",
       "      <td>6965.0</td>\n",
       "      <td>13711.0</td>\n",
       "      <td>15362.0</td>\n",
       "      <td>16762.0</td>\n",
       "      <td>30811.0</td>\n",
       "      <td>36417.0</td>\n",
       "      <td>61220.0</td>\n",
       "      <td>145225.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hash_score_bin      0.0       1.0       2.0       3.0       4.0       5.0   \\\n",
       "tcs_maxs_bin                                                                 \n",
       "0.0                  NaN     220.0      53.0   81400.0   18786.0  272571.0   \n",
       "1.0             226599.0  222511.0  153802.0   13598.0   16543.0   91069.0   \n",
       "2.0                  4.0     263.0      19.0     399.0    2760.0   18864.0   \n",
       "3.0                 66.0    6528.0    4452.0   10568.0   28820.0  317948.0   \n",
       "4.0             151569.0  129892.0    2051.0    5377.0   44952.0  169633.0   \n",
       "5.0               5015.0    2637.0  271746.0  119089.0  125960.0  105225.0   \n",
       "6.0                286.0    2272.0    5632.0    4861.0   10654.0  179559.0   \n",
       "7.0                112.0    2070.0    4416.0    4510.0   17853.0  231335.0   \n",
       "8.0                151.0    2611.0    3780.0    4324.0   10749.0  260123.0   \n",
       "9.0                138.0    2657.0    3394.0    4175.0    9297.0  209182.0   \n",
       "10.0               173.0    2734.0    3133.0    3834.0    8039.0  151444.0   \n",
       "11.0               167.0    2569.0    3165.0    3622.0    8302.0  167976.0   \n",
       "12.0               161.0    3208.0    3634.0    4789.0   19949.0  153156.0   \n",
       "13.0               105.0    2118.0    2191.0    2557.0    6014.0   58717.0   \n",
       "14.0               115.0    2106.0    2408.0    2785.0    7591.0   89206.0   \n",
       "15.0                97.0    1745.0    2058.0    2437.0    6545.0   61564.0   \n",
       "16.0                67.0    1691.0    1734.0    2182.0    6634.0   49387.0   \n",
       "17.0                71.0    1281.0    1542.0    1679.0    4664.0   48747.0   \n",
       "18.0                77.0     611.0     815.0     954.0    3220.0   41220.0   \n",
       "\n",
       "hash_score_bin      6.0      7.0      8.0      9.0      10.0     11.0  \\\n",
       "tcs_maxs_bin                                                            \n",
       "0.0                122.0    195.0    324.0     24.0     19.0      4.0   \n",
       "1.0                 94.0    113.0    119.0     15.0     19.0      7.0   \n",
       "2.0                 30.0     23.0     29.0      3.0      2.0      1.0   \n",
       "3.0                544.0   3390.0    411.0     80.0     69.0     28.0   \n",
       "4.0             127831.0   1155.0    499.0    121.0     66.0     44.0   \n",
       "5.0               2793.0    305.0    160.0     55.0    117.0     63.0   \n",
       "6.0              11670.0  10123.0    782.0   1079.0     71.0     39.0   \n",
       "7.0              18299.0  46657.0  32451.0  16225.0   5185.0   1855.0   \n",
       "8.0              17839.0  23478.0  37244.0   9561.0   6206.0   3150.0   \n",
       "9.0              23335.0  58336.0  24956.0  11873.0   4713.0   3217.0   \n",
       "10.0             13780.0  38691.0  72404.0  72578.0  16247.0   5957.0   \n",
       "11.0             16670.0  39724.0  35475.0  42077.0  30403.0   9903.0   \n",
       "12.0             14354.0  38237.0  35045.0  43557.0  59543.0  56945.0   \n",
       "13.0              8225.0  18801.0  21462.0  33501.0  39013.0  46840.0   \n",
       "14.0             12988.0  25422.0  26781.0  35052.0  41140.0  51478.0   \n",
       "15.0             11127.0  20737.0  26170.0  32850.0  59644.0  55040.0   \n",
       "16.0              8292.0  19105.0  23176.0  34110.0  44332.0  53378.0   \n",
       "17.0              7181.0  15999.0  19787.0  23861.0  37116.0  47733.0   \n",
       "18.0              6965.0  13711.0  15362.0  16762.0  30811.0  36417.0   \n",
       "\n",
       "hash_score_bin     12.0      13.0  \n",
       "tcs_maxs_bin                       \n",
       "0.0                 5.0       4.0  \n",
       "1.0                 2.0       4.0  \n",
       "2.0                 3.0       NaN  \n",
       "3.0                52.0      18.0  \n",
       "4.0                62.0      16.0  \n",
       "5.0               108.0       8.0  \n",
       "6.0                44.0      20.0  \n",
       "7.0               813.0     423.0  \n",
       "8.0              1402.0     441.0  \n",
       "9.0              1290.0     422.0  \n",
       "10.0             2869.0    1093.0  \n",
       "11.0             5688.0    1894.0  \n",
       "12.0            21841.0    7344.0  \n",
       "13.0            32824.0   10809.0  \n",
       "14.0            41939.0   22484.0  \n",
       "15.0            57614.0   36581.0  \n",
       "16.0            78655.0   55447.0  \n",
       "17.0            66977.0   91174.0  \n",
       "18.0            61220.0  145225.0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tab = df_train.groupby(['tcs_maxs_bin','hash_score_bin'])['label'].agg([np.mean,np.size]).unstack() \n",
    "tab['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('{0} AUCROC train: tcs_max_score {1:.6f}. ha_score {2:.6f}. xgboost(tcs_max,ha_sc) {3:.6f}'.format(\n",
    "               'RandomForest',\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train.label, \n",
    "                  y_score = [e[1] for e in clfRF.predict_proba(df_train[['tcs_maxs','hash_score']])]\n",
    "                ),\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test.label, \n",
    "                  y_score = [e[1] for e in clfRF.predict_proba(df_test[['tcs_maxs','hash_score']])]\n",
    "                ),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_top = df_train[df_train['tcs_maxs'] > df_train['tcs_maxs'].quantile(0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_top.loc[:,'hash_score_bin'] = pd.cut(\n",
    "    df_train_top['hash_score'], \n",
    "    bins = np.unique(df_train_top['hash_score'].quantile(np.arange(0,1.01,0.1)).values), \n",
    "    labels  = False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash_score_bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>46896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.002484</td>\n",
       "      <td>27779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.002057</td>\n",
       "      <td>37428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.002604</td>\n",
       "      <td>37244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.003053</td>\n",
       "      <td>37337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.003294</td>\n",
       "      <td>37339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.003884</td>\n",
       "      <td>37335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.004794</td>\n",
       "      <td>37337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.006187</td>\n",
       "      <td>37337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.019927</td>\n",
       "      <td>37337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean   size\n",
       "hash_score_bin                 \n",
       "0.0             0.001578  46896\n",
       "1.0             0.002484  27779\n",
       "2.0             0.002057  37428\n",
       "3.0             0.002604  37244\n",
       "4.0             0.003053  37337\n",
       "5.0             0.003294  37339\n",
       "6.0             0.003884  37335\n",
       "7.0             0.004794  37337\n",
       "8.0             0.006187  37337\n",
       "9.0             0.019927  37337"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_top.groupby('hash_score_bin')['label'].agg([np.mean,np.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_sampled = df_train[(df_train.label == 1) | (np.random.rand(len(df_train)) < 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest AUCROC: 0.858583009817\n",
      "LogRegr AUCROC: 0.853759819568\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "from sklearn import svm\n",
    "clf = {\n",
    "   # 'LinSVC': sklearn.svm.LinearSVC(penalty='l1', loss='squared_hinge',C=1.0, class_weight='auto', max_iter=1000),\n",
    "   #'SVC': sklearn.svm.SVC(probability = True,max_iter = 100),\n",
    "    'LogRegr': sklearn.linear_model.LogisticRegression(),\n",
    "    'RandomForest': sklearn.ensemble.RandomForestClassifier(max_depth = 5,n_estimators = 50),\n",
    "   # 'GBM': sklearn.ensemble.GradientBoostingClassifier(n_estimators = 400)\n",
    "    \n",
    "}\n",
    "for m in clf:\n",
    "    clf[m].fit(X = df_train[['tcs_maxs','hash_score']],y = df_train['label'])\n",
    "    print('{0} AUCROC: {1}'.format(m,sklearn.metrics.roc_auc_score(\n",
    "                y_true = df_test['label'], \n",
    "                y_score = [e[1] for e in clf[m].predict_proba(df_test[['tcs_maxs','hash_score']])]\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### RandomForest Немного лучше max_tcs_score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = np_utils.normalize(df_train[['tcs_maxs','hash_score']])\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X = np.array([[ 1., -1.,  2.,11],\n",
    "               [ 2.,  0.,  0.,13],\n",
    "               [ 0.,  1., -1.,10]])\n",
    "scaler = preprocessing.StandardScaler().fit(df_train_sampled[['tcs_maxs','hash_score']])\n",
    "X, y = scaler.transform(df_train_sampled[['tcs_maxs','hash_score']]), df_train_sampled['label']\n",
    "Xt, yt = scaler.transform(df_test[['tcs_maxs','hash_score']]), df_test['label']\n",
    "\n",
    "\n",
    "Y_train = np_utils.to_categorical(df_train_sampled['label'].values, 2) # One-hot encode the labels\n",
    "#Y_test = np_utils.to_categorical(df_test['label'], 2) # One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 15 # we iterate twenty times over the entire training set\n",
    "hidden_size_1 = 32 # there will be 16 neurons in first layer\n",
    "hidden_size_2 = 16 \n",
    "\n",
    "\n",
    "inp = Input(shape=(2,)) # Our input is a 1D vector of size 784\n",
    "hidden_1 = Dense(hidden_size_1, activation='relu')(inp) # First hidden ReLU layer\n",
    "hidden_2 = Dense(hidden_size_2, activation='relu')(hidden_1) # Second hidden ReLU layer\n",
    "out = Dense(2, activation='softmax')(hidden_2) # Output softmax layer\n",
    "\n",
    "model = Model(input=inp, output=out) # To define a model, just specify its input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 675550 samples, validate on 75062 samples\n",
      "Epoch 1/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0438 - acc: 0.9919 - val_loss: 0.0288 - val_acc: 0.9942\n",
      "Epoch 2/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0277 - acc: 0.9944 - val_loss: 0.0287 - val_acc: 0.9942\n",
      "Epoch 3/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0277 - acc: 0.9944 - val_loss: 0.0291 - val_acc: 0.9939\n",
      "Epoch 4/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0277 - acc: 0.9944 - val_loss: 0.0288 - val_acc: 0.9942\n",
      "Epoch 5/15\n",
      "675550/675550 [==============================] - 7s - loss: 0.0277 - acc: 0.9945 - val_loss: 0.0291 - val_acc: 0.9940\n",
      "Epoch 6/15\n",
      "675550/675550 [==============================] - 8s - loss: 0.0276 - acc: 0.9945 - val_loss: 0.0289 - val_acc: 0.9943\n",
      "Epoch 7/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0276 - acc: 0.9945 - val_loss: 0.0288 - val_acc: 0.9942\n",
      "Epoch 8/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0276 - acc: 0.9945 - val_loss: 0.0286 - val_acc: 0.9944\n",
      "Epoch 9/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0287 - val_acc: 0.9944\n",
      "Epoch 10/15\n",
      "675550/675550 [==============================] - 5s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0287 - val_acc: 0.9943\n",
      "Epoch 11/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0287 - val_acc: 0.9943\n",
      "Epoch 12/15\n",
      "675550/675550 [==============================] - 7s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0286 - val_acc: 0.9944\n",
      "Epoch 13/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0291 - val_acc: 0.9940\n",
      "Epoch 14/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0289 - val_acc: 0.9941\n",
      "Epoch 15/15\n",
      "675550/675550 [==============================] - 6s - loss: 0.0275 - acc: 0.9945 - val_loss: 0.0286 - val_acc: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5829ae0b50>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "#model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras train AUCROC: 0.868020784375\n"
     ]
    }
   ],
   "source": [
    "    print('{0} AUCROC: {1}'.format('Keras train',sklearn.metrics.roc_auc_score(\n",
    "                y_true = y,\n",
    "                y_score =[e[1] for e in model.predict(X)]\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras test AUCROC: 0.86265400094\n"
     ]
    }
   ],
   "source": [
    "    print('{0} AUCROC: {1}'.format('Keras test',sklearn.metrics.roc_auc_score(\n",
    "                y_true = yt,\n",
    "                y_score = [e[1] for e in model.predict(Xt)]\n",
    "    )))\n",
    "\n",
    "#model.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "cl = AdaBoostClassifier()\n",
    "cl.fit(df_train[['tcs_maxs','hash_score']], df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost AUCROC train: 0.869603. test: 0.861106\n"
     ]
    }
   ],
   "source": [
    "print('{0} AUCROC train: {1:.6f}. test: {2:.6f}'.format(\n",
    "               'AdaBoost',\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train.label, \n",
    "                  y_score = cl.predict_proba(df_train[['tcs_maxs','hash_score']])[:,1]\n",
    "                ),\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test.label, \n",
    "                  y_score = cl.predict_proba(df_test[['tcs_maxs','hash_score']])[:,1]\n",
    "                ),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost AUCROC train: 0.877821. test: 0.868445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "print('Target class is first day.')\n",
    "clAB1 = AdaBoostClassifier()\n",
    "clAB1.fit(df_train[['tcs_maxs','hash_score']], df_train['first_day'])\n",
    "print('{0} AUCROC train: {1:.6f}. test: {2:.6f}'.format(\n",
    "               'AdaBoost',\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_train['first_day'], \n",
    "                  y_score = clAB1.predict_proba(df_train[['tcs_maxs','hash_score']])[:,1]\n",
    "                ),\n",
    "                sklearn.metrics.roc_auc_score(\n",
    "                  y_true = df_test['first_day'], \n",
    "                  y_score = clAB1.predict_proba(df_test[['tcs_maxs','hash_score']])[:,1]\n",
    "                ),\n",
    ")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample                          label sum   count       label mean\n",
      "Full train sample               4340        7468151     0.0006    \n",
      "tcs_maxs >q0.7 or ha >q0.7      3879        2825140     0.0014    \n",
      "tcs_maxs >q0.7 and ha >q0.7     3187        1552765     0.0021    \n",
      "tcs_maxs >q0.8 or ha >q0.8      3530        2029848     0.0017    \n",
      "tcs_maxs >q0.8 and ha >q0.8     2630        957364      0.0027    \n",
      "tcs_maxs >q0.9 or ha >q0.9      2979        1123401     0.0027    \n",
      "tcs_maxs >q0.9 and ha >q0.9     1846        364596      0.0051    \n",
      "tcs_maxs >q0.95 or ha >q0.95    2338        601552      0.0039    \n",
      "tcs_maxs >q0.95 and ha >q0.95   1279        145225      0.0088    \n",
      "tcs_maxs >q0.98 or ha >q0.98    1673        254736      0.0066    \n",
      "tcs_maxs >q0.98 and ha >q0.98   818         43970       0.0186    \n",
      "tcs_maxs >q0.99 or ha >q0.99    1274        134312      0.0095    \n",
      "tcs_maxs >q0.99 and ha >q0.99   601         14978       0.0401    \n"
     ]
    }
   ],
   "source": [
    "print('{:<30}  {:<10}  {:<10}  {:<10}'.format('Sample','label sum','count','label mean'))\n",
    "print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('Full train sample', df_train.label.sum(),df_train.label.count(),df_train.label.mean()))\n",
    "for q in [0.7,0.8,0.9,0.95,0.98,0.99]:\n",
    "    df1 = df_train[(df_train['tcs_maxs'] > df_train['tcs_maxs'].quantile(q)) | (df_train['hash_score'] > df_train['hash_score'].quantile(q))]\n",
    "    print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('tcs_maxs >q{0} or ha >q{0}'.format(q), df1.label.sum(),df1.label.count(),df1.label.mean()))\n",
    "    df1 = df_train[(df_train['tcs_maxs'] > df_train['tcs_maxs'].quantile(q)) & (df_train['hash_score'] > df_train['hash_score'].quantile(q))]\n",
    "    print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('tcs_maxs >q{0} and ha >q{0}'.format(q), df1.label.sum(),df1.label.count(),df1.label.mean()))\n",
    "\n",
    "\n",
    "#df_train_top1.label.sum(),df_train_top1.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample                          label sum   count       label mean\n",
      "Full train sample               4340        7468151     0.0006    \n",
      "tcs_maxs >q0.7                  3555        2138254     0.0017    \n",
      "tcs_maxs >q0.8                  3117        1493582     0.0021    \n",
      "tcs_maxs >q0.9                  2418        741182      0.0033    \n",
      "tcs_maxs >q0.95                 1853        373370      0.0050    \n",
      "tcs_maxs >q0.98                 1303        149343      0.0087    \n",
      "tcs_maxs >q0.99                 986         74608       0.0132    \n",
      "tcs_maxs >q0.995                826         36200       0.0228    \n",
      "tcs_maxs >q0.999                652         7477        0.0872    \n"
     ]
    }
   ],
   "source": [
    "print('{:<30}  {:<10}  {:<10}  {:<10}'.format('Sample','label sum','count','label mean'))\n",
    "print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('Full train sample', df_train.label.sum(),df_train.label.count(),df_train.label.mean()))\n",
    "for q in [0.7,0.8,0.9,0.95,0.98,0.99,0.995,0.999]:\n",
    "    df1 = df_train[(df_train['tcs_maxs'] > df_train['tcs_maxs'].quantile(q))]\n",
    "    print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('tcs_maxs >q{0}'.format(q), df1.label.sum(),df1.label.count(),df1.label.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample                          label sum   count       label mean\n",
      "Full train sample               4340        7468151     0.0006    \n",
      "ha >q0.7                        3511        2239651     0.0016    \n",
      "ha >q0.8                        3043        1493630     0.0020    \n",
      "ha >q0.9                        2407        746815      0.0032    \n",
      "ha >q0.95                       1764        373407      0.0047    \n",
      "ha >q0.98                       1188        149363      0.0080    \n",
      "ha >q0.99                       889         74682       0.0119    \n",
      "ha >q0.995                      694         37341       0.0186    \n",
      "ha >q0.999                      417         7469        0.0558    \n"
     ]
    }
   ],
   "source": [
    "print('{:<30}  {:<10}  {:<10}  {:<10}'.format('Sample','label sum','count','label mean'))\n",
    "print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('Full train sample', df_train.label.sum(),df_train.label.count(),df_train.label.mean()))\n",
    "for q in [0.7,0.8,0.9,0.95,0.98,0.99,0.995,0.999]:\n",
    "    df1 = df_train[df_train['hash_score'] > df_train['hash_score'].quantile(q)]\n",
    "    print('{:<30}  {:<10}  {:<10}  {:<10.4f}'.format('ha >q{0}'.format(q), df1.label.sum(),df1.label.count(),df1.label.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
